<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>PA &amp; CODING</title>
  
  <subtitle>求仁得仁</subtitle>
  <link href="https://jxch.github.io/atom.xml" rel="self"/>
  
  <link href="https://jxch.github.io/"/>
  <updated>2024-09-06T02:16:49.940Z</updated>
  <id>https://jxch.github.io/</id>
  
  <author>
    <name>钱不寒</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>MongoDB-SpringBoot集成</title>
    <link href="https://jxch.github.io/2024/09/06/architect/mongodb/mongodb-springboot-ji-cheng/"/>
    <id>https://jxch.github.io/2024/09/06/architect/mongodb/mongodb-springboot-ji-cheng/</id>
    <published>2024-09-06T02:16:49.000Z</published>
    <updated>2024-09-06T02:16:49.940Z</updated>
    
    <content type="html"><![CDATA[<ul><li>MongoTemplate<ul><li>CRUD<ul><li>实体 <code>@Document @Id @Field @Transient</code><ul><li><code>@Transient</code> 指定此成员变量不参与文档的序列化</li></ul></li><li><code>Query</code><ul><li><code>Criteria</code></li><li><code>Sort</code></li><li><code>new BasicQuery(json)</code></li></ul></li></ul></li><li>聚合操作 <code>MongoTemplate#aggregate</code><ul><li><code>Aggregation</code></li><li><code>TypedAggregation</code><ul><li><code>GroupOperation</code></li><li><code>MatchOperation</code></li><li><code>SortOperation</code></li><li><code>ProjectionOperation</code></li></ul></li></ul></li><li>事务操作<ul><li>编程式事务：<code>TransactionOptions -&gt; ClientSession</code></li><li>声明式事务（配置事务管理器）：<code>MongoDatabaseFactory -&gt; MongoTransactionManager</code></li></ul></li><li>change stream：<code>MessageListenerContainer</code></li></ul></li></ul><hr><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token comment">// 编程式事务</span><span class="token keyword">var</span> txo <span class="token operator">=</span> <span class="token class-name">TransactionOptions</span><span class="token punctuation">.</span><span class="token function">builder</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">readPreference</span><span class="token punctuation">(</span><span class="token class-name">ReadPreference</span><span class="token punctuation">.</span><span class="token function">primary</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">readConcern</span><span class="token punctuation">(</span><span class="token class-name">ReadConcern</span><span class="token punctuation">.</span><span class="token constant">MAJORITY</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">writeConcern</span><span class="token punctuation">(</span><span class="token class-name">WriteConcern</span><span class="token punctuation">.</span><span class="token constant">MAJORITY</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">build</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">try</span> <span class="token punctuation">(</span><span class="token class-name">ClientSession</span> clientSession <span class="token operator">=</span> client<span class="token punctuation">.</span><span class="token function">startSession</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>clientSession<span class="token punctuation">.</span><span class="token function">startTransaction</span><span class="token punctuation">(</span>txo<span class="token punctuation">)</span><span class="token punctuation">;</span>clientSession<span class="token punctuation">.</span><span class="token function">commitTransaction</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>clientSession<span class="token punctuation">.</span><span class="token function">abortTransaction</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// 回滚事务</span><span class="token punctuation">}</span><span class="token comment">// 声明式事务：配置事务管理器 -&gt; @Transactional</span><span class="token annotation punctuation">@Bean</span><span class="token class-name">MongoTransactionManager</span> <span class="token function">transactionManager</span><span class="token punctuation">(</span><span class="token class-name">MongoDatabaseFactory</span> factory<span class="token punctuation">)</span><span class="token punctuation">{</span><span class="token class-name">TransactionOptions</span> txnOptions <span class="token operator">=</span> <span class="token class-name">TransactionOptions</span><span class="token punctuation">.</span><span class="token function">builder</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">readPreference</span><span class="token punctuation">(</span><span class="token class-name">ReadPreference</span><span class="token punctuation">.</span><span class="token function">primary</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">readConcern</span><span class="token punctuation">(</span><span class="token class-name">ReadConcern</span><span class="token punctuation">.</span><span class="token constant">MAJORITY</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">writeConcern</span><span class="token punctuation">(</span><span class="token class-name">WriteConcern</span><span class="token punctuation">.</span><span class="token constant">MAJORITY</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">build</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">return</span> <span class="token keyword">new</span> <span class="token class-name">MongoTransactionManager</span><span class="token punctuation">(</span>factory<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><hr><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token comment">// change stream</span><span class="token comment">// 配置 mongo 监听器的容器 MessageListenerContainer</span><span class="token comment">// spring 启动时会自动启动监听的任务用于接收 changestream</span><span class="token annotation punctuation">@Bean</span><span class="token class-name">MessageListenerContainer</span> <span class="token function">messageListenerContainer</span><span class="token punctuation">(</span><span class="token class-name">MongoTemplate</span> template<span class="token punctuation">,</span> <span class="token class-name">DocumentMessageListener</span> documentMessageListener<span class="token punctuation">)</span> <span class="token punctuation">{</span>  <span class="token class-name">Executor</span> executor <span class="token operator">=</span> <span class="token class-name">Executors</span><span class="token punctuation">.</span><span class="token function">newFixedThreadPool</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token class-name">MessageListenerContainer</span> messageListenerContainer <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">DefaultMessageListenerContainer</span><span class="token punctuation">(</span>template<span class="token punctuation">,</span> executor<span class="token punctuation">)</span> <span class="token punctuation">{</span> <span class="token annotation punctuation">@Override</span> <span class="token keyword">public</span> <span class="token keyword">boolean</span> <span class="token function">isAutoStartup</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span> <span class="token keyword">return</span> <span class="token boolean">true</span><span class="token punctuation">;</span> <span class="token punctuation">}</span> <span class="token punctuation">}</span><span class="token punctuation">;</span>   <span class="token class-name">ChangeStreamRequest</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Document</span><span class="token punctuation">&gt;</span></span> request <span class="token operator">=</span> <span class="token class-name">ChangeStreamRequest</span><span class="token punctuation">.</span><span class="token function">builder</span><span class="token punctuation">(</span>documentMessageListener<span class="token punctuation">)</span> <span class="token punctuation">.</span><span class="token function">collection</span><span class="token punctuation">(</span><span class="token string">"user"</span><span class="token punctuation">)</span> <span class="token comment">//需要监听的集合名 </span><span class="token comment">//过滤需要监听的操作类型，可以根据需求指定过滤条件 </span><span class="token punctuation">.</span><span class="token function">filter</span><span class="token punctuation">(</span><span class="token class-name">Aggregation</span><span class="token punctuation">.</span><span class="token function">newAggregation</span><span class="token punctuation">(</span>  <span class="token class-name">Aggregation</span><span class="token punctuation">.</span><span class="token function">match</span><span class="token punctuation">(</span> <span class="token class-name">Criteria</span>  <span class="token punctuation">.</span><span class="token function">where</span><span class="token punctuation">(</span><span class="token string">"operationType"</span><span class="token punctuation">)</span>  <span class="token punctuation">.</span><span class="token function">in</span><span class="token punctuation">(</span><span class="token string">"insert"</span><span class="token punctuation">,</span> <span class="token string">"update"</span><span class="token punctuation">,</span> <span class="token string">"delete"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment">//不设置时，文档更新时，只会发送变更字段的信息，设置UPDATE_LOOKUP会返回文档的全部信息 </span><span class="token punctuation">.</span><span class="token function">fullDocumentLookup</span><span class="token punctuation">(</span><span class="token class-name">FullDocument</span><span class="token punctuation">.</span><span class="token constant">UPDATE_LOOKUP</span><span class="token punctuation">)</span> <span class="token punctuation">.</span><span class="token function">build</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>   messageListenerContainer<span class="token punctuation">.</span><span class="token function">register</span><span class="token punctuation">(</span>request<span class="token punctuation">,</span> <span class="token class-name">Document</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>   <span class="token keyword">return</span> messageListenerContainer<span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token comment">// 配置mongo监听器，用于接收数据库的变更信息</span><span class="token annotation punctuation">@Component</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">DocumentMessageListener</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">S</span><span class="token punctuation">,</span> <span class="token class-name">T</span><span class="token punctuation">&gt;</span></span> <span class="token keyword">implements</span> <span class="token class-name">MessageListener</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">S</span><span class="token punctuation">,</span> <span class="token class-name">T</span><span class="token punctuation">&gt;</span></span> <span class="token punctuation">{</span>  <span class="token annotation punctuation">@Override</span>   <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">onMessage</span><span class="token punctuation">(</span><span class="token class-name">Message</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">S</span><span class="token punctuation">,</span> <span class="token class-name">T</span><span class="token punctuation">&gt;</span></span> message<span class="token punctuation">)</span> <span class="token punctuation">{</span> <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span>  <span class="token string">"Received Message in collection %s.\n\trawsource: %s\n\tconverted: %s"</span><span class="token punctuation">,</span> message<span class="token punctuation">.</span><span class="token function">getProperties</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">getCollectionName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> message<span class="token punctuation">.</span><span class="token function">getRaw</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> message<span class="token punctuation">.</span><span class="token function">getBody</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;ul&gt;
&lt;li&gt;MongoTemplate
&lt;ul&gt;
&lt;li&gt;CRUD
&lt;ul&gt;
&lt;li&gt;实体 &lt;code&gt;@Document @Id @Field @Transient&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;@Transient&lt;/code&gt; 指定此成员变量不参与文档的</summary>
      
    
    
    
    <category term="IT学习笔记" scheme="https://jxch.github.io/categories/IT%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="MongoDB" scheme="https://jxch.github.io/tags/MongoDB/"/>
    
  </entry>
  
  <entry>
    <title>MongoDB-Change Stream</title>
    <link href="https://jxch.github.io/2024/09/06/architect/mongodb/mongodb-change-stream/"/>
    <id>https://jxch.github.io/2024/09/06/architect/mongodb/mongodb-change-stream/</id>
    <published>2024-09-06T02:11:49.000Z</published>
    <updated>2024-09-06T02:13:27.026Z</updated>
    
    <content type="html"><![CDATA[<ul><li>Change Stream 指数据的变化事件流，MongoDB从3.6版本开始提供订阅数据变更的功能<ul><li>是用于实现变更追踪的解决方案</li><li><img src="/static/IT/MongoDB/MongoDB-Change-Stream-1.png" alt="Change Stream"></li></ul></li><li>Change Stream 的实现原理：是基于 oplog 实现的，提供推送实时增量的推送功能<ul><li>它在 oplog 上开启一个 tailable cursor 来追踪所有复制集上的变更操作，最终调用应用中定义的回调函数</li><li>被追踪的变更事件主要包括<ul><li>insert/update/delete：插入、更新、删除；</li><li>drop：集合被删除；</li><li>rename：集合被重命名；</li><li>dropDatabase：数据库被删除；</li><li>invalidate：drop/rename/dropDatabase 将导致 invalidate 被触发， 并关闭 change stream；</li></ul></li></ul></li><li>如果只对某些类型的变更事件感兴趣，可以使用使用聚合管道的过滤步骤过滤事件<ul><li><code>var cs = db.user.watch([{ $match:{operationType:{$in:["insert","delete"]}} }])</code></li></ul></li><li>Change Stream会采用 <code>readConcern:majority</code> 这样的一致性级别，保证写入的变更不会被回滚<ul><li>未开启 majority readConcern 的集群无法使用 Change Stream；</li><li>当集群无法满足 <code>{w:majority}</code> 时，不会触发 Change Stream（例如 PSA 架构 中的 S 因故障宕机）</li></ul></li><li>Change Stream 故障恢复<ul><li><img src="/static/IT/MongoDB/MongoDB-Change-Stream-2.png" alt="Change Stream 故障恢复"></li><li>假设在一系列写入操作的过程中，订阅 Change Stream 的应用在接收到“写3”之后 于 t0 时刻崩溃<ul><li>想要从上次中断的地方继续获取变更流，只需要保留上次变更通知中的 <code>_id</code> 即可</li><li>Change Stream 回调所返回的的数据带有 <code>_id</code>，这个 <code>_id</code> 可以用于断点恢复</li><li><code>var cs = db.collection.watch([], {resumeAfter: &lt;_id&gt;})</code></li></ul></li></ul></li><li>使用场景<ul><li>跨集群的变更复制——在源集群中订阅 Change Stream，一旦得到任何变更立即写入目标集群</li><li>微服务联动——当一个微服务变更数据库时，其他微服务得到通知并做出相应的变更</li><li>其他任何需要系统联动的场景<ul><li>监控；消息推送</li><li>分析平台：推到下游的计算平台</li><li>数据同步：热备份；冷备份</li></ul></li></ul></li><li>注意事项<ul><li>Change Stream 依赖于 oplog，因此中断时间不可超过 oplog 回收的最大时间窗</li><li>在执行 update 操作时，如果只更新了部分数据，那么 Change Stream 通知的也是增量部分</li><li>删除数据时通知的仅是删除数据的 <code>_id</code></li></ul></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;ul&gt;
&lt;li&gt;Change Stream 指数据的变化事件流，MongoDB从3.6版本开始提供订阅数据变更的功能
&lt;ul&gt;
&lt;li&gt;是用于实现变更追踪的解决方案&lt;/li&gt;
&lt;li&gt;&lt;img src=&quot;/static/IT/MongoDB/MongoDB-Change-Str</summary>
      
    
    
    
    <category term="IT学习笔记" scheme="https://jxch.github.io/categories/IT%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="MongoDB" scheme="https://jxch.github.io/tags/MongoDB/"/>
    
  </entry>
  
  <entry>
    <title>MongoDB-索引</title>
    <link href="https://jxch.github.io/2024/09/06/architect/mongodb/mongodb-suo-yin/"/>
    <id>https://jxch.github.io/2024/09/06/architect/mongodb/mongodb-suo-yin/</id>
    <published>2024-09-06T02:08:49.000Z</published>
    <updated>2024-09-06T02:09:42.210Z</updated>
    
    <content type="html"><![CDATA[<ul><li>索引数据结构</li><li>索引设计原则</li><li>索引操作</li><li>索引类型<ul><li>单键索引；复合索引；多键索引；地理空间索引；全文索引；Hash索引；通配符索引</li></ul></li><li>索引属性<ul><li>唯一索引；部分索引；稀疏索引；TTL索引；隐藏索引</li></ul></li><li>索引使用建议</li><li>Explain 执行计划</li></ul><hr><h2 id="索引数据结构">索引数据结构</h2><ul><li>MongoDB采用B+Tree&nbsp;做索引，索引创建在colletions上<ul><li>不使用索引的查询，先扫描所有的文档，再匹配符合条件的文档</li><li>使用索引的查询，通过索引找到文档，使用索引能够极大的提升查询效率</li></ul></li><li>WiredTiger 数据文件在磁盘的存储结构<ul><li><img src="/static/IT/MongoDB/MongoDB-%E7%B4%A2%E5%BC%95-1.png" alt="WiredTiger"><ul><li>B+&nbsp;Tree中的leaf&nbsp;page包含一个页头（page&nbsp;header）、块头（block&nbsp;header）和真正的数据（key/value）<ul><li>页头定义了页的类型、页中实际载荷数据的大小、页中记录条数等信息</li><li>块头定义了此页的checksum、块在磁盘上的寻址位置等信息</li></ul></li><li>WiredTiger有一个块设备管理的模块，用来为page分配block<ul><li>如果要定位某一行数据<ul><li>先通过block的位置找到此page（相对于文件起始位置的偏移量）</li><li>再通过page找到行数据的相对位置</li><li>最后可以得到行数据相对于文件起始位置的偏移量offsets</li></ul></li></ul></li></ul></li></ul></li></ul><hr><h2 id="索引设计原则">索引设计原则</h2><ul><li>每个查询原则上都需要创建对应索引</li><li>单个索引设计应考虑满足尽量多的查询</li><li>索引字段选择及顺序需要考虑查询覆盖率及选择性</li><li>慎重<ul><li>对于更新及其频繁的字段上创建索引需慎重</li><li>对于数组索引需要慎重考虑未来元素个数</li><li>对于超长字符串类型字段上慎用索引</li><li>并发更新较高的单个集合上不宜创建过多索引</li></ul></li></ul><hr><h2 id="索引操作">索引操作</h2><ul><li>创建索引 <code> db.collection.createIndex(keys,&nbsp;options)</code><ul><li>Key&nbsp;值为你要创建的索引字段，1&nbsp;按升序创建索引，&nbsp;-1&nbsp;&nbsp;按降序创建索引</li><li>可选参数<ul><li>background 创建索引后台执行，默认值为 false</li><li>unique 创建唯一索引，默认值为 false</li><li>name 索引的名称，如果未指定，MongoDB将通过连接索引的字段名和排序顺序生成一个索引名称</li><li>dropDups （已废弃）在建立唯一索引时是否删除重复记录<ul><li>指定&nbsp;true&nbsp;创建唯一索引。默认值为&nbsp;false</li></ul></li><li>sparse 对文档中不存在的字段数据不启用索引（稀疏索引）<ul><li>如果设置为true的话，在索引字段中不会查询出不包含对应字段的文档。默认值为&nbsp;false</li></ul></li><li>expireAfterSeconds 设定集合的生存时间，TTL设定以秒为单位</li><li>v 索引的版本号。默认的索引版本取决于mongod创建索引时运行的版本</li><li>weights 索引权重值，数值在&nbsp;1&nbsp;到&nbsp;99_999&nbsp;之间，表示该索引相对于其他索引字段的得分权重</li><li>default_language 对于文本索引，该参数决定了停用词及词干和词器的规则列表。&nbsp;默认为英语</li><li>language_override 对于文本索引，该参数指定了包含在文档中的字段名<ul><li>语言覆盖默认的 language，默认值为&nbsp;language</li></ul></li><li>hidden 隐藏索引</li></ul></li></ul></li><li>查看索引<ul><li><code>db.books.getIndexes()</code> 查看索引信息</li><li><code>db.books.getIndexKeys()</code> 查看索引键</li><li><code>db.collection.totalIndexSize([is_detail])</code> 查看索引占用空间<ul><li>is_detail：可选参数，传入除0或false外的任意数据，都会显示该集合中每个索引的大小及总大小<ul><li>如果传入0或false则只显示该集合中所有索引的总大小。默认值为false</li></ul></li></ul></li></ul></li><li>删除索引<ul><li><code>db.col.dropIndex("索引名称")</code> 删除集合指定索引</li><li><code>db.col.dropIndexes()</code> 删除集合所有索引，不能删除主键索引</li></ul></li></ul><hr><h2 id="索引类型">索引类型</h2><ul><li>单键索引（Single&nbsp;Field&nbsp;Indexes）：在某一个特定的字段上建立索引<ul><li>MongoDB在ID上建立了唯一的单键索引</li><li><code>db.books.createIndex({title:1})</code></li></ul></li><li>复合索引（Compound&nbsp;Index）：是多个字段组合而成的索引<ul><li><code>db.books.createIndex({type:1,favCount:1})</code></li></ul></li><li>多键索引（Multikey&nbsp;Index）：在数组的属性上建立索引<ul><li>针对这个数组的任意值的查询都会定位到这个文档，既多个索引入口或者键值引用同一个文档（多键）</li><li>多键索引很容易与复合索引产生混淆<ul><li>复合索引是多个字段的组合，而多键索引则仅仅是在一个字段上出现了多键（multi&nbsp;key）</li><li>多键索引也可以出现在复合字段上<ul><li>MongoDB 并不支持一个复合索引中同时出现多个数组字段</li><li><code>db.inventory.createIndex(&nbsp;{&nbsp;item:1, ratings:&nbsp;1&nbsp;}&nbsp;)</code></li></ul></li></ul></li><li>支持在包含嵌套对象的数组字段上创建多键索引</li><li><code>db.inventory.createIndex(&nbsp;{&nbsp;ratings:&nbsp;1&nbsp;}&nbsp;)</code></li></ul></li><li>地理空间索引（Geospatial&nbsp;Index）：专门用于实现位置检索的一种特殊索引<ul><li>文档属性：<code>location:{type:"Point",coordinates:[‐73.97,40.77]}</code></li><li><code>db.restaurant.createIndex({location&nbsp;:&nbsp;"2dsphere"})</code><ul><li>创建一个2dsphere索引</li></ul></li><li>查询附近10000米：<code>db.restaurant.find({location:{$near:{$geometry:{type:"Point",coordinates:[-73.88,40.78]},$maxDistance:10000}}})</code><ul><li><code>$near</code> 查询操作符，用于实现附近检索，返回数据结果会按距离排序</li><li><code>$geometry</code> 操作符用于指定一个GeoJSON格式的地理空间对象<ul><li><code>type=Point</code> 表示地理坐标点</li><li>coordinates 则是用户当前所在的经纬度位置</li></ul></li><li><code>$maxDistance</code> 限定了最大距离，单位是米</li></ul></li></ul></li><li>全文索引（Text&nbsp;Indexes）：可通过建立文本索引来实现简易的分词检索<ul><li><code>db.reviews.createIndex(&nbsp;{&nbsp;comments:&nbsp;"text"&nbsp;}&nbsp;)</code></li><li><code>db.reviews.find({$text:&nbsp;{$search:&nbsp;"java&nbsp;coffee&nbsp;shop"}})</code><ul><li><code>$text</code>操作符可以在有text&nbsp;index的集合上执行文本检索</li><li><code>$text</code>将会使用空格和标点符号作为分隔符对检索字符串进行分词，&nbsp;并且对检索字符串中所有的分词结果进行一个逻辑上的&nbsp;OR&nbsp;操作</li></ul></li><li>MongoDB的文本索引功能存在诸多限制，而官方并未提供中文分词的功能</li></ul></li><li>Hash索引（Hashed&nbsp;Indexes）：在索引字段上进行精确匹配但不支持范围查询，不支持多键hash<ul><li><code>db.users.createIndex({username&nbsp;:&nbsp;'hashed'})</code></li><li>Hash索引上的入口是均匀分布的，在分片集合中非常有用</li></ul></li><li>通配符索引（Wildcard&nbsp;Indexes）：支持对未知或任意字段的查询<ul><li><code>db.products.createIndex(&nbsp;{&nbsp;"product_attributes.$**"&nbsp;:&nbsp;1&nbsp;}&nbsp;)</code></li><li>通配符索引不兼容的索引类型或属性<ul><li>TTL - TTL索引</li><li>Compound - 复合索引</li><li>Text - 全文索引</li><li>2d (Geospatial) - 地理空间索引</li><li>2dsphere (Geospatial) - 地理空间索引</li><li>Hashed - Hash索引</li><li>Unique - 唯一索引</li></ul></li><li>通配符索引是稀疏的，不索引空字段<ul><li>通配符索引不能支持查询字段不存在的文档</li></ul></li><li>通配符索引为文档或数组的内容生成条目，而不是文档/数组本身<ul><li>通配符索引不能支持精确的文档/数组相等匹配</li><li><code>db.products.find({&nbsp;"product_attributes.colors"&nbsp;:&nbsp;[&nbsp;"Blue",&nbsp;"Black"&nbsp;]&nbsp;}&nbsp;)</code><ul><li>不支持通配符索引</li></ul></li></ul></li><li>通配符索引可以支持查询字段等于空文档<code>{}</code>的情况</li></ul></li></ul><hr><h2 id="索引属性">索引属性</h2><ul><li>唯一索引（Unique&nbsp;Indexes）<ul><li>唯一性索引对于文档中缺失的字段，会使用null值代替，因此不允许存在多个文档缺失索引字段的情况</li><li>对于分片的集合，唯一性约束必须匹配分片规则<ul><li>为了保证全局的唯一性，分片键必须作为唯一性索引的前缀字段</li></ul></li></ul></li><li>部分索引（Partial&nbsp;Indexes）<ul><li>部分索引仅对满足指定过滤器表达式的文档进行索引<ul><li>通过在一个集合中为文档的一个子集建立索引</li></ul></li><li>部分索引具有更低的存储需求和更低的索引创建和维护的性能成本</li><li>部分索引提供了稀疏索引功能的超集，应该优先于稀疏索引</li><li><code>db.restaurants.createIndex({cuisine:1,name:1},{partialFilterExpression:{rating:{$gt:5}}})</code><ul><li>partialFilterExpression 选项接受指定过滤条件的文档<ul><li>等式表达式 (例如 <code>field:value</code> 或使用 <code>$eq</code> 操作符)</li><li><code>$exists:true</code></li><li><code>$gt&nbsp;$gte&nbsp;$lt&nbsp;$lte</code></li><li><code>$type&nbsp;</code></li><li>顶层的 <code>$and</code></li></ul></li></ul></li></ul></li><li>稀疏索引（Sparse&nbsp;Indexes）：&nbsp;只对存在字段的文档进行索引（包括字段值为null的文档）<ul><li>索引的稀疏属性确保索引只包含具有索引字段的文档的条目<ul><li>索引将跳过没有索引字段的文档</li></ul></li><li>如果稀疏索引会导致查询和排序操作的结果集不完整，MongoDB将不会使用该索引<ul><li>除非<code>hint()</code>明确指定索引<br>-<code> db.scores.find().sort(&nbsp;{&nbsp;score:&nbsp;‐1&nbsp;}&nbsp;).hint(&nbsp;{&nbsp;score:&nbsp;1&nbsp;}&nbsp;)</code></li></ul></li></ul></li><li>TTL索引（TTL&nbsp;Indexes）：在一定时间或特定时钟时间后自动从集合中删除文档<ul><li>TTL索引需要声明在一个日期类型的字段中，TTL&nbsp;索引是特殊的单字段索引<ul><li>TTL索引具有普通索引的功能，同样可以用于加速数据的查询</li></ul></li><li><code>db.xx.createIndex(&nbsp;{&nbsp;"lastModifiedDate":&nbsp;1&nbsp;},&nbsp;{&nbsp;expireAfterSeconds:3600&nbsp;}&nbsp;)</code><ul><li>单位是秒</li></ul></li><li>MongoDB会在周期性运行的后台线程中对该集合进行检查及数据清理工作<ul><li>TTL&nbsp;索引不保证过期数据会在过期后立即被删除</li><li>删除过期文档的后台任务每&nbsp;60&nbsp;秒运行一次</li></ul></li><li>可变的过期时间：TTL索引在创建之后，仍然可以对过期时间进行修改<ul><li>collMod 命令对索引的定义进行变更</li><li><code>db.runCommand({collMod:"xx",index:{keyPattern:{createdAt:1},expireAfterSeconds:600}})</code></li></ul></li><li>使用约束<ul><li>TTL索引只能支持单个字段，并且必须是非<code>_id</code>字段</li><li>TTL索引不能用于固定集合</li><li>TTL索引无法保证及时的数据老化<ul><li>MongoDB会通过后台的TTLMonitor定时器来清理老化数据，默认的间隔时间是1分钟</li><li>如果在数据库负载过高的情况下，TTL的行为则会进一步受到影响</li></ul></li><li>TTL索引对于数据的清理仅仅使用了remove命令，这种方式并不是很高效<ul><li>TTLMonitor在运行期间对系统CPU、磁盘都会造成一定的压力</li><li>相比之下，按日期分表的方式操作会更加高效</li></ul></li></ul></li></ul></li><li>隐藏索引（Hidden&nbsp;Indexes）<ul><li>隐藏索引对查询规划器不可见，不能用于支持查询</li><li>通过对规划器隐藏索引，用户可以在不实际删除索引的情况下评估删除索引的潜在影响</li><li>创建隐藏索引 <code>db.restaurants.createIndex({&nbsp;borough:&nbsp;1&nbsp;},{&nbsp;hidden:&nbsp;true&nbsp;});</code></li><li>隐藏现有索引 <code>db.restaurants.hideIndex(&nbsp;{&nbsp;borough:&nbsp;1}&nbsp;);</code></li><li>取消隐藏索引 <code>db.restaurants.unhideIndex(&nbsp;{&nbsp;borough:&nbsp;1}&nbsp;);</code></li></ul></li><li>多索引属性场景<ul><li>唯一约束结合部分索引使用导致唯一约束失效<ul><li>如果同时指定了partialFilterExpression和唯一约束，那么唯一约束只适用于满足筛选器表达式的文档</li><li>如果文档不满足筛选条件，那么带有唯一约束的部分索引不会阻止插入不满足唯一约束的文档</li></ul></li><li>具有稀疏性和唯一性的索引<ul><li>可以防止集合中存在字段值重复的文档，但允许不包含此索引字段的文档插入</li></ul></li></ul></li><li>日志存储场景：日期分表；固定集合；TTL索引<ul><li>插入：&nbsp;<code>writeConcern:0</code><ul><li>发起写操作，不关心是否成功</li></ul></li></ul></li></ul><hr><h2 id="索引使用建议">索引使用建议</h2><ul><li>为每一个查询建立合适的索引<ul><li>针对于数据量较大比如说超过几十上百万（文档数目）数量级的集合</li></ul></li><li>创建合适的复合索引，不要依赖于交叉索引<ul><li>交叉索引就是针对每个字段单独建立一个单字段索引，然后在查询执行时候使用相应的单字段索引进行索引交叉而得到查询结果</li><li>交叉索引目前触发率较低，所以如果你有一个多字段查询的时候，建议使用复合索引能够保证索引正常的使用</li></ul></li><li>复合索引字段顺序：匹配条件在前，范围条件在后（Equality&nbsp;First,&nbsp;Range&nbsp;After）</li><li>尽可能使用覆盖索引（Covered&nbsp;Index）<ul><li>建议只返回需要的字段，同时，利用覆盖索引来提升性能</li></ul></li><li>建索引要在后台运行<ul><li>在对一个集合创建索引时，该集合所在的数据库将不接受其他读写操作</li><li>所以对大数据量的集合建索引，建议使用后台运行选项&nbsp;<code>{background:&nbsp;true}</code></li></ul></li><li>避免设计过长的数组索引<ul><li>数组索引是多值的，在存储时需要使用更多的空间</li></ul></li></ul><hr><h2 id="Explain-执行计划">Explain 执行计划</h2><ul><li>我们需要关心的问题<ul><li>查询是否使用了索引</li><li>索引是否减少了扫描的记录数量</li><li>是否存在低效的内存排序</li></ul></li><li><code>db.collection.find().explain(&lt;verbose&gt;)</code><ul><li>verbose&nbsp;&nbsp;可选参数，表示执行计划的输出模式，默认 queryPlanner<ul><li>queryPlanner&nbsp;执行计划的详细信息，包括查询计划、集合信息、查询条件、最佳执行计划、查询方式和&nbsp;MongoDB&nbsp;服务信息等</li><li>exectionStats&nbsp;最佳执行计划的执行情况和被拒绝的计划等信息<ul><li>executionStats&nbsp;模式的返回信息中包含了&nbsp;queryPlanner&nbsp;模式的所有字段，并且还包含了最佳执行计划的执行情况</li></ul></li><li>allPlansExecution&nbsp;选择并执行最佳执行计划，并返回最佳执行计划和其他执行计划的执行情况<ul><li>allPlansExecution返回的信息包含&nbsp;executionStats&nbsp;模式的内容，且包含<code>allPlansExecution:[]</code>块</li></ul></li></ul></li></ul></li><li>stage 状态<ul><li>COLLSCAN&nbsp;全表扫描</li><li>IXSCAN&nbsp;索引扫描</li><li>FETCH&nbsp;根据索引检索指定文档</li><li>SHARD_MERGE&nbsp;将各个分片返回数据进行合并</li><li>SORT&nbsp;在内存中进行了排序</li><li>LIMIT&nbsp;使用limit限制返回数</li><li>SKIP&nbsp;使用skip进行跳过</li><li>IDHACK&nbsp;对_id进行查询</li><li>SHARDING_FILTER&nbsp;通过mongos对分片数据进行查询</li><li>COUNTSCAN&nbsp;count不使用Index进行count时的stage返回</li><li>COUNT_SCAN&nbsp;count使用了Index进行count时的stage返回</li><li>SUBPLA&nbsp;未使用到索引的<code>$or</code>查询的stage返回</li><li>TEXT&nbsp;使用全文索引进行查询时候的stage返回</li><li>PROJECTION&nbsp;限定返回字段时候stage的返回</li></ul></li><li>执行计划的返回结果中尽量不要出现以下 stage<ul><li>COLLSCAN(全表扫描)</li><li>SORT (使用sort但是无index)</li><li>不合理的SKIP</li><li>SUBPLA (未用到index的$or)</li><li>COUNTSCAN (不使用index进行count)</li></ul></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;ul&gt;
&lt;li&gt;索引数据结构&lt;/li&gt;
&lt;li&gt;索引设计原则&lt;/li&gt;
&lt;li&gt;索引操作&lt;/li&gt;
&lt;li&gt;索引类型
&lt;ul&gt;
&lt;li&gt;单键索引；复合索引；多键索引；地理空间索引；全文索引；Hash索引；通配符索引&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;索引属性
&lt;ul&gt;
</summary>
      
    
    
    
    <category term="IT学习笔记" scheme="https://jxch.github.io/categories/IT%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="MongoDB" scheme="https://jxch.github.io/tags/MongoDB/"/>
    
  </entry>
  
  <entry>
    <title>MongoDB-数据模型</title>
    <link href="https://jxch.github.io/2024/09/06/architect/mongodb/mongodb-shu-ju-mo-xing/"/>
    <id>https://jxch.github.io/2024/09/06/architect/mongodb/mongodb-shu-ju-mo-xing/</id>
    <published>2024-09-06T02:02:49.000Z</published>
    <updated>2024-09-06T02:05:51.459Z</updated>
    
    <content type="html"><![CDATA[<ul><li>BSON</li><li>ObjectId 生成器</li><li>内嵌文档和数组</li><li>固定集合</li><li>WiredTiger读写模型</li></ul><hr><h2 id="BSON">BSON</h2><ul><li>JSON基于文本的解析效率并不是最好的，在某些场景下往往会考虑选择更合适的编/解码格式</li><li>BSON（Binary&nbsp;JSON）是二进制版本的JSON，其在性能方面有更优的表现<ul><li>在空间的使用上，BSON相比JSON并没有明显的优势</li></ul></li><li>MongoDB在文档存储、命令协议上都采用了BSON作为编/解码格式<ul><li>类JSON的轻量级语义，支持简单清晰的嵌套、数组层次结构，可以实现模式灵活的文档结构</li><li>更高效的遍历，BSON在编码时会记录每个元素的长度，可以直接通过seek操作进行元素的内容读取，相对JSON解析来说，遍历速度更快</li><li>更丰富的数据类型，除了JSON的基本数据类型，BSON还提供了MongoDB所需的一些扩展类型，比如日期、二进制数据等，这更加方便数据的表示和操作</li></ul></li><li>一个BSON文档最大大小为16M，文档嵌套的级别不超过100</li><li>$type 操作符基于BSON类型来检索集合中匹配的数据类型，并返回结果<ul><li><code>db.xx.find({"title"&nbsp;:&nbsp;{$type&nbsp;:&nbsp;"string"}})</code></li></ul></li><li>日期类型 <code>db.dates.insert([{data1:Date()},{data2:new&nbsp;Date()},{data3:ISODate()}])</code><ul><li><code>Date()</code> 使用UTC（Coordinated&nbsp;Universal&nbsp;Time）进行存储，也就是+0时区的时间</li><li>使用<code>new&nbsp;Date()</code>与<code>ISODate()</code>最终都会生成ISODate类型的字段（对应于UTC时间）</li></ul></li></ul><hr><h2 id="ObjectId-生成器">ObjectId 生成器</h2><ul><li>MongoDB集合中所有的文档都有一个唯一的_id字段，作为集合的主键<ul><li>在默认情况下，<code>_id</code>字段使用ObjectId类型，采用16进制编码形式，共12个字节</li></ul></li><li>为了避免文档的<code>_id</code>字段出现重复，ObjectId被定义为3个部分<ul><li><img src="/static/IT/MongoDB/MongoDB-%E6%95%B0%E6%8D%AE%E6%A8%A1%E5%9E%8B-1.png" alt="ObjectId"></li><li>4字节表示Unix时间戳（秒）</li><li>5字节表示随机数（机器号+进程号唯一）<ul><li>5字节的随机数并没有明确定义，客户端可以采用机器号、进程号来实现</li></ul></li><li>3字节表示计数器（初始化时随机）</li></ul></li><li>大多数客户端驱动都会自行生成这个字段，比如MongoDB&nbsp;Java&nbsp;Driver会根据插入的文档是否包含<code>_id</code>字段来自动补充ObjectId对象。这样做不但提高了离散性，还可以降低MongoDB服务器端的计算压力</li><li><code>x&nbsp;=&nbsp;ObjectId()</code> 生成一个新的&nbsp;ObjectId</li><li>属性/方法<ul><li><code>str</code> 返回对象的十六进制字符串表示</li><li><code>ObjectId.getTimestamp()</code> 将对象的时间戳部分作为日期返回</li><li><code>ObjectId.toString()</code> 以字符串文字的形式返回&nbsp;JavaScript&nbsp;表示 ObjectId(…)</li><li><code>ObjectId.valueOf()</code> 将对象的表示形式返回为十六进制字符串。返回的字符串是<code>str</code>属性</li></ul></li></ul><hr><h2 id="内嵌文档和数组">内嵌文档和数组</h2><ul><li>内嵌文档：可以嵌套文档，比如查询时可以用<code>.</code>操作符</li><li>数组<ul><li><code>$slice</code>获取最后一个tag<ul><li><code>db.books.find({"author.name":"三毛"},{title:1,tags:{$slice:‐1}})</code></li></ul></li><li><code>$push</code>在数组末尾追加元素<ul><li><code>db.books.updateOne({"author.name":"三毛"},{$push:{tags:"猎奇"}})</code></li><li><code>$each</code>操作符配合可以用于添加多个元素<ul><li><code>db.books.updateOne({"author.name":"三毛"},{$push:{tags:{$each:["伤感","想象力"]}}})</code></li><li>加上<code>$slice</code>操作符，那么只会保留经过切片后的元素<ul><li><code>db.books.updateOne({"author.name":"三毛"},{$push:{tags:{$each:["伤感","想象力"],$slice:‐3}}})</code></li></ul></li></ul></li></ul></li><li>根据元素查询<ul><li><code>db.books.find({tags:"伤感"})</code> 查出所有包含伤感的文档</li><li><code>db.books.find({tags:{$all:["伤感","想象力"]}})</code></li></ul></li></ul></li><li>嵌套型的数组：数组元素可以是基本类型，也可以是内嵌的文档结构<ul><li><code>$elementMatch</code> 根据数组内文档的属性进行检索<ul><li><code>db.goods.find({tags:{$elemMatch:{tagKey:"color",tagValue:"黑色"}}})</code><ul><li>筛选出 <code>color=黑色</code> 的商品信息</li></ul></li></ul></li><li>如果进行组合式的条件检索，则可以使用多个<code>$elemMatch</code>操作符<ul><li><code>db.goods.find({tags:{$all:[{$elemMatch:{tagKey:"color",tagValue:"黑色"}},{$elemMatch:{tagKey:"size",tagValue:"XL"}}]}})</code></li></ul></li></ul></li></ul><hr><h2 id="固定集合">固定集合</h2><ul><li>固定集合（capped&nbsp;collection）是一种限定大小的集合。跟普通的集合相比，数据在写入这种集合时遵循FIFO原则<ul><li>可以保证数据库只会存储“限额”的数据，超过该限额的旧数据都会被丢弃</li></ul></li><li>创建固定集合：<code>db.createCollection("logs",{capped:true,size:4096,max:10})</code><ul><li>max：指集合的文档数量最大值，这里是10条</li><li>size：指集合的空间占用最大值，这里是4096字节（4KB）</li><li>只要任一条件达到阈值都会认为集合已经写满。其中size是必选的，而max则是可选的</li></ul></li><li><code>db.logs.stats()</code> 查看文档的占用空间</li><li>优势<ul><li>固定集合在底层使用的是顺序I/O操作，因此固定集合的写入性能是很高的</li><li>如果按写入顺序进行数据读取，也会获得非常好的性能表现</li></ul></li><li>限制<ul><li>无法动态修改存储的上限，如果需要修改max或size，则只能先执行<code>collection.drop</code>命令，将集合删除后再重新创建</li><li>无法删除已有的数据，对固定集合中的数据进行删除会报错</li><li>对已有数据进行修改，新文档大小必须与原来的文档大小一致，否则不允许更新</li><li>默认情况下，固定集合只有一个<code>_id</code>索引，而且最好是按数据写入的顺序进行读取<ul><li>也可以添加新的索引，但这会降低数据写入的性能</li></ul></li><li>固定集合不支持分片<ul><li>在MongoDB&nbsp;4.2版本中规定了事务中也无法对固定集合执行写操作</li></ul></li></ul></li><li>适用场景：很适合用来存储一些“临时态”的数据，意味着数据在一定程度上可以被丢弃，随着时间的推移，数据的重要性逐渐降低，直至被淘汰处理<ul><li>系统日志<ul><li>在MongoDB内部，副本集的同步日志（oplog）就使用了固定集合</li></ul></li><li>最新发布的TopN条文章信息（少量文档）<ul><li>得益于内部缓存的作用，对于这种少量文档的查询是非常高效的</li></ul></li></ul></li><li>使用固定集合实现FIFO队列：采用读取游标的方式（游标在获取不到数据时并不会被关闭）<ul><li><code>var&nbsp;cursor&nbsp;=&nbsp;db.xx.find({timestamped:{$gte:new&nbsp;Date()}}).tailable();</code></li><li><code>cursor.hasNext()</code></li><li><code>var doc = cursor.next()</code></li></ul></li></ul><hr><h2 id="WiredTiger-读写模型">WiredTiger 读写模型</h2><ul><li>MongoDB从3.0开始引入可插拔存储引擎的概念<ul><li>目前主要有MMAPV1、WiredTiger存储引擎（节省约60%以上的硬盘资源）可供选择</li></ul></li><li>读缓存：理想情况下，MongoDB可以提供近似内存式的读写性能<ul><li>WiredTiger引擎实现了数据的二级缓存，第一层是操作系统的页面缓存，第二层则是引擎提供的内部缓存</li><li><img src="/static/IT/MongoDB/MongoDB-%E6%95%B0%E6%8D%AE%E6%A8%A1%E5%9E%8B-2.png" alt="WiredTiger"></li><li>读取数据时的流程如下<ul><li>数据库发起Buffer&nbsp;I/O读操作，由操作系统将磁盘数据页加载到文件系统的页缓存区</li><li>引擎层读取页缓存区的数据，进行解压后存放到内部缓存区</li><li>在内存中完成匹配查询，将结果返回给应用</li></ul></li><li>MongoDB为了尽可能保证业务查询的“热数据”能快速被访问，其内部缓存的默认大小达到了内存的一半，该值由wiredTigerCacheSize参数指定<ul><li><code>wiredTigerCacheSize=Math.max((RAM/2‐1GB),256MB)</code></li></ul></li></ul></li><li>写缓冲<ul><li>当数据发生写入时，MongoDB并不会立即持久化到磁盘上，而是先在内存中记录这些变更，之后通过CheckPoint机制将变化的数据写入磁盘<ul><li>如果每次写入都触发一次磁盘I/O，那么开销太大，而且响应时延会比较大</li><li>多个变更的写入可以尽可能进行I/O合并，降低资源负荷</li></ul></li></ul></li><li>MongoDB单机下保证数据可靠性的机制包括以下两个部分<ul><li>CheckPoint（检查点）机制<ul><li>快照（snapshot）描述了某一时刻（point-in-time）数据在内存中的一致性视图，而这种数据的一致性是WiredTiger通过MVCC（多版本并发控制）实现的</li><li>当建立CheckPoint时，WiredTiger会在内存中建立所有数据的一致性快照，并将该快照覆盖的所有数据变化一并进行持久化（fsync）</li><li>成功之后，内存中数据的修改才得以真正保存</li><li>默认情况下，MongoDB每60s建立一次CheckPoint，在检查点写入过程中，上一个检查点仍然是可用的。这样可以保证一旦出错，MongoDB仍然能恢复到上一个检查点<ul><li>CheckPoint的刷新周期可以调整<code>storage.syncPeriodSecs</code>参数（默认值60s）</li><li>在MongoDB&nbsp;3.4及以下版本中，当Journal日志达到2GB时同样会触发CheckPoint行为</li></ul></li><li>如果应用存在大量随机写入，则CheckPoint可能会造成磁盘I/O的抖动。在磁盘性能不足的情况下，问题会更加显著，此时适当缩短CheckPoint周期可以让写入平滑一些</li></ul></li><li>Journal 日志<ul><li>Journal是一种预写式日志（write&nbsp;ahead&nbsp;log）机制，主要用来弥补CheckPoint机制的不足</li><li>如果开启了Journal日志，那么WiredTiger会将每个写操作的redo日志写入Journal缓冲区，该缓冲区会频繁地将日志持久化到磁盘上</li><li>默认情况下，Journal缓冲区每100ms执行一次持久化<ul><li>Journal日志达到100MB，或是应用程序指定 <code>journal:true</code>，写操作都会触发日志的持久化</li></ul></li><li>Journal日志的刷新周期可以通过参数<code>storage.journal.commitIntervalMs</code>指定<ul><li>MongoDB&nbsp;3.4及以下版本的默认值是50ms，而3.6版本之后调整到了100ms</li></ul></li><li>由于Journal日志采用的是顺序I/O写操作，频繁地写入对磁盘的影响并不是很大</li></ul></li><li>一旦MongoDB发生宕机，重启程序时会先恢复到上一个检查点，然后根据Journal日志恢复增量的变化。由于Journal日志持久化的间隔非常短，数据能得到更高的保障，如果按照当前版本的默认配置，则其在断电情况下最多会丢失100ms的写入数据</li></ul></li><li>WiredTiger写入数据的流程<ul><li><img src="/static/IT/MongoDB/MongoDB-%E6%95%B0%E6%8D%AE%E6%A8%A1%E5%9E%8B-3.png" alt="WiredTiger"></li><li>应用向MongoDB写入数据（插入、修改或删除）</li><li>数据库从内部缓存中获取当前记录所在的页块，如果不存在则会从磁盘中加载（Buffer&nbsp;I/O）</li><li>WiredTiger开始执行写事务，修改的数据写入页块的一个更新记录表，此时原来的记录仍然保持不变</li><li>如果开启了Journal日志，则在写数据的同时会写入一条Journal日志（Redo&nbsp;Log）<ul><li>该日志在最长不超过100ms之后写入磁盘</li></ul></li><li>数据库每隔60s执行一次CheckPoint操作，此时内存中的修改会真正刷入磁盘</li></ul></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;ul&gt;
&lt;li&gt;BSON&lt;/li&gt;
&lt;li&gt;ObjectId 生成器&lt;/li&gt;
&lt;li&gt;内嵌文档和数组&lt;/li&gt;
&lt;li&gt;固定集合&lt;/li&gt;
&lt;li&gt;WiredTiger读写模型&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&quot;BSON&quot;&gt;BSON&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;</summary>
      
    
    
    
    <category term="IT学习笔记" scheme="https://jxch.github.io/categories/IT%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="MongoDB" scheme="https://jxch.github.io/tags/MongoDB/"/>
    
  </entry>
  
  <entry>
    <title>MongoDB-事务</title>
    <link href="https://jxch.github.io/2024/09/06/architect/mongodb/mongodb-shi-wu/"/>
    <id>https://jxch.github.io/2024/09/06/architect/mongodb/mongodb-shi-wu/</id>
    <published>2024-09-06T01:48:49.000Z</published>
    <updated>2024-09-06T01:54:15.493Z</updated>
    
    <content type="html"><![CDATA[<ul><li>MongoDB 多文档事务<ul><li>writeConcern</li><li>readPreference</li><li>readConcern</li></ul></li><li>事务隔离级别</li></ul><hr><h2 id="MongoDB-多文档事务">MongoDB 多文档事务</h2><ul><li>对单个文档的操作是原子的<ul><li>由于可以在单个文档结构中使用内嵌文档和数组来获得数据之间的关系，而不必跨多个文档和集合进行范式化，所以这种单文档原子性避免了许多实际场景中对多文档事务的需求</li></ul></li><li>支持多文档事务（能不用尽量不用）<ul><li>通过合理地设计文档模型，可以规避绝大部分使用事务的必要性</li></ul></li><li>支持分布式事务，事务可以跨多个操作、集合、数据库、文档和分片使用</li><li>使用事务的原则<ul><li>无论何时，事务的使用总是能避免则避免</li><li>模型设计先于事务，尽可能用模型设计规避事务</li><li>不要使用过大的事务（尽量控制在&nbsp;1000&nbsp;个文档更新以内）</li><li>当必须使用事务时，尽可能让涉及事务的文档分布在同一个分片上，这将有效地提高效率</li></ul></li><li>事务支持机制<ul><li>Atomocity&nbsp;原子性：单表单文档；复制集多表多行；分片集群多表多行</li><li>Consistency&nbsp;一致性： writeConcern,&nbsp;readConcern</li><li>Isolation&nbsp;隔离性：readConcern</li><li>Durability&nbsp;持久性：Journal&nbsp;and&nbsp;Replication</li></ul></li><li>使用方法</li></ul><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token comment">// java</span><span class="token keyword">try</span> <span class="token punctuation">(</span><span class="token class-name">ClientSession</span> clientSession <span class="token operator">=</span> client<span class="token punctuation">.</span><span class="token function">startSession</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span> clientSession<span class="token punctuation">.</span><span class="token function">startTransaction</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>collection<span class="token punctuation">.</span><span class="token function">insertOne</span><span class="token punctuation">(</span>clientSession<span class="token punctuation">,</span> docOne<span class="token punctuation">)</span><span class="token punctuation">;</span>collection<span class="token punctuation">.</span><span class="token function">insertOne</span><span class="token punctuation">(</span>clientSession<span class="token punctuation">,</span> docTwo<span class="token punctuation">)</span><span class="token punctuation">;</span>clientSession<span class="token punctuation">.</span><span class="token function">commitTransaction</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token comment">// js</span><span class="token keyword">var</span> session <span class="token operator">=</span> db<span class="token punctuation">.</span><span class="token function">getMongo</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">startSession</span><span class="token punctuation">(</span><span class="token punctuation">)</span>session<span class="token punctuation">.</span><span class="token function">startTransaction</span><span class="token punctuation">(</span><span class="token punctuation">{</span>readConcern<span class="token operator">:</span><span class="token punctuation">{</span>level<span class="token operator">:</span><span class="token string">"snapshot"</span><span class="token punctuation">}</span><span class="token punctuation">,</span>writeConcern<span class="token operator">:</span><span class="token punctuation">{</span>w<span class="token operator">:</span><span class="token string">"majority"</span><span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token punctuation">)</span>session<span class="token punctuation">.</span><span class="token function">commitTransaction</span><span class="token punctuation">(</span><span class="token punctuation">)</span>session<span class="token punctuation">.</span><span class="token function">abortTransaction</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment">// 回滚事务</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="writeConcern">writeConcern</h3><ul><li>writeConcern&nbsp;决定一个写操作落到多少个节点上才算成功<ul><li>w:&nbsp;数据写入到number个节点才向用客户端确认<ul><li>{w:&nbsp;0}&nbsp;对客户端的写入不需要发送任何确认，适用于性能要求高，但不关注正确性的场景</li><li>{w:&nbsp;1}&nbsp;默认的writeConcern，数据写入到Primary就向客户端发送确认<ul><li><img src="/static/IT/MongoDB/MongoDB-%E4%BA%8B%E5%8A%A1-1.png" alt="w:&nbsp;1"></li></ul></li><li>{w:&nbsp;“majority”}&nbsp;数据写入到副本集大多数成员后向客户端发送确认，适用于对数据安全性要求比较高的场景，该选项会降低写入性能<ul><li><img src="/static/IT/MongoDB/MongoDB-%E4%BA%8B%E5%8A%A1-2.png" alt="w:&nbsp;&quot;majority&quot;"></li></ul></li></ul></li><li>j:&nbsp;写入操作的journal持久化后才向客户端确认<ul><li>默认为{j:&nbsp;false}，如果要求Primary写入持久化了才向客户端确认，则指定该选项为true</li></ul></li><li>wtimeout:&nbsp;写入超时时间，仅w的值大于1时有效<ul><li>当指定{w:&nbsp;}时，数据需要成功写入number个节点才算成功，如果写入过程中有节点故障，可能导致这个条件一直不能满足，从而一直不能向客户端发送确认结果<ul><li>客户端可设置wtimeout选项来指定超时时间，当写入过程持续超过该时间仍未结束，则认为写入失败</li></ul></li></ul></li></ul></li><li>注意事项<ul><li>然多于半数的&nbsp;writeConcern&nbsp;都是安全的，但通常只会设置&nbsp;majority，因为这是等待写入延迟时间最短的选择</li><li>不要设置&nbsp;writeConcern&nbsp;等于总节点数，因为一旦有一个节点故障，所有写操作都将失败</li><li>writeConcern&nbsp;虽然会增加写操作延迟时间，但并不会显著增加集群压力，因此无论是否等待，写操作最终都会复制到所有节点上。设置&nbsp;writeConcern&nbsp;只是让写操作等待复制后再返回而已</li><li>应对重要数据应用&nbsp;{w:&nbsp;“majority”}，普通数据可以应用&nbsp;{w:&nbsp;1}&nbsp;以确保最佳性能</li></ul></li></ul><h3 id="readPreference">readPreference</h3><ul><li>readPreference 决定使用哪一个节点来满足正在发起的读请求<ul><li>primary:&nbsp;只选择主节点，默认模式</li><li>primaryPreferred：优先选择主节点，如果主节点不可用则选择从节点</li><li>secondary：只选择从节点</li><li>secondaryPreferred：优先选择从节点，&nbsp;如果从节点不可用则选择主节点</li><li>nearest：根据客户端对节点的&nbsp;Ping&nbsp;值判断节点的远近，选择从最近的节点读取</li></ul></li><li>场景举例<ul><li>primary/primaryPreferred 用户下订单后马上将用户转到订单详情页（此时从节点可能还没复制到新订单）</li><li>secondary/secondaryPreferred 用户查询自己下过的订单（时效性通常没有太高要求）</li><li>secondary 生成报表（对时效性要求不高，但资源需求大）</li><li>nearest 将用户上传的图片分发到全世界，让各地用户能够就近读取</li></ul></li><li>readPreference&nbsp;配置<ul><li><code>mongodb://host1:27107,host2:27107,host3:27017/?replicaSet=rs0&amp;readPreference=secondary</code></li><li><code>MongoCollection.withReadPreference(ReadPreference&nbsp;readPref)</code></li><li><code>db.collection.find().readPref(&nbsp;"secondary"&nbsp;)</code></li></ul></li><li>Tag：readPreference&nbsp;只能控制使用一类节点。Tag&nbsp;则可以将节点选择控制到一个或几个节点<ul><li><img src="/static/IT/MongoDB/MongoDB-%E4%BA%8B%E5%8A%A1-3.png" alt="Tag"></li><li><code>conf&nbsp;=&nbsp;rs.conf()</code></li><li><code>conf.members[1].tags&nbsp;=&nbsp;{&nbsp;purpose:&nbsp;"online"}</code></li><li><code>conf.members[4].tags&nbsp;=&nbsp;{&nbsp;purpose:&nbsp;"analyse"}</code></li><li><code>rs.reconfig(conf)</code></li><li><code>db.collection.find({}).readPref(&nbsp;"secondary",&nbsp;[&nbsp;{purpose:&nbsp;"analyse"}&nbsp;]&nbsp;)</code></li></ul></li><li>注意事项<ul><li>指定&nbsp;readPreference&nbsp;时也应注意高可用问题<ul><li>将&nbsp;readPreference&nbsp;指定&nbsp;primary，则发生故障转移不存在&nbsp;primary&nbsp;期间将没有节点可读。如果业务允许，则应选择&nbsp;primaryPreferred</li></ul></li><li>使用&nbsp;Tag&nbsp;时也会遇到同样的问题，如果只有一个节点拥有一个特定&nbsp;Tag，则在这个节点失效时将无节点可读。这在有时候是期望的结果，有时候不是</li><li>Tag&nbsp;有时需要与优先级、选举权综合考虑。例如做报表的节点通常不会希望它成为主节点，则优先级应为&nbsp;0</li></ul></li></ul><h3 id="readConcern">readConcern</h3><ul><li>在&nbsp;readPreference&nbsp;选择了指定的节点后，readConcern&nbsp;决定这个节点上的数据哪些是可读的，类似事务隔离级别<ul><li>available：读取所有可用的数据</li><li>local（默认）：读取所有可用且属于当前分片的数据</li><li>majority（数据读一致性的充分保证）：读取在大多数节点上提交完成的数据</li><li>linearizable（增强处理&nbsp;majority&nbsp;情况下主节点失联时候的例外情况&nbsp;）：可线性化读取文档，仅支持从主节点读</li><li>snapshot（最高隔离级别）：读取最近快照中的数据，仅可用于多文档事务</li><li><code>db.user.find().readConcern("local")</code></li></ul></li><li>在复制集中&nbsp;local&nbsp;和&nbsp;available&nbsp;是没有区别的，两者的区别主要体现在分片集上<ul><li>一个&nbsp;chunk&nbsp;x&nbsp;正在从&nbsp;shard1&nbsp;向&nbsp;shard2&nbsp;迁移</li><li>整个迁移过程中&nbsp;chunk&nbsp;x&nbsp;中的部分数据会在&nbsp;shard1&nbsp;和&nbsp;shard2&nbsp;中同时存在，但源分片&nbsp;shard1仍然是chunk&nbsp;x&nbsp;的负责方<ul><li>所有对&nbsp;chunk&nbsp;x&nbsp;的读写操作仍然进入&nbsp;shard1</li><li>config&nbsp;中记录的信息&nbsp;chunk&nbsp;x&nbsp;仍然属于&nbsp;shard1</li></ul></li><li>此时如果读&nbsp;shard2，则会体现出&nbsp;local&nbsp;和&nbsp;available&nbsp;的区别<ul><li>local：只取应该由&nbsp;shard2&nbsp;负责的数据（不包括&nbsp;x）</li><li>available：shard2&nbsp;上有什么就读什么（包括&nbsp;x）</li></ul></li><li>注意事项<ul><li>虽然看上去总是应该选择&nbsp;local，但毕竟对结果集进行过滤会造成额外消耗。在一些无关紧要的场景（例如统计）下，也可以考虑&nbsp;available</li><li>从主节点读取数据时默认&nbsp;readConcern&nbsp;是&nbsp;local</li><li>从从节点读取数据时默认 readConcern&nbsp;是&nbsp;available（向前兼容原因）</li></ul></li></ul></li><li><code>readConcern:majority</code> 只读取大多数据节点上都提交了的数据<ul><li><img src="/static/IT/MongoDB/MongoDB-%E4%BA%8B%E5%8A%A1-4.png" alt="readConcern: majority"></li><li><img src="/static/IT/MongoDB/MongoDB-%E4%BA%8B%E5%8A%A1-5.png" alt="readConcern: majority"></li><li>考虑&nbsp;t3&nbsp;时刻的&nbsp;Secondary1<ul><li>对于要求&nbsp;majority&nbsp;的读操作，它将返回&nbsp;x=0</li><li>对于不要求&nbsp;majority&nbsp;的读操作，它将返回&nbsp;x=1</li></ul></li><li>配置文件：<code>replication:enableMajorityReadConcern:&nbsp;true</code></li></ul></li><li>MVCC&nbsp;机制（节点上维护多个&nbsp;x&nbsp;版本），MongoDB&nbsp;通过维护多个快照来链接不同的版本<ul><li>每个被大多数节点确认过的版本都将是一个快照</li><li>快照持续到没有人使用为止才被删除</li></ul></li><li>MongoDB&nbsp;中的回滚<ul><li>写操作到达大多数节点之前都是不安全的，一旦主节点崩溃，而从节点还没复制到该次操作，刚才的写操作就丢失了</li><li>把一次写操作视为一个事务，从事务的角度，可以认为事务被回滚了</li></ul></li><li><code>readConcern:majority</code> 可以有效避免脏读<ul><li>如果在一次写操作到达大多数节点前读取了这个写操作，然后因为系统故障该操作回滚了，则发生了脏读问题</li></ul></li><li>安全的读写分离：向主节点写入一条数据之后立即从从节点读取这条数据（可能读不到）<ul><li>使用 writeConcern+readConcern&nbsp;majority 来解决<ul><li><code>db.orders.insert({oid:101,sku:"kite",q:1},{writeConcern:{w:"majority"}})</code></li><li><code>db.orders.find({oid:101}).readPref("secondary").readConcern("majority")</code></li></ul></li></ul></li><li><code>readConcern:&nbsp;linearizable</code> 只读取大多数节点确认过的数据。和&nbsp;majority&nbsp;最大差别是保证绝对的操作线性顺序<ul><li>在写操作自然时间后面的发生的读，一定可以读到之前的写</li><li>只对读取单个文档时有效</li><li>可能导致非常慢的读，因此总是建议配合使用&nbsp;maxTimeMS</li><li><img src="/static/IT/MongoDB/MongoDB-%E4%BA%8B%E5%8A%A1-6.png" alt="rreadConcern:&nbsp;linearizable"></li></ul></li><li><code>readConcern:&nbsp;snapshot</code> 只在多文档事务中生效<ul><li>将保证在事务中的读：不出现脏读、不可重复读、幻读</li><li>因为所有的读都将使用同一个快照，直到事务提交为止该快照才被释放</li></ul></li></ul><hr><h2 id="事务隔离级别">事务隔离级别</h2><ul><li>事务完成前，事务外的操作对该事务所做的修改不可访问<ul><li>readPreference<ul><li>available：读取所有可用的数据</li><li>local（默认）：读取所有可用且属于当前分片的数据</li><li>majority（数据读一致性的充分保证）：读取在大多数节点上提交完成的数据</li><li>linearizable（增强处理&nbsp;majority&nbsp;情况下主节点失联时候的例外情况&nbsp;）<ul><li>可线性化读取文档，仅支持从主节点读</li></ul></li><li>snapshot（最高隔离级别）：读取最近快照中的数据，仅可用于多文档事务</li></ul></li></ul></li><li>如果事务内使用&nbsp;{readConcern:&nbsp;“snapshot”}，则可以达到可重复读</li><li>事务超时<ul><li>默认情况下MongoDB会为每个事务设置1分钟的超时时间，如果在该时间内没有提交，就会强制将其终止</li><li>该超时时间可以通过transactionLifetimeLimitSecond变量设定</li></ul></li><li>事务写机制<ul><li>当一个事务开始后，如果事务要修改的文档在事务外部被修改过，则事务修改这个文档时会触发&nbsp;Abort&nbsp;错误，因为此时的修改冲突了<ul><li>这种情况下，只需要简单地重做事务就可以了</li></ul></li><li>如果一个事务已经开始修改一个文档，在事务以外尝试修改同一个文档，则事务以外的修改会等待事务完成才能继续进行</li></ul></li><li>注意事项<ul><li>可以实现和关系型数据库类似的事务场景</li><li>必须使用与&nbsp;MongoDB&nbsp;4.2&nbsp;兼容的驱动</li><li>事务默认必须在&nbsp;60&nbsp;秒（可调）内完成，否则将被取消</li><li>涉及事务的分片不能使用仲裁节点</li><li>事务会影响&nbsp;chunk&nbsp;迁移效率。正在迁移的&nbsp;chunk&nbsp;也可能造成事务提交失败（重试即可）</li><li>多文档事务中的读操作必须使用主节点读</li><li>readConcern&nbsp;只应该在事务级别设置，不能设置在每次读写操作上</li></ul></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;ul&gt;
&lt;li&gt;MongoDB 多文档事务
&lt;ul&gt;
&lt;li&gt;writeConcern&lt;/li&gt;
&lt;li&gt;readPreference&lt;/li&gt;
&lt;li&gt;readConcern&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;事务隔离级别&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id</summary>
      
    
    
    
    <category term="IT学习笔记" scheme="https://jxch.github.io/categories/IT%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="MongoDB" scheme="https://jxch.github.io/tags/MongoDB/"/>
    
  </entry>
  
  <entry>
    <title>MongoDB-开发规范</title>
    <link href="https://jxch.github.io/2024/09/06/architect/mongodb/mongodb-kai-fa-gui-fan/"/>
    <id>https://jxch.github.io/2024/09/06/architect/mongodb/mongodb-kai-fa-gui-fan/</id>
    <published>2024-09-06T01:47:49.000Z</published>
    <updated>2024-09-06T01:47:40.302Z</updated>
    
    <content type="html"><![CDATA[<ul><li>命名原则：数据库名和集合名称均不能超过64个字符<ul><li>数据库、集合命名需要简单易懂，数据库名使用小写字符</li><li>集合名称使用统一命名风格，可以统一大小写或使用驼峰式命名</li></ul></li><li>集合设计：<ul><li>对少量数据的包含关系，使用嵌套模式有利于读性能和保证原子性的写入</li><li>对于复杂的关联关系，以及后期可能发生演进变化的情况，建议使用引用模式</li></ul></li><li>文档设计：避免使用大文档，MongoDB的文档最大不能超过16MB<ul><li>尽可能减少字段名的长度，一般建议将字段名称控制在32个字符以内</li></ul></li><li>索引设计：在必要时使用索引加速查询<ul><li>避免建立过多的索引，单个集合建议不超过10个索引</li><li>对集合的写入操作很可能也会触发索引的写入，从而触发更多的I/O操作</li><li>及时清理不使用或不合理的索引</li><li>遵循索引优化原则，如覆盖索引、优先前缀匹配等，使用explain命令分析索引性能</li></ul></li><li>分片设计：对可能出现快速增长或读写压力较大的业务表考虑分片<ul><li>分片键的设计满足均衡分布的目标</li><li>业务上尽量避免广播查询</li><li>在集合达到256GB之前就进行分片</li><li>如果集合中存在唯一性索引，则应该确保该索引覆盖分片键，避免冲突</li><li>为了降低风险，单个分片的数据集合大小建议不超过2TB</li></ul></li><li>升级设计：需支持对旧版本数据的兼容性<ul><li>在添加唯一性约束索引之前，对数据表进行检查并及时清理冗余的数据</li><li>新增、修改数据库对象等操作需要经过评审，并保持对数据字典进行更新</li></ul></li><li>数据老化：及时清理无效、过期的数据<ul><li>优先考虑为系统日志、历史数据表添加合理的老化策略</li></ul></li><li>数据一致性：<ul><li>非关键业务使用默认的 <code>WriteConcern:1</code>（更高性能写入）</li><li>关键业务类，使用 <code>WriteConcern:majority</code> 保证一致性（性能下降）</li><li>如果业务上严格不允许脏读，则使用 <code>ReadConcern:majority</code> 选项</li></ul></li><li>重复数据：使用<code>update</code>、<code>findAndModify</code>对数据进行修改时，如果设置了<code>upsert:true</code>，则必须使用唯一性索引避免产生重复数据</li><li>业务上尽量避免短连接：使用官方最新驱动的连接池实现，控制客户端连接池的大小，最大值建议不超过200</li><li>对大量数据写入使用Bulk&nbsp;Write批量化API，建议使用无序批次更新</li><li>优先使用单文档事务保证原子性<ul><li>如果需要使用多文档事务，则必须保证事务尽可能小，一个事务的执行时间最长不能超过60s</li></ul></li><li>在条件允许的情况下，利用读写分离降低主节点压力<ul><li>对于一些统计分析类的查询操作，可优先从节点上执行</li></ul></li><li>考虑业务数据的隔离<ul><li>例如将配置数据、历史数据存放到不同的数据库中</li><li>微服务之间使用单独的数据库，尽量避免跨库访问</li></ul></li><li>维护数据字典文档并保持更新，提前按不同的业务进行数据容量的规划</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;ul&gt;
&lt;li&gt;命名原则：数据库名和集合名称均不能超过64个字符
&lt;ul&gt;
&lt;li&gt;数据库、集合命名需要简单易懂，数据库名使用小写字符&lt;/li&gt;
&lt;li&gt;集合名称使用统一命名风格，可以统一大小写或使用驼峰式命名&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;集合设计：
&lt;ul&gt;
&lt;</summary>
      
    
    
    
    <category term="IT学习笔记" scheme="https://jxch.github.io/categories/IT%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="MongoDB" scheme="https://jxch.github.io/tags/MongoDB/"/>
    
  </entry>
  
  <entry>
    <title>MongoDB-聚合操作</title>
    <link href="https://jxch.github.io/2024/09/06/architect/mongodb/mongodb-ju-he-cao-zuo/"/>
    <id>https://jxch.github.io/2024/09/06/architect/mongodb/mongodb-ju-he-cao-zuo/</id>
    <published>2024-09-06T01:42:49.000Z</published>
    <updated>2024-09-06T01:44:43.622Z</updated>
    
    <content type="html"><![CDATA[<ul><li>单一作用聚合：提供了对常见聚合过程的简单访问，操作都从单个集合聚合文档</li><li>聚合管道：是一个数据聚合的框架，模型基于数据处理流水线的概念。文档进入多级管道，将文档转换为聚合结果</li><li>MapReduce 操作具有两个阶段（已被弃用，使用聚合管道代替）<ul><li>处理每个文档并向每个输入文档发射一个或多个对象的map阶段</li><li>reduce组合map操作的输出阶段</li></ul></li></ul><hr><h2 id="单一作用聚合">单一作用聚合</h2><p>聚合来自单个集合文档：</p><ul><li><code>db.collection.estimatedDocumentCount()</code> 返回集合或视图中所有文档的计数</li><li><code>db.collection.count()</code> 返回与find()集合或视图的查询匹配的文档计数<ul><li><code>db.books.count(query)</code> 等同于 <code>db.collection.find(query).count()</code></li><li>在分片群集上，如果存在孤立文档或正在进行块迁移，则 <code>db.collection.count()</code> 没有查询谓词可能导致计数不准确<ul><li>要避免这些情况，请在分片群集上使用 <code>db.collection.aggregate()</code> 方法</li></ul></li></ul></li><li><code>db.collection.distinct()</code>  在单个集合或视图中查找指定字段的不同值，并在数组中返回结果<ul><li><code>db.books.distinct("type")</code></li><li><code>db.books.distinct("type",{favCount:{$gt:90}})</code></li></ul></li></ul><hr><h2 id="聚合管道">聚合管道</h2><ul><li>MongoDB&nbsp;聚合框架（Aggregation&nbsp;Framework）是一个计算框架<ul><li>作用在一个或几个集合上</li><li>对集合中的数据进行的一系列运算</li><li>将这些数据转化为期望的形式</li></ul></li><li>从效果而言，聚合框架相当于&nbsp;SQL&nbsp;查询中的 GROUP&nbsp;BY、&nbsp;LEFT&nbsp;OUTER&nbsp;JOIN&nbsp;、&nbsp;AS等</li><li>管道（Pipeline）和阶段（Stage）：整个聚合运算过程称为管道（Pipeline），它是由多个阶段（Stage）组成的<ul><li><img src="/static/IT/MongoDB/MongoDB-%E8%81%9A%E5%90%88%E6%93%8D%E4%BD%9C-1.png" alt="Pipeline"></li><li>每个管道<ul><li>接受一系列文档（原始数据）</li><li>每个阶段对这些文档进行一系列运算</li><li>结果文档输出给下一个阶段</li></ul></li></ul></li><li>聚合管道操作语法：<code>db.collection.aggregate([$stage1,&nbsp;$stage2,&nbsp;...$stageN],&nbsp;{options})</code><ul><li>pipelines&nbsp;一组数据聚合阶段<ul><li>除<code>$out</code>、<code>$Merge</code> 和 <code>$geonear</code> 阶段之外，每个阶段都可以在管道中出现多次</li></ul></li><li>options&nbsp;可选，聚合操作的其他参数<ul><li>查询计划、是否使用临时文件、&nbsp;游标、最大操作时间、读写策略、强制索引等</li></ul></li><li><img src="/static/IT/MongoDB/MongoDB-%E8%81%9A%E5%90%88%E6%93%8D%E4%BD%9C-2.png" alt="聚合管道"></li></ul></li><li>常用的管道聚合阶段<ul><li><code>$match</code> 筛选条件</li><li><code>$project</code> 投影</li><li><code>$lookup</code> 左外连接</li><li><code>$sort</code> 排序</li><li><code>$group</code> 分组</li><li><code>$skip/$limit</code> 分页</li><li><code>$unwind</code> 展开数组</li><li><code>$graphLookup</code> 图搜索</li><li><code>$facet/$bucket</code> 分面搜索</li></ul></li><li>聚合表达式<ul><li>获取字段信息<ul><li><code>$&lt;field&gt;</code>&nbsp;&nbsp;用&nbsp;<code>$</code>&nbsp;指示字段路径</li><li><code>$&lt;field&gt;.&lt;sub&nbsp;field&gt;</code>&nbsp;使用&nbsp;<code>$</code>&nbsp;和 <code>.</code>&nbsp;来指示内嵌文档的路径</li></ul></li><li>常量表达式<ul><li><code>$literal:&lt;value&gt;</code> &nbsp;指示常量&nbsp;<code>&lt;value&gt;</code></li></ul></li><li>系统变量表达式<ul><li><code>$$&lt;variable&gt;</code> 使用&nbsp;<code>$$</code>&nbsp;指示系统变量</li><li><code>$$CURRENT</code> 指示管道中当前操作的文档</li></ul></li></ul></li><li><code>$project</code>：投影操作，&nbsp;将原始字段投影成指定名称<ul><li><code>db.books.aggregate([{$project:{name:"$title"}}])</code><ul><li>将集合中的&nbsp;title&nbsp;投影成&nbsp;name</li></ul></li><li><code>db.books.aggregate([{$project:{name:"$title",_id:0,type:1,author:1}}])</code><ul><li>剔除不需要的字段</li></ul></li><li>从嵌套文档中排除字段<ul><li><code>db.books.aggregate([{$project:{name:"$title",_id:0,type:1,"author.name":1}}])</code></li><li><code>db.books.aggregate([{$project:{name:"$title",_id:0,type:1,author:{name:1}}}])</code></li></ul></li></ul></li><li><code>$match</code> 用于对文档进行筛选，之后可以在得到的文档子集上做聚合，可以使用除了地理空间之外的所有常规查询操作符<ul><li><code>db.books.aggregate([{$match:{type:"technology"}}])</code></li><li>在实际应用中尽可能将<code>$match</code>放在管道的前面位置<ul><li>可以减少后续管道操作符要操作的文档数，提升效率</li><li>如果再投射和分组之前执行<code>$match</code>，查询可以使用索引</li></ul></li></ul></li><li><code>$count</code> 计数并返回与查询匹配的结果数<ul><li><code>db.books.aggregate([{$match:{type:"technology"}},{$count:&nbsp;"type_count"}])</code><ul><li><code>$match</code>阶段筛选出type匹配technology的文档，并传到下一阶段</li><li><code>$count</code>阶段返回聚合管道中剩余文档的计数，并将该值分配给<code>type_count</code></li></ul></li></ul></li><li><code>$group</code> 按指定的表达式对文档进行分组，并将每个不同分组的文档输出到下一个阶段<ul><li>输出文档包含一个<code>_id</code>字段，该字段按键包含不同的组</li><li>输出文档还可以包含计算字段，该字段保存由<code>$group</code>的<code>_id</code>字段分组的一些<code>accumulator</code>表达式的值</li><li><code>$group</code>不会输出具体的文档而只是统计信息</li><li><code>{$group:{_id:&lt;expression&gt;,&lt;field1&gt;:{&lt;accumulator1&gt;:&lt;expression1&gt;},...}}</code><ul><li><code>_id</code>字段是必填的;但是，可以指定<code>_id</code>值为<code>null</code>来为整个输入文档计算累计值</li><li>剩余的计算字段是可选的，并使用<code>&lt;accumulator&gt;</code>运算符进行计算</li><li><code>_id</code>和<code>&lt;accumulator&gt;</code>表达式可以接受任何有效的表达式</li></ul></li><li><code>accumulator</code> 操作符<ul><li><code>$avg</code> 计算均值</li><li><code>$first</code> 返回每组第一个文档，如果有排序，按照排序，如果没有按照默认的存储的顺序的第一个文档</li><li><code>$last</code> 返回每组最后一个文档，如果有排序，按照排序，如果没有按照默认的存储的顺序的最后个文档</li><li><code>$max</code> 根据分组，获取集合中所有文档对应值得最大值</li><li><code>$min</code> 根据分组，获取集合中所有文档对应值得最小值</li><li><code>$push</code> 将指定的表达式的值添加到一个数组中</li><li><code>$addToSet</code>&nbsp;将表达式的值添加到一个集合中（无重复值，无序）</li><li><code>$sum</code> 计算总和</li><li><code>$stdDevPop</code> 返回输入值的总体标准偏差（population&nbsp;standard&nbsp;deviation）</li><li><code>$stdDevSamp</code> 返回输入值的样本标准偏差（the&nbsp;sample&nbsp;standard&nbsp;deviation）</li></ul></li><li><code>$group</code> 阶段的内存限制为100M<ul><li>默认情况下，如果stage超过此限制，<code>$group</code>将产生错误</li><li>将 <code>allowDiskUse</code> 选项设置为 <code>true</code> 以启用<code>$group</code>操作写入临时文件来允许处理大型数据集</li></ul></li><li><code>db.books.aggregate([{$group:{_id:null,count:{$sum:1},pop:{$sum:"$favCount"},avg:{$avg:"$favCount"}}}])</code><ul><li>book的数量，收藏总数和平均值</li></ul></li><li><code>db.books.aggregate([{$group:{_id:"$author.name",pop:{$sum:"$favCount"}}}])</code><ul><li>统计每个作者的book收藏总数</li></ul></li><li><code>db.books.aggregate([{$group:{_id:"$author.name",types:{$addToSet:"$type"}}}])</code><ul><li>每个作者的book的type合集</li></ul></li></ul></li><li><code>$merge</code> 用于将聚合结果写入到指定的集合中。可以将结果合并到现有集合中，或者创建一个新集合<ul><li>into 输出集合的名称，如果目标集合不存在，MongoDB 将创建它</li><li>on 用于查找匹配文档的字段或字段组合</li><li>whenMatched 当文档匹配时执行的操作，可选值包括 “replace”, “merge”, “keepExisting”, “fail”, “pipeline”（自定义聚合阶段，用于更复杂的更新逻辑）</li><li>whenNotMatched 当文档不匹配时执行的操作，可选值包括 “insert”, “discard”, “fail”</li></ul></li><li><code>$unwind</code> 可以将数组拆分为单独的文档<ul><li>path 要指定字段路径，在字段名称前加上<code>$</code>符并用引号括起来</li><li>includeArrayIndex 可选，一个新字段的名称用于存放元素的数组索引。该名称不能以<code>$</code>开头</li><li>preserveNullAndEmptyArrays 可选，<code>default&nbsp;:false</code><ul><li>若为true，如果路径为空，缺少或为空数组，则<code>$unwind</code>输出文档</li></ul></li></ul></li><li><code>$sort</code> 对所有输入文档进行排序，并按排序顺序将它们返回到管道<ul><li><code>db.books.aggregate([{$sort&nbsp;:&nbsp;{favCount:‐1,title:1}}])</code></li><li>要对字段进行排序，请将排序顺序设置为1或-1，以分别指定升序或降序排序</li></ul></li><li><code>$limit</code> 限制传递到管道中下一阶段的文档数<ul><li>当<code>$sort</code>在管道中的<code>$limit</code>之前立即出现时，<code>$sort</code>操作只会在过程中维持前n个结果，其中n是指定的限制，而MongoDB只需要将n个项存储在内存中</li></ul></li><li><code>$skip</code> 跳过进入stage的指定数量的文档，并将其余文档传递到管道中的下一个阶段</li><li><code>$bucket</code> 用于对输入文档进行分组，根据指定的边界（buckets）将文档分配到指定的组，类似于&nbsp;<code>GROUP BY</code><ul><li>groupBy（必需）：指定要分组的字段或表达式。文档将根据该字段的值来分配到不同的 bucket 中</li><li>boundaries（必需）：一个数组，定义了 buckets 的分界点。数组元素是按升序排列的，表示不同的边界值<ul><li>值必须是相同的数据类型</li><li>例如，<code>[0, 10, 20, 30]</code>&nbsp;表示创建三个 buckets</li></ul></li><li>default（可选）：指定一个 bucket，用于存储所有不在&nbsp;<code>boundaries</code>&nbsp;定义的范围内的文档。如果未指定，超出边界范围的文档将被丢弃</li><li>output（可选）：一个文档，定义了每个 bucket 中需要包含的计算字段。每个字段是一个聚合表达式，该表达式操作落入该 bucket 中的文档<ul><li>例如，可以计算每个 bucket 中的文档总数、最大值、最小值、平均值等</li></ul></li></ul></li><li><code>$lookup</code> 主要用来实现多表关联查询<ul><li>每个输入待处理的文档，经过 <code>$lookup</code>&nbsp;阶段的处理，输出的新文档中会包含一个新生成的数组（可根据需要命名新key&nbsp;）</li><li>数组列存放的数据是来自被Join集合的适配文档，如果没有，集合为空（即&nbsp;为<code>[&nbsp;]</code>)</li><li>参数<ul><li>from 同一个数据库下等待被Join的集合</li><li>localField 源集合中的match值，如果输入的集合中，某文档没有&nbsp;localField 这个Key（Field），在处理的过程中，会默认为此文档含有&nbsp;<code>localField:null</code> 的键值对<ul><li>注意：<code>null&nbsp;=&nbsp;null</code>&nbsp;此为真</li></ul></li></ul></li></ul></li></ul><pre class="line-numbers language-javascript" data-language="javascript"><code class="language-javascript">db<span class="token punctuation">.</span>collection<span class="token punctuation">.</span><span class="token function">aggregate</span><span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">{</span><span class="token literal-property property">$lookup</span><span class="token operator">:</span> <span class="token punctuation">{</span><span class="token literal-property property">from</span><span class="token operator">:</span> <span class="token string">"&lt;collection to join&gt;"</span><span class="token punctuation">,</span><span class="token literal-property property">localField</span><span class="token operator">:</span> <span class="token string">"&lt;field from the input documents&gt;"</span><span class="token punctuation">,</span><span class="token literal-property property">foreignField</span><span class="token operator">:</span> <span class="token string">"&lt;field from the documents of the from collection&gt;"</span><span class="token punctuation">,</span><span class="token keyword">as</span><span class="token operator">:</span> <span class="token string">"&lt;output array field&gt;"</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><hr><h2 id="MapReduce">MapReduce</h2><ul><li>从MongoDB&nbsp;5.0开始，map-reduce操作已被弃用<ul><li>聚合管道比map-reduce操作提供更好的性能和可用性</li><li>Map-reduce操作可以使用聚合管道操作符重写，例如<code>$group</code>、 <code>$merge</code>等</li></ul></li><li>MapReduce操作将大量的数据处理工作拆分成多个线程并行处理，然后将结果合并在一起</li><li>MapReduce具有两个阶段<ul><li>将具有相同Key的文档数据整合在一起的map阶段</li><li>组合map操作的结果进行统计输出的reduce阶段</li></ul></li><li>MapReduce的基本语法<ul><li><img src="/static/IT/MongoDB/MongoDB-%E8%81%9A%E5%90%88%E6%93%8D%E4%BD%9C-3.png" alt="MapReduce"></li></ul></li></ul><pre class="line-numbers language-javascript" data-language="javascript"><code class="language-javascript">db<span class="token punctuation">.</span>collection<span class="token punctuation">.</span><span class="token function">mapReduce</span><span class="token punctuation">(</span><span class="token keyword">function</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span><span class="token function">emit</span><span class="token punctuation">(</span>key<span class="token punctuation">,</span>value<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token comment">//map 函数，将数据拆分成键值对，交给reduce函数</span><span class="token keyword">function</span><span class="token punctuation">(</span><span class="token parameter">key<span class="token punctuation">,</span>values</span><span class="token punctuation">)</span> <span class="token punctuation">{</span><span class="token keyword">return</span> reduceFunction<span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token comment">//reduce 函数，根据键将值做统计运算</span><span class="token punctuation">{</span><span class="token literal-property property">out</span><span class="token operator">:</span> <span class="token operator">&lt;</span>collection<span class="token operator">&gt;</span><span class="token punctuation">,</span>   <span class="token comment">// 可选，将结果汇入指定表</span><span class="token literal-property property">query</span><span class="token operator">:</span> <span class="token operator">&lt;</span>document<span class="token operator">&gt;</span><span class="token punctuation">,</span>   <span class="token comment">// 可选，筛选数据的条件，筛选的数据送入map </span><span class="token literal-property property">sort</span><span class="token operator">:</span> <span class="token operator">&lt;</span>document<span class="token operator">&gt;</span><span class="token punctuation">,</span>    <span class="token comment">// 排序完后，送入map </span><span class="token literal-property property">limit</span><span class="token operator">:</span> <span class="token operator">&lt;</span>number<span class="token operator">&gt;</span><span class="token punctuation">,</span>     <span class="token comment">// 限制送入map的文档数 </span><span class="token literal-property property">finalize</span><span class="token operator">:</span> <span class="token operator">&lt;</span><span class="token keyword">function</span><span class="token operator">&gt;</span><span class="token punctuation">,</span><span class="token comment">// 可选，修改reduce的结果后进行输出</span><span class="token literal-property property">scope</span><span class="token operator">:</span> <span class="token operator">&lt;</span>document<span class="token operator">&gt;</span><span class="token punctuation">,</span>   <span class="token comment">// 可选，指定map、reduce、finalize的全局变量 </span><span class="token literal-property property">jsMode</span><span class="token operator">:</span> <span class="token operator">&lt;</span>boolean<span class="token operator">&gt;</span><span class="token punctuation">,</span>   <span class="token comment">// 可选，默认false。在mapreduce过程中是否将数据转换成bson格式</span><span class="token literal-property property">verbose</span><span class="token operator">:</span> <span class="token operator">&lt;</span>boolean<span class="token operator">&gt;</span><span class="token punctuation">,</span>  <span class="token comment">// 可选，是否在结果中显示时间，默认false </span><span class="token literal-property property">bypassDocumentValidation</span><span class="token operator">:</span> <span class="token operator">&lt;</span>boolean<span class="token operator">&gt;</span> <span class="token comment">// 可选，是否略过数据校验</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;ul&gt;
&lt;li&gt;单一作用聚合：提供了对常见聚合过程的简单访问，操作都从单个集合聚合文档&lt;/li&gt;
&lt;li&gt;聚合管道：是一个数据聚合的框架，模型基于数据处理流水线的概念。文档进入多级管道，将文档转换为聚合结果&lt;/li&gt;
&lt;li&gt;MapReduce 操作具有两个阶段（已被弃用，使用</summary>
      
    
    
    
    <category term="IT学习笔记" scheme="https://jxch.github.io/categories/IT%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="MongoDB" scheme="https://jxch.github.io/tags/MongoDB/"/>
    
  </entry>
  
  <entry>
    <title>MongoDB-基础操作</title>
    <link href="https://jxch.github.io/2024/09/06/architect/mongodb/mongodb-ji-chu-cao-zuo/"/>
    <id>https://jxch.github.io/2024/09/06/architect/mongodb/mongodb-ji-chu-cao-zuo/</id>
    <published>2024-09-06T01:40:49.000Z</published>
    <updated>2024-09-06T01:41:04.451Z</updated>
    
    <content type="html"><![CDATA[<ul><li>特性：文档数据库（以&nbsp;JSON&nbsp;为数据模型）</li><li>Mongo&nbsp;shell：基于JavaScript（<code>interpreterVersion()</code>）</li><li>MongoDB 文档操作</li></ul><hr><h2 id="特性">特性</h2><ul><li>数据格式是BSON，一种类似JSON的二进制形式的存储格式，简称Binary&nbsp;JSON</li><li>集合（collection）：相当于SQL中的表，一个集合可以存放多个不同的文档</li><li>文档（document）：一个文档相当于数据表中的一行，由多个不同的字段组成</li><li>聚合操作（$lookup）：MongoDB用于实现“类似”表连接（tablejoin）的聚合操作符</li><li>半结构化，在一个集合中，文档所拥有的字段并不需要是相同的，而且也不需要对所用的字段进行声明<ul><li>文档还可以支持多级的嵌套、数组等灵活的数据类型</li></ul></li><li>弱关系，MongoDB没有外键的约束，也没有非常强大的表连接能力。类似的功能需要使用聚合管道技术来弥补</li><li>应用场景：不需要复杂/长事务和join支持</li><li>MongoDB&nbsp;Database&nbsp;Tools<ul><li>mongostat 数据库性能监控工具</li><li>mongotop 热点表监控工具</li><li>mongodump 数据库逻辑备份工具</li><li>mongorestore 数据库逻辑恢复工具</li><li>mongoexport 数据导出工具</li><li>mongoimport 数据导入工具</li><li>bsondump BSON格式转换工具</li><li>mongofiles GridFS文件工具</li></ul></li></ul><h2 id="Mongo-shell">Mongo&nbsp;shell</h2><ul><li><code>show&nbsp;dbs&nbsp;|&nbsp;show&nbsp;databases</code></li><li>use&nbsp;数据库名</li><li><code>db.dropDatabase() </code></li><li><code>show&nbsp;collections&nbsp;|&nbsp;show&nbsp;tables</code></li><li><code>db.createCollection("集合名", options)</code><ul><li>options<ul><li>capped：（可选）如果为true，则创建固定集合。固定集合是指有着固定大小的集合，当达到最大值时，它会自动覆盖最早的文档<ul><li>size：固定集合最大值（以字节计）</li><li>max：固定集合中包含文档的最大数量</li></ul></li></ul></li><li>当集合不存在时，向集合中插入文档也会创建集合</li></ul></li><li><code>db.集合名.stats() </code></li><li><code>db.集合名.drop() </code></li><li><code>db.createUser({user:"jxch",pwd:"jxch",roles:["root"]})</code> 创建管理员<ul><li>常用权限<ul><li><code>read readWrite</code></li><li><code>dbAdmin</code>  允许用户在指定数据库中执行管理函数，如索引创建、删除，查看统计或访问<code>system.profile</code></li><li><code>dbOwner</code> 允许用户在指定数据库中执行任意操作，增、删、改、查等</li><li><code>userAdmin</code>  允许用户向system.users集合写入，可以在指定数据库里创建、删除和管理用户</li><li>只在 admin 数据库中可用<ul><li><code>clusterAdmin</code> 赋予用户所有分片和复制集相关函数的管理权限</li><li><code>readAnyDatabase readWriteAnyDatabase</code></li><li><code>userAdminAnyDatabase</code></li><li><code>dbAdminAnyDatabase</code></li><li><code>root</code> 超级账号，超级权限</li></ul></li></ul></li><li><code>db.grantRolesToUser(&nbsp;"jxch"&nbsp;,&nbsp;[{&nbsp;role:&nbsp;"clusterAdmin",&nbsp;db:&nbsp;"admin"&nbsp;}])</code> 重新赋予用户操作权限</li><li><code>db.dropUser("jxch")</code></li><li><code>db.dropAllUser()</code> 删除当前数据库所有用户</li><li><code>db.auth("jxch", "jxch")</code> 用户认证，返回1表示认证成功<ul><li>默认情况下，MongoDB不会启用鉴权，以鉴权模式启动MongoDB<ul><li><code>mongod&nbsp;‐f&nbsp;/mongodb/conf/mongo.conf&nbsp;‐‐auth</code></li><li><code>mongo&nbsp;192.168.65.174:27017&nbsp;‐u&nbsp;jxch&nbsp;‐p&nbsp;jxch&nbsp;‐‐authenticationDatabase=admin</code></li></ul></li></ul></li><li>创建应用数据库用户<ul><li><code>use&nbsp;appdb</code></li><li><code>db.createUser({user:"jxch",pwd:"jxch",roles:["dbOwner"]})</code></li></ul></li></ul></li><li>`show&nbsp;users | show&nbsp;roles```</li><li><code>db.system.users.find()&nbsp;</code> 显示所有用户</li><li><code>show&nbsp;profile</code> 显示最近发生的操作</li><li><code>load("xxx.js") </code></li><li><code>exit&nbsp;|&nbsp;quit() </code></li><li><code>help | db.help() | db.集合名.help()</code></li></ul><h2 id="MongoDB-文档操作">MongoDB 文档操作</h2><ul><li><code>db.xxxcollection.xxxfunc</code></li><li>插入文档<ul><li>新增单个文档<ul><li><code>insertOne</code> 支持 writeConcern<ul><li>writeConcern&nbsp;决定一个写操作落到多少个节点上才算成功<ul><li>0：发起写操作，不关心是否成功</li><li>1~集群最大数据节点数：写操作需要被复制到指定节点数才算成功</li></ul></li><li>majority：写操作需要被复制到大多数节点上才算成功</li></ul></li><li>insert:&nbsp;若插入的数据主键已经存在，则会抛&nbsp;DuplicateKeyException&nbsp;异常，提示主键重复，不保存当前数据</li><li>save:&nbsp;如果 <code>_id</code>&nbsp;主键存在则更新数据，如果不存在就插入数据</li></ul></li><li>批量新增文档<ul><li><code>insertMany</code> 向指定集合中插入多条文档数据<ul><li>writeConcern：写入策略，默认为&nbsp;1，即要求确认写操作，0&nbsp;是不要求</li><li>ordered：指定是否按顺序写入，默认&nbsp;true，按顺序写入</li></ul></li><li>insert和save也可以实现批量插入</li></ul></li></ul></li><li>查询文档<ul><li>find&nbsp;查询集合中的若干文档  <code>db.collection.find(query,&nbsp;projection)</code><ul><li>query&nbsp;：可选，使用查询操作符指定查询条件<ul><li>查询逻辑运算符<ul><li>$lt:&nbsp;存在并小于</li><li>$lte:&nbsp;存在并小于等于</li><li>$gt:&nbsp;存在并大于</li><li>$gte:&nbsp;存在并大于等于</li><li>$ne:&nbsp;不存在或存在但不等于</li><li>$in:&nbsp;存在并在指定数组中</li><li>$nin:&nbsp;不存在或不在指定数组中</li><li>$or:&nbsp;匹配两个或多个条件中的一个</li><li>$and:&nbsp;匹配全部条件</li></ul></li><li>查询条件对照表<ul><li><code>a&nbsp;=&nbsp;1   &nbsp;{a:&nbsp;1}</code></li><li><code>a&nbsp;&lt;&gt;&nbsp;1  &nbsp;{a:&nbsp;{$ne:&nbsp;1}}</code></li><li><code>a&nbsp;&gt;&nbsp;1&nbsp;   {a:&nbsp;{$gt:&nbsp;1}}</code></li><li><code>a&nbsp;&gt;=&nbsp;1  &nbsp;{a:&nbsp;{$gte:&nbsp;1}}</code></li><li><code>a&nbsp;&lt;&nbsp;1   &nbsp;{a:&nbsp;{$lt:&nbsp;1}}</code></li><li><code>a&nbsp;&lt;=&nbsp;1  &nbsp;{a:&nbsp;{$lte:&nbsp;1}}</code></li></ul></li><li>查询逻辑对照表<ul><li><code>a&nbsp;=&nbsp;1&nbsp;AND&nbsp;b&nbsp;=&nbsp;1     {a:&nbsp;1,&nbsp;b:&nbsp;1}或{$and:&nbsp;[{a:&nbsp;1},&nbsp;{b:&nbsp;1}]}</code></li><li><code>a&nbsp;=&nbsp;1&nbsp;OR&nbsp;b&nbsp;=&nbsp;1      {$or:&nbsp;[{a:&nbsp;1},&nbsp;{b:&nbsp;1}]}</code></li><li><code>a&nbsp;IS&nbsp;NULL&nbsp;          {a:&nbsp;{$exists:&nbsp;false}}</code></li><li><code>a&nbsp;IN&nbsp;(1,&nbsp;2,&nbsp;3)&nbsp;     {a:&nbsp;{$in:&nbsp;[1,&nbsp;2,&nbsp;3]}}</code></li></ul></li><li>正则表达式匹配查询：&nbsp;使用&nbsp;<code>$regex</code>&nbsp;操作符来设置匹配字符串的正则表达式<ul><li><code>db.xx.find({type:{$regex:"so"}})</code></li><li><code>db.xx.find({type:/so/})</code></li></ul></li></ul></li><li>projection&nbsp;：可选，使用投影操作符指定返回的键。默认查询时返回文档中所有键值<ul><li>投影时，<code>_id</code>为1的时候，其他字段必须是1</li><li><code>_id</code>是0的时候，其他字段可以是0</li><li>如果没有<code>_id</code>字段约束，多个其他字段必须同为0或同为1</li></ul></li><li><code>find().pretty()</code> 格式化</li><li>指定排序 <code>db.xx.find({type:"value"}).sort({favCount:‐1})</code><ul><li>1&nbsp;为升序排列，而&nbsp;-1&nbsp;是用于降序排列</li></ul></li><li>分页查询 <code>db.xx.find().skip(8).limit(4)</code> （每页大小为8条，查询第3页）<ul><li>skip用于指定跳过记录数，limit则用于限定返回结果数量</li></ul></li><li>巧分页（使用查询条件 + 唯一排序条件）：数据量大的时候，应该避免使用skip/limit形式的分页<ul><li>第一页：<code>db.posts.find({}).sort({_id:&nbsp;1}).limit(20);&nbsp;</code></li><li>第二页：<code>db.posts.find({_id:&nbsp;{$gt:&nbsp;&lt;第一页最后一个_id&gt;}}).sort({_id:&nbsp;1}).limit(20);</code></li><li>第三页：<code>db.posts.find({_id:&nbsp;{$gt:&nbsp;&lt;第二页最后一个_id&gt;}}).sort({_id:&nbsp;1}).limit(20);</code></li></ul></li><li>如果查询返回的条目数量较多，mongo&nbsp;shell 则会自动实现分批显示<ul><li>默认情况下每次只显示20条，可以输入it命令读取下一批</li></ul></li><li>避免使用&nbsp;count&nbsp;，特别是数据量大和查询条件不能完整命中索引时</li></ul></li><li>findOne 查询集合中的第一个文档</li></ul></li><li>更新文档<ul><li>update 命令对指定的数据进行更新 <code>db.collection.update(query,update,options)</code><ul><li>query：描述更新的查询条件</li><li>update：描述更新的动作及新的内容<ul><li>更新操作符<ul><li><code>{$set:{field:value}}</code> 指定一个键并更新值，若键不存在则创建</li><li><code>{$unset:{field:1}}</code> 删除一个键</li><li><code>{$inc:{field:value}}</code> 对数值类型进行增减</li><li><code>{$rename:{old_field_name:new_field_name}}</code> 修改字段名称</li><li><code>{$push:{field:value}}</code> 将数值追加到数组中，若数组不存在则会进行初始化</li><li><code>{$pushAll:{field:value_array}}</code> 追加多个值到一个数组字段内</li><li><code>{$pull:{field:_value}}</code> 从数组中删除指定的元素</li><li><code>{$addToSet:{field:value}}</code> 添加元素到数组中，具有排重功能</li><li><code>{$pop:{field:1}}</code> 删除数组的第一个或最后一个元素</li><li>如果更新描述中不包含任何操作符，那么MongoDB会实现文档的replace语义</li></ul></li></ul></li><li>options：描述更新的选项<ul><li>upsert：可选，如果不存在update的记录，是否插入新的记录。默认false，不插入</li><li>multi：可选，是否按条件查询出的多条记录全部更新。&nbsp;默认false，只更新找到的第一条记录</li><li>writeConcern：可选，决定一个写操作落到多少个节点上才算成功</li></ul></li></ul></li><li>updateOne：更新单个文档</li><li>updateMany：更新多个文档</li><li>replaceOne：替换单个文档</li><li>findAndModify：兼容了查询和修改指定文档的功能，findAndModify 只能更新单个文档<ul><li>返回符合查询条件的文档数据，并完成对文档的修改</li><li>默认情况下，findAndModify会返回修改前的“旧”数据</li><li>如果希望返回修改后的数据，则可以指定new选项： <code>new:&nbsp;true</code></li></ul></li><li>findOneAndUpdate：更新单个文档并返回更新前（或更新后）的文档</li><li>findOneAndReplace：替换单个文档并返回替换前（或替换后）的文档</li></ul></li><li>删除文档<ul><li>remove<ul><li>匹配查询条件的文档会被删除</li><li>指定一个空文档条件会删除所有文档</li><li>默认会删除匹配条件的全部文档，如果希望明确限定只删除一个文档（首条），则需要指定justOne参数<ul><li><code>db.xxx.remove({type:"cc"}, true)</code></li></ul></li></ul></li><li>deleteOne</li><li>deleteMany</li><li>findOneAndDelete 返回被删除的文档<ul><li>按照指定顺序删除找到的第一个文档<ul><li><code>db.xx.findOneAndDelete({type:"cc"},{sort:{favCount:1}})</code></li><li>可以实现队列的先进先出</li></ul></li></ul></li><li>remove、deleteOne等命令只能按默认顺序删除</li><li>remove、deleteMany等命令需要对查询范围内的文档逐个删除，如果希望删除整个集合，则使用drop命令会更加高效</li></ul></li><li>文档操作最佳实践<ul><li>关于文档结构<ul><li>防止使用太长的字段名（浪费空间）</li><li>防止使用太深的数组嵌套（超过2层操作比较复杂）</li><li>不使用中文，标点符号等非拉丁字母作为字段名</li></ul></li><li>关于写操作<ul><li>update&nbsp;语句里只包括需要更新的字段</li><li>尽可能使用批量插入来提升写入性能</li><li>使用TTL自动过期日志类型的数据</li></ul></li></ul></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;ul&gt;
&lt;li&gt;特性：文档数据库（以&amp;nbsp;JSON&amp;nbsp;为数据模型）&lt;/li&gt;
&lt;li&gt;Mongo&amp;nbsp;shell：基于JavaScript（&lt;code&gt;interpreterVersion()&lt;/code&gt;）&lt;/li&gt;
&lt;li&gt;MongoDB 文档操作&lt;/l</summary>
      
    
    
    
    <category term="IT学习笔记" scheme="https://jxch.github.io/categories/IT%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="MongoDB" scheme="https://jxch.github.io/tags/MongoDB/"/>
    
  </entry>
  
  <entry>
    <title>MongoDB-高级集群架构</title>
    <link href="https://jxch.github.io/2024/09/06/architect/mongodb/mongodb-gao-ji-ji-qun-jia-gou/"/>
    <id>https://jxch.github.io/2024/09/06/architect/mongodb/mongodb-gao-ji-ji-qun-jia-gou/</id>
    <published>2024-09-06T01:32:49.000Z</published>
    <updated>2024-09-06T01:36:48.125Z</updated>
    
    <content type="html"><![CDATA[<ul><li>两地三中心集群架构</li><li>全球多写集群架构</li></ul><hr><h2 id="两地三中心集群架构">两地三中心集群架构</h2><p><img src="/static/IT/MongoDB/MongoDB-%E9%AB%98%E7%BA%A7%E9%9B%86%E7%BE%A4%E6%9E%B6%E6%9E%84-1.png" alt=""><br><img src="/static/IT/MongoDB/MongoDB-%E9%AB%98%E7%BA%A7%E9%9B%86%E7%BE%A4%E6%9E%B6%E6%9E%84-2.png" alt=""><br><img src="/static/IT/MongoDB/MongoDB-%E9%AB%98%E7%BA%A7%E9%9B%86%E7%BE%A4%E6%9E%B6%E6%9E%84-3.png" alt=""><br><img src="/static/IT/MongoDB/MongoDB-%E9%AB%98%E7%BA%A7%E9%9B%86%E7%BE%A4%E6%9E%B6%E6%9E%84-4.png" alt=""></p><hr><h2 id="全球多写集群架构">全球多写集群架构</h2><p><img src="/static/IT/MongoDB/MongoDB-%E9%AB%98%E7%BA%A7%E9%9B%86%E7%BE%A4%E6%9E%B6%E6%9E%84-5.png" alt=""><br><img src="/static/IT/MongoDB/MongoDB-%E9%AB%98%E7%BA%A7%E9%9B%86%E7%BE%A4%E6%9E%B6%E6%9E%84-6.png" alt=""><br><img src="/static/IT/MongoDB/MongoDB-%E9%AB%98%E7%BA%A7%E9%9B%86%E7%BE%A4%E6%9E%B6%E6%9E%84-7.png" alt="MongoDB Zone Sharding - 全球集群"><br><img src="/static/IT/MongoDB/MongoDB-%E9%AB%98%E7%BA%A7%E9%9B%86%E7%BE%A4%E6%9E%B6%E6%9E%84-8.png" alt=""></p>]]></content>
    
    
      
      
    <summary type="html">&lt;ul&gt;
&lt;li&gt;两地三中心集群架构&lt;/li&gt;
&lt;li&gt;全球多写集群架构&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&quot;两地三中心集群架构&quot;&gt;两地三中心集群架构&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;/static/IT/MongoDB/MongoDB-%E9%AB%98%E7%</summary>
      
    
    
    
    <category term="IT学习笔记" scheme="https://jxch.github.io/categories/IT%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="MongoDB" scheme="https://jxch.github.io/tags/MongoDB/"/>
    
  </entry>
  
  <entry>
    <title>MongoDB-复制集</title>
    <link href="https://jxch.github.io/2024/09/06/architect/mongodb/mongodb-fu-zhi-ji/"/>
    <id>https://jxch.github.io/2024/09/06/architect/mongodb/mongodb-fu-zhi-ji/</id>
    <published>2024-09-06T01:24:49.000Z</published>
    <updated>2024-09-06T01:28:36.366Z</updated>
    
    <content type="html"><![CDATA[<ul><li>复制集架构</li><li>复制集操作</li><li>复制集成员角色</li><li>复制集高可用</li><li>复制集数据同步机制 oplog</li></ul><hr><h2 id="复制集架构">复制集架构</h2><ul><li>在生产环境中，不建议使用单机版的MongoDB服务器<ul><li>单机版的MongoDB无法保证可靠性，一旦进程发生故障或是服务器宕机，业务将直接不可用</li><li>一旦服务器上的磁盘损坏，数据会直接丢失，而此时并没有任何副本可用</li></ul></li><li>Mongodb复制集（Replication&nbsp;Set）由一组Mongod实例（进程）组成，包含一个Primary节点和多个Secondary节点<ul><li>Mongodb&nbsp;Driver（客户端）的所有数据都写入Primary</li><li>Secondary从Primary同步写入的数据，以保持复制集内所有成员存储相同的数据集，提供数据的高可用</li><li><img src="/static/IT/MongoDB/MongoDB-%E5%A4%8D%E5%88%B6%E9%9B%86-1.png" alt="Mongodb复制集"></li></ul></li><li>复制集提供冗余和高可用性，是所有生产部署的基础，依赖于两个方面的功能<ul><li>数据写入时将数据迅速复制到另一个独立节点上</li><li>在接受写入的节点发生故障时自动选举出一个新的替代节点</li></ul></li><li>在实现高可用的同时，复制集实现了其他几个附加作用<ul><li>数据分发：将数据从一个区域复制到另一个区域，减少另一个区域的读延迟</li><li>读写分离：不同类型的压力分别在不同的节点上执行</li><li>异地容灾：在数据中心故障时候快速切换到异地</li></ul></li><li>local.system.replset：用来记录当前复制集的成员</li><li>local.startup_log：用来记录本地数据库的启动日志信息</li><li>local.replset.minvalid：用来记录复制集的跟踪信息，如初始化同步需要的字段</li></ul><hr><h2 id="复制集操作">复制集操作</h2><ul><li>PSS模式（官方推荐模式）：由一个主节点和两个备节点所组成，即 Primary+Secondary+Secondary<ul><li><img src="/static/IT/MongoDB/MongoDB-%E5%A4%8D%E5%88%B6%E9%9B%86-2.png" alt="PSS模式"></li><li>此模式始终提供数据集的两个完整副本，如果主节点不可用，则复制集选择备节点作为主节点并继续正常操作。旧的主节点在可用时重新加入复制集</li></ul></li><li>PSA模式：由一个主节点、一个备节点和一个仲裁者节点组成，即 Primary+Secondary+Arbiter<ul><li><img src="/static/IT/MongoDB/MongoDB-%E5%A4%8D%E5%88%B6%E9%9B%86-3.png" alt="PSA模式"></li><li>其中，Arbiter节点不存储数据副本，也不提供业务的读写操作</li><li>Arbiter节点发生故障不影响业务，仅影响选举投票</li><li>此模式仅提供数据的一个完整副本，如果主节点不可用，则复制集将选择备节点作为主节点</li></ul></li><li>复制集环境搭建<ul><li>即使暂时只有一台服务器，也要以单节点模式启动复制集<ul><li>单机多实例启动复制集</li><li>单节点启动复制集</li></ul></li><li>复制集各节点软件版本必须一致</li><li>增加节点不会增加系统写性能</li><li>启动&nbsp;MongoDB&nbsp;进程：<code>mongod&nbsp;‐f&nbsp;/data/db1/mongod.conf</code></li><li>配置复制集<ul><li>复制集通过<code>replSetInitiate</code>命令或mongo&nbsp;shell的<code>rs.initiate()</code>进行初始化<ul><li><code>rs.initiate()</code></li><li><code>rs.add("192.168.65.174:28018")</code></li><li>或 <code>rs.initiate({_id:&nbsp;"rs0",members:&nbsp;[{_id:&nbsp;0,host:&nbsp;"192.168.65.174:28017"}]})</code></li></ul></li><li>初始化后各个成员间开始发送心跳消息，并发起Priamry选举操作</li><li>获得『大多数』成员投票支持的节点，会成为Primary，其余节点成为Secondary</li></ul></li></ul></li><li>复制集状态查询<ul><li><code>rs.status()</code> 查看复制集整体状态<ul><li>可查看各成员当前状态，包括是否健康，是否在全量同步，心跳信息，增量同步信息，&nbsp;选举信息，上一次的心跳时间等</li></ul></li><li><code>db.isMaster()</code> 查看当前节点角色<ul><li>除了当前节点角色信息，是一个更精简化的信息，也返回整个复制集的成员列表，真正的Primary是谁，协议相关的配置信息等，Driver&nbsp;在首次连接复制集时会发送该命令</li></ul></li></ul></li><li>Mongo&nbsp;Shell 复制集命令<ul><li>rs.add()&nbsp;为复制集新增节点</li><li>rs.addArb()&nbsp;为复制集新增一个&nbsp;arbiter</li><li>rs.conf()&nbsp;返回复制集配置信息</li><li>rs.freeze()&nbsp;防止当前节点在一段时间内选举成为主节点</li><li>rs.help()&nbsp;返回&nbsp;replica&nbsp;set&nbsp;的命令帮助</li><li>rs.initiate()&nbsp;初始化一个新的复制集</li><li>rs.printReplicationInfo()&nbsp;以主节点的视角返回复制的状态报告</li><li>rs.printSecondaryReplicationInfo() 以从节点的视角返回复制状态报告</li><li>rs.reconfig() 通过重新应用复制集配置来为复制集更新配置</li><li>rs.remove()&nbsp;从复制集中移除一个节点</li><li>rs.secondaryOk()&nbsp;为当前的连接设置从节点可读<ul><li>在默认配置下，MongoDB 的客户端会将读操作只定向到主节点，这样可以确保读取的数据是最新的，因为主节点是接受写操作的唯一节点</li></ul></li><li>rs.status()&nbsp;返回复制集状态信息</li><li>rs.stepDown()&nbsp;让当前的&nbsp;primary&nbsp;变为从节点并触发&nbsp;election</li><li>rs.syncFrom()&nbsp;设置复制集节点从哪个节点处同步数据，将会覆盖默认选取逻辑</li></ul></li><li>安全认证<ul><li>创建用户<ul><li><code>use&nbsp;admin</code></li><li><code>db.createUser({user:"fox",pwd:"fox",roles:[{role:"clusterAdmin",db:"admin"}]})</code></li></ul></li><li>创建keyFile文件：&nbsp;集群之间的安全认证（开启keyfile认证就默认开启了auth认证了）<ul><li><code>openssl&nbsp;rand&nbsp;‐base64&nbsp;756&nbsp;&gt;&nbsp;/data/mongo.key</code></li><li>创建keyFile前，需要先停掉复制集中所有主从节点的mongod服务，然后再创建，否则有可能出现服务启动不了的情况</li><li>将主节点中的keyfile文件拷贝到复制集其他从节点服务器中，路径地址对应mongo.conf配置文件中的keyFile字段地址，并设置keyfile权限为600</li><li>启动命令 <code>mongod&nbsp;‐f&nbsp;/data/db1/mongod.conf&nbsp;‐‐keyFile&nbsp;/data/mongo.key</code></li><li>客户端连接 <code>mongo&nbsp;‐‐port&nbsp;28017&nbsp;‐ufox&nbsp;‐pfox&nbsp;‐‐authenticationDatabase=admin</code></li></ul></li></ul></li><li>复制集连接方式<ul><li>方式一：直接连接&nbsp;Primary&nbsp;节点，正常情况下可读写&nbsp;MongoDB，但主节点故障切换后，无法正常访问</li><li>方式二（强烈推荐）：通过高可用&nbsp;Uri&nbsp;的方式连接&nbsp;MongoDB，当&nbsp;Primary&nbsp;故障切换后，MongoDB&nbsp;Driver&nbsp;可自动感知并把流量路由到新的&nbsp;Primary&nbsp;节点<ul><li>springboot 可以同时配置集群内所有节点</li></ul></li></ul></li></ul><hr><h2 id="复制集成员角色">复制集成员角色</h2><ul><li>属性一：Priority&nbsp;=&nbsp;0<ul><li>当&nbsp;Priority&nbsp;等于&nbsp;0&nbsp;时，它不可以被复制集选举为主</li><li>Priority&nbsp;的值越高，则被选举为主的概率更大</li><li>通常，在跨机房方式下部署复制集可以使用该特性</li></ul></li><li>属性二：Vote&nbsp;=&nbsp;0<ul><li>不可以参与选举投票，此时该节点的&nbsp;Priority&nbsp;也必须为&nbsp;0，即它也不能被选举为主</li><li>由于一个复制集中最多只有7个投票成员，因此多出来的成员则必须将其vote属性值设置为0</li></ul></li><li>成员角色<ul><li>Primary：主节点，其接收所有的写请求，然后把修改同步到所有备节点<ul><li>一个复制集只能有一个主节点，当主节点“挂掉”后，其他节点会重新选举出来一个主节点</li></ul></li><li>Secondary：备节点，与主节点保持同样的数据集；当主节点“挂掉”时，参与竞选主节点<ul><li>分为以下三个不同类型<ul><li>Hidden&nbsp;=&nbsp;false：正常的只读节点，是否可选为主，是否可投票，取决于&nbsp;Priority，Vote&nbsp;的值</li><li>Hidden&nbsp;=&nbsp;true：隐藏节点，对客户端不可见，&nbsp;可以参与选举，但是&nbsp;Priority&nbsp;必须为&nbsp;0，即不能被提升为主<ul><li>由于隐藏节点不会接受业务访问，因此可通过隐藏节点做一些数据备份、离线计算的任务，这并不会影响整个复制集</li><li>在其他节点上执行&nbsp;db.isMaster()&nbsp;将不会显示隐藏节点</li></ul></li><li>Delayed&nbsp;：延迟节点，必须同时具备隐藏节点和Priority0的特性<ul><li>会延迟一定的时间（SlaveDelay&nbsp;配置决定）从上游复制增量</li><li>常用于快速回滚场景</li></ul></li></ul></li></ul></li><li>Arbiter：仲裁节点，只用于参与选举投票，本身不承载任何数据，只作为投票角色<ul><li>2个节点的复制集，1个&nbsp;Primary，1个Secondary，任意节点宕机，复制集将不能提供服务了（无法选出Primary），这时可以给复制集添加㇐个&nbsp;Arbiter节点，即使有节点宕机，仍能选出Primary</li><li>当复制集成员为偶数时，最好加入㇐个Arbiter节点，以提升复制集可用性</li></ul></li></ul></li><li>配置隐藏节点：很多情况下将节点设置为隐藏节点是用来协助&nbsp;delayed&nbsp;members&nbsp;的<ul><li><code>cfg&nbsp;=&nbsp;rs.conf()</code></li><li><code>cfg.members[1].priority&nbsp;=&nbsp;0</code></li><li><code>cfg.members[1].hidden&nbsp;=&nbsp;true</code></li><li><code>rs.reconfig(cfg)</code></li></ul></li><li>配置延时节点：当我们配置一个延时节点的时候，复制过程与该节点的&nbsp;oplog&nbsp;都将延时时。延时节点中的数据集将会比复制集中主节点的数据延后<ul><li><code>cfg&nbsp;=&nbsp;rs.conf()</code></li><li><code>cfg.members[1].priority&nbsp;=&nbsp;0</code></li><li><code>cfg.members[1].hidden&nbsp;=&nbsp;true</code></li><li><code>cfg.members[1].slaveDelay&nbsp;=&nbsp;60</code> 延迟1分钟</li><li><code>rs.reconfig(cfg)</code></li></ul></li><li>查看复制延迟：如果希望查看当前节点oplog的情况，则可以使用<code>rs.printReplicationInfo()</code>命令<ul><li>oplog的大小、最早一条oplog以及最后一条oplog的产生时间</li><li>通常在oplog大小不变的情况下，业务写操作越频繁，复制窗口（时间差）就会越短</li><li>在节点上执行<code>rs.printSecondaryReplicationInfo()</code>命令，可以一并列出所有备节点成员的同步延迟情况</li></ul></li><li>添加投票节点<ul><li><code>mongod&nbsp;‐‐port&nbsp;30000&nbsp;‐‐dbpath&nbsp;/data/arb&nbsp;‐‐replSet&nbsp;rs0</code> 启动仲裁节点，指定数据目录和复制集名称</li><li><code>rs.addArb("ip:30000")</code> 添加仲裁节点到复制集</li></ul></li><li>移除复制集节点<ul><li>使用&nbsp;<code>rs.remove()</code>&nbsp;来移除节点 <code>rs.remove("ip:port")</code></li><li>通过&nbsp;<code>rs.reconfig()</code>&nbsp;来移除节点<ul><li><code>cfg&nbsp;=&nbsp;rs.conf()</code></li><li><code>cfg.members.splice(2,1)</code> 从2开始移除1个元素</li><li><code>rs.reconfig(cfg)</code></li></ul></li></ul></li><li>更改复制集节点<ul><li><code>cfg&nbsp;=&nbsp;rs.conf()</code></li><li><code>cfg.members[0].host&nbsp;=&nbsp;"ip:port"</code></li><li><code>rs.reconfig(cfg)</code></li></ul></li></ul><hr><h2 id="复制集高可用">复制集高可用</h2><ul><li>复制集选举：Raft算法实现，选举成功的必要条件是大多数投票节点存活<ul><li>MongoDB对raft协议添加了一些扩展<ul><li>支持chainingAllowed链式复制<ul><li>从节点不只是从主节点上同步数据，还可以选择一个离自己最近（心跳延时最小）的节点来复制数据</li></ul></li><li>增加了预投票阶段，即 preVote<ul><li>主要是用来避免网络分区时产生 Term (任期) 值激增的问题<ul><li>多个节点同时选举；选举失败重试</li></ul></li><li>当一个节点认为自己有资格成为主节点时，它首先会向副本集中的其他节点发送预投票请求<ul><li>接收到预投票请求的节点会根据自身的状态进行检查，决定是否同意该请求</li><li>如果接收预投票请求的节点同意该请求，它就会给发起节点一个正面的响应</li><li>如果发起请求的节点收到足够多的正面响应（大多数节点同意它参与正式选举），它才会正式发起选举。否则，该节点会放弃这次尝试，并等待一段时间后再重试</li></ul></li></ul></li><li>支持投票优先级<ul><li>如果从节点发现自己的优先级比主节点高，则会主动发起投票并尝试成为新的主节点</li></ul></li><li>一个复制集最多可以有50&nbsp;个成员，但只有&nbsp;7&nbsp;个投票成员<ul><li>因为一旦过多的成员参与数据复制、投票过程，将会带来更多可靠性方面的问题</li></ul></li></ul></li><li>当复制集内存活的成员数量不足大多数时，整个复制集将无法选举出主节点，此时无法提供写服务，这些节点都将处于只读状态</li><li>如果希望避免平票结果的产生，最好使用奇数个节点成员，比如3个或5个。当然，在MongoDB复制集的实现中，对于平票问题已经提供了解决方案<ul><li>为选举定时器增加少量的随机时间偏差，这样避免各个节点在同一时刻发起选举，提高成功率</li><li>使用仲裁者角色，该角色不做数据复制，也不承担读写业务，仅仅用来投票</li></ul></li></ul></li><li>自动故障转移<ul><li>在复制集组建完成之后，各成员节点会开启定时器，持续向其他成员发起心跳；这里涉及的参数为 heartbeatIntervalMillis，即心跳间隔时间，默认值是2s<ul><li>如果心跳成功，则会持续以2s的频率继续发送心跳</li><li>如果心跳失败，则会立即重试心跳，一直到心跳恢复成功</li></ul></li><li>选举超时检测，一次心跳检测失败并不会立即触发重新选举；除了心跳，成员节点还会启动一个选举超时检测定时器，该定时器默认以10s的间隔执行，具体可以通过electionTimeoutMillis参数指定<ul><li>如果心跳响应成功，则取消上一次的electionTimeout调度（保证不会发起选举），并发起新一轮electionTimeout调度</li><li>如果心跳响应迟迟不能成功，那么electionTimeout任务被触发，进而导致备节点发起选举并成为新的主节点</li></ul></li><li>在MongoDB的实现中，选举超时检测的周期要略大于electionTimeoutMillis设定<ul><li>该周期会加入一个随机偏移量，大约在10～11.5s，如此的设计是为了错开多个备节点主动选举的时间，提升成功率</li></ul></li><li>在electionTimeout任务中触发选举必须要满足以下条件<ul><li>当前节点是备节点；当前节点具备选举权限；在检测周期内仍然没有与主节点心跳成功</li></ul></li></ul></li><li>业务影响评估<ul><li>在复制集发生主备节点切换的情况下，会出现短暂的无主节点阶段，此时无法接受业务写操作<ul><li>如果是因为主节点故障导致的切换，则对于该节点的所有读写操作都会产生超时<ul><li>可以通过开启retryWrite来降低影响<ul><li><code>mongodb://localhost/?retryWrites=true</code></li><li><code>mongo&nbsp;‐‐retryWrites</code></li></ul></li></ul></li><li>如果主节点属于强制掉电，那么整个Failover过程将会变长，很可能需要在Election定时器超时后才被其他节点感知并恢复，这个时间窗口一般会在12s以内；实际上，对于业务呼损的考量还应该加上客户端或mongos对于复制集角色的监视和感知行为（真实的情况可能需要长达30s以上）<ul><li>对于非常重要的业务，建议在业务层面做一些防护策略，比如设计重试机制</li></ul></li></ul></li><li>如果想不丢数据重启复制集，更优雅的打开方式应该是这样的<ul><li>逐个重启复制集里所有的Secondary节点</li><li>对Primary发送rs.stepDown()命令，等待primary降级为Secondary</li><li>重启降级后的Primary</li></ul></li></ul></li></ul><hr><h2 id="复制集数据同步机制-oplog">复制集数据同步机制 oplog</h2><ul><li>在复制集架构中，主节点与备节点之间是通过oplog来同步数据的<ul><li><img src="/static/IT/MongoDB/MongoDB-%E5%A4%8D%E5%88%B6%E9%9B%86-4.png" alt="oplog"><ul><li>这里的oplog是一个特殊的固定集合</li><li>当主节点上的一个写操作完成后，会向oplog集合写入一条对应的日志</li><li>备节点则通过这个oplog不断拉取到新的日志，在本地进行回放以达到数据同步的目的</li></ul></li></ul></li><li>MongoDB&nbsp;oplog<ul><li>MongoDB&nbsp;oplog&nbsp;是&nbsp;Local&nbsp;库下的一个集合，用来保存写操作所产生的增量日志</li><li>它是一个&nbsp;Capped&nbsp;Collection（固定集合），即超出配置的最大值后，会自动删除最老的历史数据<ul><li>MongoDB&nbsp;针对&nbsp;oplog&nbsp;的删除有特殊优化，以提升删除效率</li></ul></li><li>主节点产生新的&nbsp;oplog&nbsp;Entry，从节点通过复制&nbsp;oplog&nbsp;并应用来保持和主节点的状态一致</li></ul></li><li>查看 oplog<ul><li><code>use&nbsp;local</code></li><li><code>db.oplog.rs.find().sort({$natural:‐1}).pretty()</code><ul><li>ts字段描述了oplog产生的时间戳，可称之为optime。optime是备节点实现增量日志同步的关键，它保证了oplog是节点有序的，其由两部分组成<ul><li>当前的系统时间，即UNIX时间至现在的秒数，32位</li><li>整数计时器，不同时间值会将计数器进行重置，32位</li></ul></li><li>optime属于BSON的Timestamp类型，这个类型一般在MongoDB内部使用</li></ul></li></ul></li><li>oplog 保证了节点级有序，那么备节点便可以通过轮询的方式进行拉取；这里会用到可持续追踪的游标（tailable&nbsp;cursor）技术<ul><li><img src="/static/IT/MongoDB/MongoDB-%E5%A4%8D%E5%88%B6%E9%9B%86-5.png" alt="oplog"><ul><li>每个备节点都分别维护了自己的一个offset，也就是从主节点拉取的最后一条日志的optime</li><li>在执行同步时就通过这个optime向主节点的oplog集合发起查询</li><li>为了避免不停地发起新的查询链接，在启动第一次查询后可以将cursor挂住（通过将cursor设置为tailable）</li><li>这样只要oplog中产生了新的记录，备节点就能使用同样的请求通道获得这些数据</li><li>tailable&nbsp;cursor只有在查询的集合为固定集合时才允许开启</li></ul></li></ul></li><li>oplog 集合的大小 <code>replication.oplogSizeMB</code><ul><li>默认值为 <code>oplogSizeMB&nbsp;=&nbsp;min(磁盘可用空间*5%，50GB)</code></li><li><code>db.oplog.rs.stats().maxSize</code> 查看oplog大小</li><li><code>replSetResizeOplog</code>命令，可以实现动态修改oplogSize而不需要重启服务器<ul><li><code>db.adminCommand({replSetResizeOplog:&nbsp;1,&nbsp;size:&nbsp;60000})</code></li></ul></li></ul></li><li>oplog 幂等性：每一条oplog记录都描述了一次数据的原子性变更，对于oplog来说，必须保证是幂等性的</li><li>oplog 幂等性的代价<ul><li>简单元素的操作，$inc&nbsp;转化为&nbsp;$set并没有什么影响，执行开销上也差不多</li><li>但当遇到数组元素操作时，情况就不一样了<ul><li><code>$push</code>操作被转换为了<code>$set</code>操作（设置数组指定位置的元素为某个值），开销上也差不多</li><li>当向数组的头部添加元素时，oplog里的<code>$set</code>操作不再是设置数组某个位置的值（因为基本所有的元素位置都调整了），而是<code>$set</code>数组最终的结果，即整个数组的内容都要写入oplog</li><li>当push操作指定了<code>$slice</code>或者<code>$sort</code>参数时，oplog的记录方式也是一样的，会将整个数组的内容作为<code>$set</code>的参数</li><li><code>$pull</code>,&nbsp;<code>$addToSet</code>等更新操作符也是类似，更新数组后，oplog里会转换成<code>$set</code>数组的最终内容，才能保证幂等性</li></ul></li><li>大数组更新：oplog的写入被放大，导致同步追不上（致主备间网卡流量跑满）<ul><li>当数组非常大时，对数组的一个小更新，可能就需要把整个数组的内容记录到oplog里</li><li>由于oplog的量太大，旧的内容很快被删除掉，最终导致Secondary追不上，转换为RECOVERING状态</li></ul></li><li>使用数组时，尽量注意<ul><li>数组的元素个数不要太多，总的大小也不要太大</li><li>尽量避免对数组进行更新操作</li><li>如果一定要更新，尽量只在尾部插入元素，复杂的逻辑可以考虑在业务层面上来支持</li></ul></li></ul></li><li>oplog 复制延迟<ul><li>由于oplog集合是有固定大小的，因此存放在里面的oplog随时可能会被新的记录冲掉</li><li>如果备节点的复制不够快，就无法跟上主节点的步伐，从而产生复制延迟（replication&nbsp;lag）问题</li><li>一旦备节点的延迟过大，则随时会发生复制断裂的风险<ul><li>这意味着备节点的optime（最新一条同步记录）已经被主节点老化掉，于是备节点将无法继续进行数据同步</li></ul></li></ul></li><li>尽量避免复制延迟带来的风险<ul><li>增加oplog的容量大小，并保持对复制窗口的监视</li><li>通过一些扩展手段降低主节点的写入速度</li><li>优化主备节点之间的网络</li><li>避免字段使用太大的数组（可能导致oplog膨胀）</li></ul></li><li>数据回滚<ul><li>由于复制延迟是不可避免的，这意味着主备节点之间的数据无法保持绝对的同步</li><li>当复制集中的主节点宕机时，备节点会重新选举成为新的主节点<ul><li>当旧的主节点重新加入时，必须回滚掉之前的一些“脏日志数据”，以保证数据集与新的主节点一致<ul><li>主备复制集合的差距越大，发生大量数据回滚的风险就越高</li></ul></li></ul></li><li>对于写入的业务数据来说，如果已经被复制到了复制集的大多数节点，则可以避免被回滚的风险<ul><li>应用上可以通过设定更高的写入级别（writeConcern：majority）来保证数据的持久性</li></ul></li><li>这些由旧主节点回滚的数据会被写到单独的rollback目录下，必要的情况下仍然可以恢复这些数据<ul><li>当rollback发生时，MongoDB将把rollback的数据以BSON格式存放到dbpath路径下rollback文件夹中，BSON文件的命名格式：<code>&lt;database&gt;.&lt;collection&gt;.&lt;timestamp&gt;.bson</code></li><li><code>mongorestore&nbsp;‐‐host&nbsp;192.168.192:27018&nbsp;‐‐db&nbsp;test&nbsp;‐‐collection&nbsp;emp&nbsp;‐ufox&nbsp;‐pfox  ‐‐authenticationDatabase=admin&nbsp;rollback/emp_rollback.bson</code></li></ul></li></ul></li><li>同步源选择：MongoDB 是允许通过备节点进行复制的<ul><li>在<code>settings.chainingAllowed</code>开启的情况下（默认是开启的），备节点自动选择一个最近的节点（ping命令时延最小）进行同步</li><li>默认情况下备节点并不一定会选择主节点进行同步，这个副作用就是会带来延迟的增加，关闭这个设置：<ul><li><code>cfg&nbsp;=&nbsp;rs.config()</code></li><li><code>cfg.settings.chainingAllowed&nbsp;=&nbsp;false</code></li><li><code>rs.reconfig（cfg)</code></li></ul></li><li>使用<code>replSetSyncFrom</code>命令临时更改当前节点的同步源，比如在初始化同步时将同步源指向备节点来降低对主节点的影响<ul><li><code>db.adminCommand(&nbsp;{&nbsp;replSetSyncFrom:&nbsp;"hostname:port"&nbsp;})</code></li></ul></li></ul></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;ul&gt;
&lt;li&gt;复制集架构&lt;/li&gt;
&lt;li&gt;复制集操作&lt;/li&gt;
&lt;li&gt;复制集成员角色&lt;/li&gt;
&lt;li&gt;复制集高可用&lt;/li&gt;
&lt;li&gt;复制集数据同步机制 oplog&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&quot;复制集架构&quot;&gt;复制集架构&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;在</summary>
      
    
    
    
    <category term="IT学习笔记" scheme="https://jxch.github.io/categories/IT%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="MongoDB" scheme="https://jxch.github.io/tags/MongoDB/"/>
    
  </entry>
  
  <entry>
    <title>MongoDB-分片集</title>
    <link href="https://jxch.github.io/2024/09/06/architect/mongodb/mongodb-fen-pian-ji/"/>
    <id>https://jxch.github.io/2024/09/06/architect/mongodb/mongodb-fen-pian-ji/</id>
    <published>2024-09-06T01:18:49.000Z</published>
    <updated>2024-09-06T01:21:50.830Z</updated>
    
    <content type="html"><![CDATA[<ul><li>分片集群架构</li><li>分片策略</li><li>数据均衡</li></ul><hr><h2 id="分片集群架构">分片集群架构</h2><ul><li>使用分片的场景<ul><li>存储容量需求超出单机的磁盘容量</li><li>活跃的数据集超出单机内存容量，导致很多请求都要从磁盘读取数据</li><li>写IOPS超出单个MongoDB节点的写服务能力</li></ul></li><li>MongoDB&nbsp;分片集群架构（Sharded&nbsp;Cluster）：水平扩展<ul><li>在分片模式下，存储不同的切片数据的节点被称为分片节点，除了分片节点，集群中还需要一些配置节点、路由节点，以保证分片机制的正常运作<ul><li><img src="/static/IT/MongoDB/MongoDB-%E5%88%86%E7%89%87%E9%9B%86-1.png" alt="MongoDB&nbsp;分片集群架构"></li></ul></li></ul></li><li>核心概念<ul><li>数据分片<ul><li>分片用于存储真正的数据，并提供最终的数据读写访问。分片仅仅是一个逻辑的概念，它可以是一个单独的mongod实例，也可以是一个复制集</li><li>在生产环境中也一般会使用复制集的方式，这是为了防止数据节点出现单点故障</li></ul></li><li>配置服务器（Config&nbsp;Server）<ul><li>配置服务器包含多个节点，并组成一个复制集结构</li><li>配置复制集中保存了整个分片集群中的元数据，其中包含各个集合的分片策略，以及分片的路由表等</li></ul></li><li>查询路由（mongos）<ul><li>mongos是分片集群的访问入口，其本身并不持久化数据</li><li>mongos启动后，会从配置服务器中加载元数据</li><li>之后mongos开始提供访问服务，并将用户的请求正确路由到对应的分片</li><li>在分片集群中可以部署多个mongos以分担客户端请求的压力</li></ul></li></ul></li><li>使用分片集群<ul><li><code>sh.enableSharding("shop")</code> 先开启database的分片功能</li><li><code>sh.shardCollection("shop.product",{productId:"hashed"},false,{numInitialChunks:4})</code><ul><li>对集合执行分片初始化</li><li>shop.product集合将productId作为分片键，并采用了哈希分片策略</li><li>“numInitialChunks：4”表示将初始化4个chunk</li><li>numInitialChunks 必须和哈希分片策略配合使用</li><li>这个选项只能用于空的集合，如果已经存在数据则会返回错误</li></ul></li></ul></li><li>查询数据分布 <code>db.product.getShardDistribution()</code></li><li>chunk的意思是数据块，一个chunk代表了集合中的“一段数据”<ul><li>chunk所描述的是范围区间，就是分片键各个值（或哈希值）的连续区间</li><li>集群在操作分片集合时，会根据分片键找到对应的chunk，并向该chunk所在的分片发起操作请求</li><li>chunk的分布在一定程度上会影响数据的读写路径，这由以下两点决定<ul><li>chunk的切分方式，决定如何找到数据所在的chunk</li><li>chunk的分布状态，决定如何找到chunk所在的分片</li></ul></li></ul></li></ul><hr><h2 id="分片策略">分片策略</h2><ul><li>分片算法：chunk切分是根据分片策略进行实施的，分片策略的内容包括分片键和分片算法<ul><li>范围分片（range&nbsp;sharding）：范围分片能很好地满足范围查询的需求<ul><li>缺点在于，如果Shard&nbsp;Key有明显递增（或者递减）趋势，则新插入的文档会分布到同一个chunk，此时写压力会集中到一个节点，从而导致单点的性能瓶颈<ul><li>时间值；ObjectId，自动生成的_id由时间、计数器组成；UUID，包含系统时间、时钟序列；自增整数序列</li></ul></li></ul></li><li>哈希分片（hash&nbsp;sharding）：适用于日志，物联网等高并发场景<ul><li>事先根据分片键计算出一个新的哈希值（64位整数），再根据哈希值按照范围分片的策略进行chunk的切分</li><li><img src="/static/IT/MongoDB/MongoDB-%E5%88%86%E7%89%87%E9%9B%86-2.png" alt="哈希分片"></li><li>哈希分片与范围分片是互补的（哈希分片的离散性既是优点也是缺点）<ul><li>由于哈希算法保证了随机性，所以文档可以更加离散地分布到多个chunk上，这避免了集中写问题</li><li>然而，在执行一些范围查询时，哈希分片并不是高效的（离散）</li></ul></li></ul></li><li>哈希分片只能选择单个字段，而范围分片允许采用组合式的多字段作为分片键<ul><li>4.4&nbsp;以后的版本，可以将单个字段的哈希分片和一个到多个的范围分片键字段来进行组合<ul><li><code>{x:1&nbsp;,&nbsp;y:"hashed"}</code></li></ul></li></ul></li></ul></li><li>分片标签：MongoDB允许通过为分片添加标签（tag）的方式来控制数据分发<ul><li>一个标签可以关联到多个分片区间（TagRange）<ul><li>均衡器会优先考虑chunk是否正处于某个分片区间上（被完全包含）；意思是当前的chunk是不是在某个分片区间上被完全包含了（可以关联多个分片区间）<ul><li>如果是则会将chunk迁移到分片区间所关联的分片，否则按一般情况处理</li></ul></li></ul></li><li>分片标签适用于一些特定的场景<ul><li>集群中可能同时存在OLTP和OLAP处理<ul><li>一些系统日志的重要性相对较低，而且主要以少量的统计分析为主</li><li>为了便于单独扩展，我们可能希望将日志与实时类的业务数据分开，此时就可以使用标签</li></ul></li></ul></li><li><code>sh.addShardTag("shard01","oltp")</code> 让分片拥有指定的标签</li><li><code>sh.addTagRange("main.devices",{shardKey:MinKey},{shardKey:MaxKey},"oltp")</code> 指定分片标签</li></ul></li><li>分片键（ShardKey）的选择<ul><li>在选择分片键时，需要根据业务的需求及范围分片、哈希分片的不同特点进行权衡</li><li>在设计分片键时需要考虑的因素包括<ul><li>分片键的基数（cardinality），取值基数越大越有利于扩展</li><li>分片键的取值分布应该尽可能均匀</li><li>业务读写模式，尽可能分散写压力，而读操作尽可能来自一个或少量的分片</li><li>分片键应该能适应大部分的业务操作</li></ul></li></ul></li><li>分片键（ShardKey）的约束：ShardKey&nbsp;必须是一个索引<ul><li>非空集合须在&nbsp;ShardCollection&nbsp;前创建索引</li><li>空集合&nbsp;ShardCollection&nbsp;自动创建索引</li><li>ShardKey&nbsp;大小无限制</li><li>支持复合哈希分片键</li><li>Document&nbsp;中可以不包含&nbsp;ShardKey，插入时被当&nbsp;做&nbsp;Null&nbsp;处理</li><li>为&nbsp;ShardKey&nbsp;添加后缀&nbsp;refineCollectionShardKey&nbsp;命令，可以修改&nbsp;ShardKey&nbsp;包含的&nbsp;Field</li><li>如果&nbsp;ShardKey&nbsp;为非 <code>_ID</code>&nbsp;字段，&nbsp;那么可以修改&nbsp;ShardKey&nbsp;对应的值</li></ul></li></ul><hr><h2 id="数据均衡">数据均衡</h2><ul><li>均衡的方式：为了保证分片集群的水平扩展能力，业务数据应当尽可能地保持均匀分布<ul><li>所有的数据应均匀地分布于不同的chunk上（由业务场景和分片策略来决定）</li><li>每个分片上的chunk数量尽可能是相近的<ul><li>手动均衡<ul><li>可以在初始化集合时预分配一定数量的chunk（仅适用于哈希分片）</li><li>可以通过splitAt、moveChunk命令进行手动切分、迁移</li></ul></li><li>自动均衡：开箱即用<ul><li>均衡器会在后台对各分片的chunk进行监控，一旦发现了不均衡状态就会自动进行chunk的搬迁以达到均衡</li></ul></li></ul></li></ul></li><li>chunk 不均衡通常来自于两方面的因素<ul><li>在没有人工干预的情况下，chunk会持续增长并产生分裂（split），而不断分裂的结果就会出现数量上的不均衡</li><li>在动态增加分片服务器时，也会出现不均衡的情况</li></ul></li><li>chunk 分裂：默认情况下，一个chunk的大小为64MB，该参数由配置的chunksize参数指定<ul><li>如果持续地向该chunk写入数据，并导致数据量超过了chunk大小，则MongoDB会自动进行分裂，将该chunk切分为两个相同大小的chunk<ul><li><img src="/static/IT/MongoDB/MongoDB-%E5%88%86%E7%89%87%E9%9B%86-3.png" alt="chunk 分裂"></li></ul></li><li>chunk分裂是基于分片键进行的，如果分片键的基数太小，则可能因为无法分裂而会出现 jumbo&nbsp;chunk（超大块）的问题<ul><li>jumbo&nbsp;chunk对水平扩展有负面作用，该情况不利于数据的均衡，业务上应尽可能避免</li></ul></li></ul></li><li>写入压力过大的情况可能会导致chunk多次失败（split）<ul><li>最终当chunk中的文档数大于<code>1.3×avgObjectSize</code>时会导致无法迁移</li></ul></li><li>自动均衡<ul><li>MongoDB的数据均衡器运行于Primary&nbsp;Config&nbsp;Server（配置服务器的主节点）上，而该节点也同时会控制chunk数据的搬迁流程<ul><li><img src="/static/IT/MongoDB/MongoDB-%E5%88%86%E7%89%87%E9%9B%86-4.png" alt="自动均衡"></li><li>分片shard0在持续的业务写入压力下，产生了chunk分裂</li><li>分片服务器通知Config&nbsp;Server进行元数据更新</li><li>Config&nbsp;Server的自动均衡器对chunk分布进行检查，发现shard0和shard1的chunk数差异达到了阈值<ul><li>向shard0下发moveChunk命令以执行chunk迁移</li></ul></li><li>shard0执行指令，将指定数据块复制到shard1<ul><li>该阶段会完成索引、chunk数据的复制</li><li>整个过程中业务侧对数据的操作仍然会指向shard0</li><li>在第一轮复制完毕之后，目标shard1会向shard0确认是否还存在增量更新的数据<ul><li>如果存在则继续复制</li></ul></li></ul></li><li>shard0完成迁移后发送通知，此时Config&nbsp;Server开始更新元数据库，将chunk的位置更新为目标shard1<ul><li>在更新完元数据库后并确保没有关联cursor的情况下，shard0会删除被迁移的chunk副本</li></ul></li><li>Config&nbsp;Server通知mongos服务器更新路由表<ul><li>新的业务请求将被路由到shard1</li></ul></li></ul></li></ul></li><li>迁移阈值：均衡器对于数据的“不均衡状态”判定是根据两个分片上的chunk个数差异来进行的<ul><li>chunk个数少于20 迁移阈值 2</li><li>chunk个数20～79 迁移阈值 4</li><li>chunk个数80及以上 迁移阈值 8</li></ul></li><li>迁移速度：整个过程并不是很快<ul><li><code>_secondaryThrottle</code>：用于调整迁移数据写到目标分片的安全级别（默认设定为 false）<ul><li>如果没有设定，则会使用<code>w:2</code>选项，即至少一个备节点确认写入迁移数据后才算成功</li><li>MongoDB&nbsp;3.4版本开始，<code>_secondaryThrottle</code>被默认设定为false，chunk迁移不再等待备节点写入确认</li></ul></li><li><code>_waitForDelete</code>：在chunk迁移完成后，源分片会将不再使用的chunk删除（默认设定为 false）<ul><li>如果<code>_waitForDelete</code>是true，那么均衡器需要等待chunk同步删除后才进行下一次迁移</li><li>该选项默认为false，这意味着对于旧chunk的清理是异步进行的</li></ul></li><li>并行迁移数量：允许n个分片的集群同时执行n/2个并发任务</li><li>从MongoDB&nbsp;4.0版本开始，支持在迁移数据的过程中并发地读取源端和写入目标端<ul><li>使得新加入的分片能更快地分担集群的访问读写压力</li></ul></li></ul></li><li>数据均衡带来的问题：会影响性能<ul><li>在分片间进行数据块的迁移是一个“繁重”的工作，很容易带来磁盘I/O使用率飙升，或业务时延陡增等一些问题<ul><li>提升磁盘能力</li><li>将数据均衡的窗口对齐到业务的低峰期以降低影响<ul><li><code>use&nbsp;config</code></li><li><code>sh.setBalancerState(true)</code></li><li><code>db.settings.update({_id:"balancer"},{$set:{activeWindow:{start:"02:00",stop:"04:00"}}},{upsert:true})</code><ul><li>启用了自动均衡器，同时在每天的凌晨2点到4点运行数据均衡操作</li></ul></li></ul></li></ul></li><li>对分片集合中执行count命令可能会产生不准确的结果<ul><li>mongos在处理count命令时会分别向各个分片发送请求，并累加最终的结果<ul><li>如果分片上正在执行数据迁移，则可能导致重复的计算</li></ul></li><li>替代办法是使用<code>db.collection.countDocuments({})</code>方法<ul><li>该方法会执行聚合操作进行实时扫描，可以避免元数据读取的问题，但需要更长时间</li></ul></li></ul></li><li>在执行数据库备份的期间，不能进行数据均衡操作，会产生不一致的备份数据<ul><li>在备份操作之前，可以通过如下命令确认均衡器的状态<ul><li><code>sh.getBalancerState()</code>：查看均衡器是否开启</li><li><code>sh.isBalancerRunning()</code>：查看均衡器是否正在运行</li><li><code>sh.getBalancerWindow()</code>：查看当前均衡的窗口设定</li></ul></li></ul></li></ul></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;ul&gt;
&lt;li&gt;分片集群架构&lt;/li&gt;
&lt;li&gt;分片策略&lt;/li&gt;
&lt;li&gt;数据均衡&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&quot;分片集群架构&quot;&gt;分片集群架构&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;使用分片的场景
&lt;ul&gt;
&lt;li&gt;存储容量需求超出单机的磁盘容量&lt;/li&gt;
&lt;li&gt;活</summary>
      
    
    
    
    <category term="IT学习笔记" scheme="https://jxch.github.io/categories/IT%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="MongoDB" scheme="https://jxch.github.io/tags/MongoDB/"/>
    
  </entry>
  
  <entry>
    <title>MongoDB-调优</title>
    <link href="https://jxch.github.io/2024/09/06/architect/mongodb/mongodb-diao-you/"/>
    <id>https://jxch.github.io/2024/09/06/architect/mongodb/mongodb-diao-you/</id>
    <published>2024-09-06T01:13:49.000Z</published>
    <updated>2024-09-06T01:15:18.111Z</updated>
    
    <content type="html"><![CDATA[<ul><li>影响 MongoDB 性能的因素</li><li>MongoDB 性能监控工具：mongostat；mongotop；Profiler；<code>db.currentOp()</code></li></ul><hr><h2 id="影响-MongoDB-性能的因素">影响 MongoDB 性能的因素</h2><ul><li>导致MongoDB性能不佳的原因<ul><li>慢查询；阻塞等待（通常是因为模型/索引设计不佳导致的）</li><li>硬件资源不足</li></ul></li><li>影响MongoDB性能的因素<ul><li><img src="/static/IT/MongoDB/MongoDB-%E8%B0%83%E4%BC%98-1.png" alt="影响MongoDB性能的因素"></li></ul></li><li>MongoDB 优化建模<ul><li>使用数组索引区分不同的属性，比如一张电影票在不同影院的价格，用户查最优价格的时候就可以使用数组索引</li><li>对数据的分段存储<ul><li>比如高频时序数据，那么可以利用嵌套文档把每秒钟的数据单独存放为一个属性，然后把每分钟的数据单独存放为一个文档（恰好WiredTiger是每分钟进行一次刷盘）</li></ul></li></ul></li></ul><hr><h2 id="MongoDB-性能监控工具">MongoDB 性能监控工具</h2><ul><li>mongostat：可以提供数据库节点或者整个集群当前的状态视图（当前的QPS/内存使用/连接数，以及多个分片的压力分布），采用Go语言实现，其内部使用了<code>db.serverStatus()</code>命令，要求执行用户需具备clusterMonitor角色权限<ul><li><code>mongostat -h 192.168.65.174 --port 28017 -ufox -pfox --authenticationDatabase=admin --discover -n 300 2</code><ul><li><code>--discover</code>：启用自动发现，可展示集群中所有分片节点的状态</li><li><code>-n 300 2</code>：表示输出300次，每次间隔2s。也可以不指定<code>-n 300</code>，此时会一直保持输出</li></ul></li><li>需要关注的指标主要有<ul><li>插入、删除、修改、查询的速率是否产生较大波动，是否超出预期</li><li>qrw、arw：队列是否较高，若长时间大于0则说明此时读写速度较慢<ul><li><code>qrw</code> 客户端读写等待队列数量，高并发时，一般队列值会升高</li><li><code>arw</code> 客户端读写活跃个数</li></ul></li><li>conn：连接数是否太多<ul><li><code>conn</code> 当前连接数</li></ul></li><li>dirty：百分比是否较高，若持续高于10%则说明磁盘I/O存在瓶颈<ul><li><code>%dirty</code> WiredTiger 缓存中脏数据百分比</li><li><code>%used</code> WiredTiger 正在使用的缓存百分比</li></ul></li><li>netIn、netOut：是否超过网络带宽阈值<ul><li><code>netIn</code> 网络接收数据量</li><li><code>netOut</code> 网络发送数据量</li></ul></li><li>repl：状态是否异常，如PRI、SEC、RTR为正常，若出现REC等异常值则需要修复<ul><li><code>repl</code> 复制节点状态（主节点/二级节点……)</li></ul></li></ul></li><li><code>--interactive</code>选项，用来实现非滚动式的监视（交互模式）<ul><li><code>mongostat -h 192.168.65.174 --port 28017 -ufox -pfox --authenticationDatabase=admin --discover --interactive -n 2</code></li></ul></li></ul></li><li>mongotop：可用于查看数据库的热点表，可以判定是哪些集合占用了大部分读写时间，mongotop与mongostat的实现原理类似，同样需要clusterMonitor角色权限<ul><li><code>mongotop -h 192.168.65.174 --port=28017 -ufox -pfox --authenticationDatabase=admin</code><ul><li>默认情况下，mongotop会持续地每秒输出当前的热点表</li></ul></li><li>需要关注的因素主要有<ul><li>热点表操作耗费时长是否过高<ul><li>这里的时长是在一定的时间间隔内的统计值，它代表某个集合读写操作所耗费的时间总量</li><li>在业务高峰期时，核心表的读写操作一般比平时高一些，通过mongotop的输出可以对业务尖峰做出一些判断</li></ul></li><li>是否存在非预期的热点表。一些慢操作导致的性能问题可以从mongotop的结果中体现出来</li></ul></li><li><code>mongotop -h 192.168.65.174 --port=28017 -ufox -pfox --authenticationDatabase=admin -n 100 2</code><ul><li>最多输出100次，每次间隔时间为2s</li></ul></li></ul></li><li>Profiler：可以用来记录、分析MongoDB的详细操作日志。默认情况下该功能是关闭的，对某个业务库开启Profiler模块之后，符合条件的慢操作日志会被写入该库的system.profile集合中<ul><li>提供了几种调试级别<ul><li>0 日志关闭，无任何输出</li><li>1 部分开启，仅符合条件（时长大于slowms）的操作日志会被记录</li><li>2 日志全开，所有的操作日志都被记录</li></ul></li><li><code>db.setProfilingLevel(2)</code> 对当前的数据库开启 Profiler 模块，并将 level 设置为2（日志全开）</li><li><code>db.getProfilingStatus()</code> 检查是否生效<ul><li>slowms 是慢操作的阈值，单位是毫秒</li><li>sampleRate 表示日志随机采样的比例，1.0则表示满足条件的全部输出</li></ul></li><li><code>db.setProfilingLevel(1,500)</code> 只记录时长超过500ms的操作，则可以将level设置为1</li><li><code>db.setProfilingLevel(1,{slowms:500,sampleRate:0.5})</code> 设置随机采样的比例</li><li><code>db.system.profile.find().limit(5).sort({ts:-1}).pretty()</code> 查看最近发生的操作日志<ul><li>ns：名称空间，格式为 <code>{db}.{collection}</code></li><li>numYield：操作数，大于0表示等待锁或者是磁盘I/O操作</li><li>nreturned：返回条目数</li><li>keysExamined：扫描索引条目数，如果比nreturned大出很多，则说明查询效率不高</li><li>docsExamined：扫描文档条目数，如果比nreturned大出很多，则说明查询效率不高</li><li>locks：锁占用的情况</li><li>responseLength：响应数据大小（字节数），一次性查询太多的数据会影响性能，可以使用limit、batchSize进行一些限制</li><li>ts：命令执行的时间点</li></ul></li><li><code>db.system.profile.find().limit(10).sort({millis:-1}).pretty()</code> 查看执行时长最大的10条操作记录</li><li><code>db.system.profile.find({op:"update",ns:"shop.user"})</code> 查看某个集合中的update操作日志</li><li>注意事项<ul><li>system.profile是一个1MB的固定大小的集合，随着记录日志的增多，一些旧的记录会被滚动删除</li><li>在线上开启Profiler模块需要非常谨慎，这是因为其对MongoDB的性能影响比较大。建议按需部分开启，同时slowms的值不要设置太低</li><li>sampleRate的默认值是1.0，该字段可以控制记录日志的命令数比例，但只有在MongoDB 4.0版本之后才支持</li><li>Profiler模块的设置是内存级的，重启服务器后会自动恢复默认状态</li></ul></li></ul></li><li><code>db.currentOp()</code> 用来查看数据库当前正在执行的一些操作，读取的是当前数据库的命令快照<ul><li>返回有用的信息<ul><li>操作的运行时长，快速发现耗时漫长的低效扫描操作</li><li>执行计划信息，用于判断是否命中了索引，或者存在锁冲突的情况</li><li>操作ID、时间、客户端等信息，方便定位出产生慢操作的源头</li></ul></li><li>优化<ul><li>字段加索引</li><li>如果更新的数据集非常大，要避免大范围update操作，切分成小批量的操作</li></ul></li><li><code>db.killOp(4001)</code><ul><li>opid表示当前操作在数据库进程中的唯一编号</li><li>如果已经发现该操作正在导致数据库系统响应缓慢，则可以考虑将其“杀”死</li></ul></li><li>命令输出<ul><li>currentOp.type：操作类型，可以是op、idleSession、idleCursor的一种，一般的操作信息以op表示</li><li>currentOp.currentOpTime：操作的开始时间</li><li>currentOp.opid：操作的标志编号</li><li>currentOp.active：操作是否活跃。如果是空闲状态则为false</li><li>currentOp.secs_running：操作持续时间（以秒为单位）</li><li>currentOp.ns：操作目标的集合命名空间</li><li>currentOp.locks：当前操作持有锁的类型和模式</li><li>currentOp.waitingForLock：是否正在等待锁</li><li>currentOp.numYields：当前操作执行yield的次数。一些锁互斥或者磁盘I/O读取都会导致该值大于0</li><li>currentOp.lockStats：当前操作持有锁的统计</li></ul></li><li>注意事项<ul><li>db.currentOp返回的是数据库命令的瞬时状态，因此如果数据库压力不大，则通常只会返回极少的结果</li><li>如果启用了复制集，那么currentOp还会返回一些复制的内部操作（<a href="http://xn--local-my8im294a.oplog.rs">针对local.oplog.rs</a>），需要筛选</li><li>db.currentOp的结果是一个BSON文档，如果大小超过16MB则会被压缩。可以使用聚合操作<code>$currentOp</code>获得完整的结果</li></ul></li></ul></li><li><code>db.currentOp()</code> 过滤条件<ul><li><code>db.currentOp({ secs_running:{$gt:1} })</code>  查看执行时间超过1s的操作</li><li><code>db.currentOp({ ns:/test/ })</code> 查看test数据库中的操作</li><li>查看等待锁的增加、删除、修改、查询操作<ul><li><code>db.currentOp({  waitingForLock:true, $or:[ </code><ul><li><code>{op:{$in:["insert","update","remove"]}},{"query.findandmodify":{$exists:true}}]})</code></li></ul></li></ul></li></ul></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;ul&gt;
&lt;li&gt;影响 MongoDB 性能的因素&lt;/li&gt;
&lt;li&gt;MongoDB 性能监控工具：mongostat；mongotop；Profiler；&lt;code&gt;db.currentOp()&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&quot;影响-MongoDB</summary>
      
    
    
    
    <category term="IT学习笔记" scheme="https://jxch.github.io/categories/IT%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="MongoDB" scheme="https://jxch.github.io/tags/MongoDB/"/>
    
  </entry>
  
  <entry>
    <title>Kafka-代码模板</title>
    <link href="https://jxch.github.io/2024/09/04/architect/kafka/kafka-dai-ma-mo-ban/"/>
    <id>https://jxch.github.io/2024/09/04/architect/kafka/kafka-dai-ma-mo-ban/</id>
    <published>2024-09-04T02:32:49.000Z</published>
    <updated>2024-09-04T02:37:22.842Z</updated>
    
    <content type="html"><![CDATA[<ul><li>配置：<code>server.properties</code></li><li>绑定Kafka服务器</li><li>生产者配置</li><li>生产者发送消息</li><li>消费配置</li><li>消费者接收消息</li><li>消费提交</li><li>springboot 集成<ul><li>ack‐mode</li><li>生产者 &amp; 消费者</li></ul></li><li>Kafka事务</li></ul><hr><h2 id="配置：server-properties">配置：<code>server.properties</code></h2><ul><li>配置：<code>server.properties</code></li></ul><pre class="line-numbers language-properties" data-language="properties"><code class="language-properties"><span class="token comment">#broker.id属性在kafka集群中必须要是唯一</span><span class="token key attr-name">broker.id</span><span class="token punctuation">=</span><span class="token value attr-value">0</span><span class="token comment">#kafka部署的机器ip和提供服务的端口号</span><span class="token key attr-name">listeners</span><span class="token punctuation">=</span><span class="token value attr-value">PLAINTEXT://192.168.65.60:9092</span><span class="token comment">#kafka的消息存储文件</span><span class="token key attr-name">log.dir</span><span class="token punctuation">=</span><span class="token value attr-value">/usr/local/data/kafka‐logs</span><span class="token comment">#kafka连接zookeeper的地址</span><span class="token key attr-name">zookeeper.connect</span><span class="token punctuation">=</span><span class="token value attr-value">192.168.65.60:2181</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="绑定Kafka服务器">绑定Kafka服务器</h2><ul><li>绑定Kafka服务器</li></ul><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token class-name">Properties</span> props <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Properties</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ProducerConfig</span><span class="token punctuation">.</span><span class="token constant">BOOTSTRAP_SERVERS_CONFIG</span><span class="token punctuation">,</span> <span class="token string">"192.168.65.60:9092,192.168.65.60:9093,192.168.65.60:9094"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 生产者</span><span class="token class-name">Producer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> producer <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">KafkaProducer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span>props<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 消费者</span><span class="token class-name">KafkaConsumer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> consumer <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">KafkaConsumer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span>props<span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="生产者配置">生产者配置</h2><ul><li>生产者配置</li></ul><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token comment">/*  * 发出消息持久化机制参数 * acks=0： 表示producer不需要等待任何broker确认收到消息的回复，就可以继续发送下一条消息。性能最高，但是最容易丢消息 * acks=1： 至少要等待leader已经成功将数据写入本地log，但是不需要等待所有follower是否成功写入，就可以继续发送下一条消息 *          如果follower没有成功备份数据，而此时leader又挂掉，则消息会丢失 * acks=‐1或all： 需要等待 min.insync.replicas(默认为1，推荐配置大于等于2) 这个参数配置的副本个数都成功写入日志 *                这种策略会保证只要有一个备份存活就不会丢失数据。这是最强的数据保证。一般除非是金融级别，或跟钱打交道的场景才会使用这种配置 */</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ProducerConfig</span><span class="token punctuation">.</span><span class="token constant">ACKS_CONFIG</span><span class="token punctuation">,</span> <span class="token string">"1"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 发送失败重试次数，重试能保证消息发送的可靠性，但是也可能造成消息重复发送，需要接收者做好消息接收的幂等性处理</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ProducerConfig</span><span class="token punctuation">.</span><span class="token constant">RETRIES_CONFIG</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 重试间隔设置，默认重试间隔100ms</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ProducerConfig</span><span class="token punctuation">.</span><span class="token constant">RETRY_BACKOFF_MS_CONFIG</span><span class="token punctuation">,</span> <span class="token number">300</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 设置发送消息的本地缓冲区，如果设置了该缓冲区，消息会先发送到本地缓冲区，可以提高消息发送性能，默认值是33554432，即32MB</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ProducerConfig</span><span class="token punctuation">.</span><span class="token constant">BUFFER_MEMORY_CONFIG</span><span class="token punctuation">,</span> <span class="token number">33554432</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// kafka本地线程会从缓冲区取数据，批量发送到broker，设置批量发送消息的大小，默认值是16384，即16kb，就是说一个batch满了16kb就发送出去</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ProducerConfig</span><span class="token punctuation">.</span><span class="token constant">BATCH_SIZE_CONFIG</span><span class="token punctuation">,</span> <span class="token number">16384</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">/*  * batch最大的延迟发送时间 * 默认值是0：意思就是消息必须立即被发送，但这样会影响性能 * 一般设置10毫秒左右，就是说这个消息发送完后会进入本地的一个batch，如果10毫秒内，这个batch满了16kb就会随batch一起被发送出去 * 如果10毫秒内，batch没满，那么也必须把消息发送出去，不能让消息的发送延迟时间太长 *  *  消息 -&gt; 本地缓冲区（32M）-&gt; batch（16k）-&gt; 发送（10ms batch不满也发送） */</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ProducerConfig</span><span class="token punctuation">.</span><span class="token constant">LINGER_MS_CONFIG</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 把发送的key和value从字符串序列化为字节数组</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ProducerConfig</span><span class="token punctuation">.</span><span class="token constant">KEY_SERIALIZER_CLASS_CONFIG</span><span class="token punctuation">,</span> <span class="token class-name">StringSerializer</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">.</span><span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ProducerConfig</span><span class="token punctuation">.</span><span class="token constant">VALUE_SERIALIZER_CLASS_CONFIG</span><span class="token punctuation">,</span> <span class="token class-name">StringSerializer</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">.</span><span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="生产者发送消息">生产者发送消息</h2><ul><li>生产者发送消息：指定分区；不指定分区；同步；异步</li></ul><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token comment">// 指定发送分区</span><span class="token keyword">var</span> producerRecord <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ProducerRecord</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span><span class="token constant">TOPIC_NAME</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> key_json<span class="token punctuation">,</span> value_json<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 未指定发送分区，具体发送的分区计算公式：hash(key) % partitionNum</span><span class="token keyword">var</span> producerRecord <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ProducerRecord</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span><span class="token constant">TOPIC_NAME</span><span class="token punctuation">,</span> key_json<span class="token punctuation">,</span> value_json<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 等待消息发送成功的同步阻塞方法</span><span class="token class-name">RecordMetadata</span> metadata <span class="token operator">=</span> producer<span class="token punctuation">.</span><span class="token function">send</span><span class="token punctuation">(</span>producerRecord<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 异步回调方式发送消息</span>producer<span class="token punctuation">.</span><span class="token function">send</span><span class="token punctuation">(</span>producerRecord<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Callback</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span><span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">onCompletion</span><span class="token punctuation">(</span><span class="token class-name">RecordMetadata</span> metadata<span class="token punctuation">,</span> <span class="token class-name">Exception</span> exception<span class="token punctuation">)</span> <span class="token punctuation">{</span><span class="token comment">// 处理异常</span><span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 关闭</span>producer<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="消费配置">消费配置</h2><ul><li>消费配置</li></ul><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token comment">// 消费分组名</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ConsumerConfig</span><span class="token punctuation">.</span><span class="token constant">GROUP_ID_CONFIG</span><span class="token punctuation">,</span> <span class="token constant">CONSUMER_GROUP_NAME</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 是否自动提交offset，默认就是true</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ConsumerConfig</span><span class="token punctuation">.</span><span class="token constant">ENABLE_AUTO_COMMIT_CONFIG</span><span class="token punctuation">,</span> <span class="token string">"true"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 自动提交offset的间隔时间</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ConsumerConfig</span><span class="token punctuation">.</span><span class="token constant">AUTO_COMMIT_INTERVAL_MS_CONFIG</span><span class="token punctuation">,</span> <span class="token string">"1000"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">/*  * 当消费主题的是一个新的消费组，或者指定offset的消费方式，offset不存在，那么应该如何消费 * latest(默认) ：只消费自己启动之后发送到主题的消息 * earliest：第一次从头开始消费，以后按照消费offset记录继续消费，这个需要区别于 consumer.seekToBeginning(每次都从头开始消费) */</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ConsumerConfig</span><span class="token punctuation">.</span><span class="token constant">AUTO_OFFSET_RESET_CONFIG</span><span class="token punctuation">,</span> <span class="token string">"earliest"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// consumer给broker发送心跳的间隔时间，broker接收到心跳如果此时有rebalance发生会通过心跳响应将rebalance方案下发给consumer，这个时间可以稍微短一点</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ConsumerConfig</span><span class="token punctuation">.</span><span class="token constant">HEARTBEAT_INTERVAL_MS_CONFIG</span><span class="token punctuation">,</span> <span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 服务端broker多久感知不到一个consumer心跳就认为他故障了，会将其踢出消费组，对应的Partition也会被重新分配给其他consumer，默认是10秒</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ConsumerConfig</span><span class="token punctuation">.</span><span class="token constant">SESSION_TIMEOUT_MS_CONFIG</span><span class="token punctuation">,</span> <span class="token number">10</span> <span class="token operator">*</span> <span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 一次poll最大拉取消息的条数，如果消费者处理速度很快，可以设置大点，如果处理速度一般，可以设置小点</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ConsumerConfig</span><span class="token punctuation">.</span><span class="token constant">MAX_POLL_RECORDS_CONFIG</span><span class="token punctuation">,</span> <span class="token number">500</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 如果两次poll操作间隔超过了这个时间，broker就会认为这个consumer处理能力太弱，会将其踢出消费组，将分区分配给别的consumer消费</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ConsumerConfig</span><span class="token punctuation">.</span><span class="token constant">MAX_POLL_INTERVAL_MS_CONFIG</span><span class="token punctuation">,</span> <span class="token number">30</span> <span class="token operator">*</span> <span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 把发送的key和value从字符串序列化为字节数组</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ConsumerConfig</span><span class="token punctuation">.</span><span class="token constant">KEY_DESERIALIZER_CLASS_CONFIG</span><span class="token punctuation">,</span> <span class="token class-name">StringDeserializer</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">.</span><span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ConsumerConfig</span><span class="token punctuation">.</span><span class="token constant">VALUE_DESERIALIZER_CLASS_CONFIG</span><span class="token punctuation">,</span> <span class="token class-name">StringDeserializer</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">.</span><span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="消费者接收消息">消费者接收消息</h2><ul><li>消费者接收消息（topic）：指定分区；回溯（从头，指定offset）；拉取集合</li></ul><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token comment">// 订阅Topic</span>consumer<span class="token punctuation">.</span><span class="token function">subscribe</span><span class="token punctuation">(</span><span class="token class-name">Arrays</span><span class="token punctuation">.</span><span class="token function">asList</span><span class="token punctuation">(</span><span class="token constant">TOPIC_NAME</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 消费指定分区</span>consumer<span class="token punctuation">.</span><span class="token function">assign</span><span class="token punctuation">(</span><span class="token class-name">Arrays</span><span class="token punctuation">.</span><span class="token function">asList</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">TopicPartition</span><span class="token punctuation">(</span><span class="token constant">TOPIC_NAME</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 回溯消费（从头消费 - seekToBeginning）</span>consumer<span class="token punctuation">.</span><span class="token function">assign</span><span class="token punctuation">(</span><span class="token class-name">Arrays</span><span class="token punctuation">.</span><span class="token function">asList</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">TopicPartition</span><span class="token punctuation">(</span><span class="token constant">TOPIC_NAME</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>consumer<span class="token punctuation">.</span><span class="token function">seekToBeginning</span><span class="token punctuation">(</span><span class="token class-name">Arrays</span><span class="token punctuation">.</span><span class="token function">asList</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">TopicPartition</span><span class="token punctuation">(</span><span class="token constant">TOPIC_NAME</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 指定offset消费</span>consumer<span class="token punctuation">.</span><span class="token function">assign</span><span class="token punctuation">(</span><span class="token class-name">Arrays</span><span class="token punctuation">.</span><span class="token function">asList</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">TopicPartition</span><span class="token punctuation">(</span><span class="token constant">TOPIC_NAME</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>consumer<span class="token punctuation">.</span><span class="token function">seek</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">TopicPartition</span><span class="token punctuation">(</span><span class="token constant">TOPIC_NAME</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 从指定时间点开始消费 - 1小时前</span><span class="token class-name">List</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">PartitionInfo</span><span class="token punctuation">&gt;</span></span> topicPartitions <span class="token operator">=</span> consumer<span class="token punctuation">.</span><span class="token function">partitionsFor</span><span class="token punctuation">(</span><span class="token constant">TOPIC_NAME</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">long</span> fetchDataTime <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Date</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">getTime</span><span class="token punctuation">(</span><span class="token punctuation">)</span> ‐ <span class="token number">1000</span> <span class="token operator">*</span> <span class="token number">60</span> <span class="token operator">*</span> <span class="token number">60</span><span class="token punctuation">;</span><span class="token class-name">Map</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">TopicPartition</span><span class="token punctuation">,</span> <span class="token class-name">Long</span><span class="token punctuation">&gt;</span></span> map <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">HashMap</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token class-name">PartitionInfo</span> par <span class="token operator">:</span> topicPartitions<span class="token punctuation">)</span> <span class="token punctuation">{</span>map<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">TopicPartition</span><span class="token punctuation">(</span>topicName<span class="token punctuation">,</span> par<span class="token punctuation">.</span><span class="token function">partition</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> fetchDataTime<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token comment">// 遍历 value.offset(); 获取offset，然后指定offset消费</span><span class="token class-name">Map</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">TopicPartition</span><span class="token punctuation">,</span> <span class="token class-name">OffsetAndTimestamp</span><span class="token punctuation">&gt;</span></span> parMap <span class="token operator">=</span> consumer<span class="token punctuation">.</span><span class="token function">offsetsForTimes</span><span class="token punctuation">(</span>map<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 拉取消息集合</span><span class="token class-name">ConsumerRecords</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> records <span class="token operator">=</span> consumer<span class="token punctuation">.</span><span class="token function">poll</span><span class="token punctuation">(</span><span class="token class-name">Duration</span><span class="token punctuation">.</span><span class="token function">ofMillis</span><span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="消费提交">消费提交</h2><ul><li>消费提交（offset）：同步；异步</li></ul><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token comment">// 手动同步提交offset，当前线程会阻塞直到offset提交成功，一般使用同步提交，因为提交之后一般也没有什么逻辑代码了</span>consumer<span class="token punctuation">.</span><span class="token function">commitSync</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 手动异步提交offset，当前线程提交offset不会阻塞，可以继续处理后面的程序逻辑</span>consumer<span class="token punctuation">.</span><span class="token function">commitAsync</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">OffsetCommitCallback</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span><span class="token annotation punctuation">@Override</span><span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">onComplete</span><span class="token punctuation">(</span><span class="token class-name">Map</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">TopicPartition</span><span class="token punctuation">,</span> <span class="token class-name">OffsetAndMetadata</span><span class="token punctuation">&gt;</span></span> offsets<span class="token punctuation">,</span> <span class="token class-name">Exception</span> ex<span class="token punctuation">)</span> <span class="token punctuation">{</span><span class="token comment">// 处理异常</span><span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><hr><h2 id="springboot-集成">springboot 集成</h2><ul><li>springboot配置application.yml</li></ul><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token key atrule">spring</span><span class="token punctuation">:</span><span class="token key atrule">kafka</span><span class="token punctuation">:</span><span class="token key atrule">bootstrap‐servers</span><span class="token punctuation">:</span> 192.168.65.60<span class="token punctuation">:</span><span class="token number">9092</span><span class="token punctuation">,</span>192.168.65.60<span class="token punctuation">:</span><span class="token number">9093</span><span class="token punctuation">,</span>192.168.65.60<span class="token punctuation">:</span><span class="token number">9094</span><span class="token key atrule">producer</span><span class="token punctuation">:</span><span class="token key atrule">retries</span><span class="token punctuation">:</span> <span class="token number">3</span><span class="token key atrule">batch‐size</span><span class="token punctuation">:</span> <span class="token number">16384</span><span class="token key atrule">buffer‐memory</span><span class="token punctuation">:</span> <span class="token number">33554432</span><span class="token key atrule">acks</span><span class="token punctuation">:</span> <span class="token number">1</span><span class="token key atrule">key‐serializer</span><span class="token punctuation">:</span> org.apache.kafka.common.serialization.StringSerializer<span class="token key atrule">value‐serializer</span><span class="token punctuation">:</span> org.apache.kafka.common.serialization.StringSerializer<span class="token key atrule">consumer</span><span class="token punctuation">:</span><span class="token key atrule">group‐id</span><span class="token punctuation">:</span> default‐group<span class="token key atrule">enable‐auto‐commit</span><span class="token punctuation">:</span> <span class="token boolean important">false</span><span class="token key atrule">auto‐offset‐reset</span><span class="token punctuation">:</span> earliest<span class="token key atrule">key‐deserializer</span><span class="token punctuation">:</span> xxx.StringDeserializer<span class="token key atrule">value‐deserializer</span><span class="token punctuation">:</span> xxx.StringDeserializer<span class="token key atrule">listener</span><span class="token punctuation">:</span><span class="token key atrule">ack‐mode</span><span class="token punctuation">:</span> manual_immediate<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="ack‐mode">ack‐mode</h3><ul><li>ack‐mode<ul><li>RECORD：当每一条记录被消费者监听器（ListenerConsumer）处理之后提交</li><li>BATCH：当每一批poll()的数据被消费者监听器处理之后提交</li><li>TIME：当每一批poll()的数据被消费者监听器处理之后，距离上次提交时间大于TIME时提交</li><li>COUNT：当每一批poll()的数据被消费者监听器处理之后，被处理record数量大于等于COUNT时提交</li><li>TIME&nbsp;|&nbsp;COUNT：有一个条件满足时提交</li><li>MANUAL：当每一批poll()的数据被消费者监听器处理之后,&nbsp;手动调用Acknowledgment.acknowledge()后提交</li><li>MANUAL_IMMEDIATE：手动调用Acknowledgment.acknowledge()后立即提交，一般使用这种（一次提交一条消息）</li></ul></li></ul><h3 id="生产者-消费者">生产者 &amp; 消费者</h3><ul><li>生产者</li></ul><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token annotation punctuation">@Autowired</span><span class="token keyword">private</span> <span class="token class-name">KafkaTemplate</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> kafkaTemplate<span class="token punctuation">;</span>kafkaTemplate<span class="token punctuation">.</span><span class="token function">send</span><span class="token punctuation">(</span><span class="token constant">TOPIC_NAME</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token string">"key"</span><span class="token punctuation">,</span> <span class="token string">"this is a msg"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><ul><li>消费者</li></ul><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token annotation punctuation">@KafkaListener</span><span class="token punctuation">(</span>topics <span class="token operator">=</span> <span class="token string">"my‐replicated‐topic"</span><span class="token punctuation">,</span>groupId <span class="token operator">=</span> <span class="token string">"zhugeGroup"</span><span class="token punctuation">)</span><span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">listenZhugeGroup</span><span class="token punctuation">(</span><span class="token class-name">ConsumerRecord</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> record<span class="token punctuation">,</span> <span class="token class-name">Acknowledgment</span> ack<span class="token punctuation">)</span> <span class="token punctuation">{</span><span class="token class-name">String</span> value <span class="token operator">=</span> record<span class="token punctuation">.</span><span class="token function">value</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>ack<span class="token punctuation">.</span><span class="token function">acknowledge</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment">//手动提交offset</span><span class="token punctuation">}</span><span class="token comment">// 配置多个消费组（再写一个消费组处理同一个topic）</span><span class="token annotation punctuation">@KafkaListener</span><span class="token punctuation">(</span>topics <span class="token operator">=</span> <span class="token string">"my‐replicated‐topic"</span><span class="token punctuation">,</span>groupId <span class="token operator">=</span> <span class="token string">"tulingGroup"</span><span class="token punctuation">)</span><span class="token comment">// 配置多个topic，concurrency就是同组下的消费者个数，就是并发消费数，必须小于等于分区总数</span><span class="token annotation punctuation">@KafkaListener</span><span class="token punctuation">(</span>groupId <span class="token operator">=</span> <span class="token string">"testGroup"</span><span class="token punctuation">,</span> topicPartitions <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token annotation punctuation">@TopicPartition</span><span class="token punctuation">(</span>topic <span class="token operator">=</span> <span class="token string">"topic1"</span><span class="token punctuation">,</span> partitions <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">"0"</span><span class="token punctuation">,</span> <span class="token string">"1"</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token annotation punctuation">@TopicPartition</span><span class="token punctuation">(</span>topic <span class="token operator">=</span> <span class="token string">"topic2"</span><span class="token punctuation">,</span> partitions <span class="token operator">=</span> <span class="token string">"0"</span><span class="token punctuation">,</span>partitionOffsets <span class="token operator">=</span> <span class="token annotation punctuation">@PartitionOffset</span><span class="token punctuation">(</span>partition <span class="token operator">=</span> <span class="token string">"1"</span><span class="token punctuation">,</span> initialOffset <span class="token operator">=</span> <span class="token string">"100"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">,</span>concurrency <span class="token operator">=</span> <span class="token string">"6"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><hr><h2 id="Kafka事务">Kafka事务</h2><ul><li>Kafka事务</li></ul><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token class-name">Properties</span> props <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Properties</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"bootstrap.servers"</span><span class="token punctuation">,</span> <span class="token string">"localhost:9092"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"transactional.id"</span><span class="token punctuation">,</span> <span class="token string">"my‐transactional‐id"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token class-name">Producer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> producer <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">KafkaProducer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span>props<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">StringSerializer</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">StringSerializer</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 初始化事务</span>producer<span class="token punctuation">.</span><span class="token function">initTransactions</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">try</span> <span class="token punctuation">{</span><span class="token comment">// 开启事务</span>producer<span class="token punctuation">.</span><span class="token function">beginTransaction</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 发到不同的主题的不同分区</span>producer<span class="token punctuation">.</span><span class="token function">send</span><span class="token punctuation">(</span><span class="token comment">/*...*/</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 提交事务</span>producer<span class="token punctuation">.</span><span class="token function">commitTransaction</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">ProducerFencedException</span> <span class="token operator">|</span> <span class="token class-name">OutOfOrderSequenceException</span> <span class="token operator">|</span> <span class="token class-name">AuthorizationException</span> e<span class="token punctuation">)</span> <span class="token punctuation">{</span>producer<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">KafkaException</span> e<span class="token punctuation">)</span> <span class="token punctuation">{</span><span class="token comment">// 回滚事务</span>producer<span class="token punctuation">.</span><span class="token function">abortTransaction</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token comment">// 关闭</span>producer<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;ul&gt;
&lt;li&gt;配置：&lt;code&gt;server.properties&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;绑定Kafka服务器&lt;/li&gt;
&lt;li&gt;生产者配置&lt;/li&gt;
&lt;li&gt;生产者发送消息&lt;/li&gt;
&lt;li&gt;消费配置&lt;/li&gt;
&lt;li&gt;消费者接收消息&lt;/li&gt;
&lt;li&gt;消费提交&lt;</summary>
      
    
    
    
    <category term="IT学习笔记" scheme="https://jxch.github.io/categories/IT%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="Kafka" scheme="https://jxch.github.io/tags/Kafka/"/>
    
  </entry>
  
  <entry>
    <title>Kafka-优化</title>
    <link href="https://jxch.github.io/2024/09/04/architect/kafka/kafka-you-hua/"/>
    <id>https://jxch.github.io/2024/09/04/architect/kafka/kafka-you-hua/</id>
    <published>2024-09-04T02:27:49.000Z</published>
    <updated>2024-09-04T02:29:51.537Z</updated>
    
    <content type="html"><![CDATA[<ul><li>环境规划</li><li>线上问题</li><li>Kafka事务</li><li>Kafka高性能原因</li></ul><hr><h2 id="环境规划">环境规划</h2><ul><li>Kafka可视化管理工具：kafka-manager</li><li>线上环境规划<ul><li><img src="/static/IT/Kafka/Kafka-%E4%BC%98%E5%8C%96-1.png" alt="环境规划"></li></ul></li><li>JVM参数设置：bin/kafka-start-server.sh 中的jvm设置<ul><li><code>export&nbsp;KAFKA_HEAP_OPTS="‐Xmx16G&nbsp;‐Xms16G&nbsp;‐Xmn10G&nbsp;‐XX:MetaspaceSize=256M&nbsp;‐XX:+UseG1GC&nbsp;‐XX:MaxGCPauseMillis=50&nbsp;‐XX:G1HeapRegionSize=16M"</code></li><li>这种大内存的情况一般都要用G1垃圾收集器，因为年轻代内存比较大，用G1可以设置GC最大停顿时间，不至于一次minor&nbsp;gc就花费太长时间，当然，因为像kafka，rocketmq，es这些中间件，写数据到磁盘会用到操作系统的page&nbsp;cache，所以JVM内存不宜分配过大，需要给操作系统的缓存留出几个G</li></ul></li></ul><hr><h2 id="线上问题">线上问题</h2><ul><li>消息丢失<ul><li>发送端：acks 设置</li><li>消费端：如果消费这边配置的是自动提交，万一消费到数据还没处理完，就自动提交offset了，但是此时你consumer直接宕机了，未处理完的数据丢失了，下次也消费不到了</li></ul></li><li>重复消费：一般消费端都是要做消费幂等处理的<ul><li>发送端：发送消息如果配置了重试机制，比如网络抖动时间过长导致发送端发送超时，实际broker可能已经接收到消息，但发送方会重新发送消息</li><li>消费端：如果消费这边配置的是自动提交，刚拉取了一批数据处理了一部分，但还没来得及提交，服务挂了，下次重启又会拉取相同的一批数据重复处理</li></ul></li><li>消息乱序<ul><li>如果发送端配置了重试机制，kafka不会等之前那条消息完全发送成功才去发送下一条消息，这样可能会出现，发送了1，2，3条消息，第一条超时了，后面两条发送成功，再重试发送第1条消息，这时消息在broker端的顺序就是2，3，1了<ul><li>是否一定要配置重试要根据业务情况而定。也可以用同步发送的模式去发消息，当然acks不能设置为0</li></ul></li><li>kafka保证全链路消息顺序消费，需要从发送端开始，将所有有序消息发送到同一个分区，然后用一个消费者去消费，但是这种性能比较低<ul><li>可以在消费者端接收到消息后将需要保证顺序消费的几条消费发到内存队列(可以搞多个)，一个内存队列开启一个线程顺序处理消息</li></ul></li></ul></li><li>消息积压<ul><li>线上有时因为发送方发送消息速度过快，或者消费方处理消息过慢，可能会导致broker积压大量未消费消息<ul><li>如果积压了上百万未消费消息需要紧急处理，可以修改消费端程序，让其将收到的消息快速转发到其他topic(可以设置很多分区)，然后再启动多个消费者同时消费新主题的不同分区</li></ul></li><li>由于消息数据格式变动或消费者程序有bug，导致消费者一直消费不成功，也可能导致broker积压大量未消费消息<ul><li>可以将这些消费不成功的消息转发到其它队列里去(类似死信队列)，后面再慢慢分析死信队列里的消息处理问题</li></ul></li></ul></li><li>延时队列：消息被发送以后，并不想让消费者立刻获取，而是等待特定的时间后，消费者才能获取这个消息进行消费<ul><li>发送延时消息时先把消息按照不同的延迟时间段发送到指定的队列中（topic_1s，topic_5s，topic_10s，…topic_2h，这个一般不能支持任意时间段的延时）</li><li>通过定时器进行轮训消费这些topic，查看消息是否到期，如果到期就把这个消息发送到具体业务处理的topic中</li><li>队列中消息越靠前的到期时间越早，具体来说就是定时器在一次消费过程中，对消息的发送时间做判断，看下是否延迟到对应时间了，如果到了就转发，如果还没到这一次定时任务就可以提前结束了</li></ul></li><li>消息回溯：对之前已消费的消息重新消费<ul><li>如果某段时间对已消费消息计算的结果觉得有问题，可能是由于程序bug导致的计算错误，当程序bug修复后，这时可能需要对之前已消费的消息重新消费</li><li>可以指定从多久之前的消息回溯消费，这种可以用consumer的offsetsForTimes、seek等方法指定从某个offset偏移的消息开始消费</li></ul></li><li>分区数与吞吐量：一般情况分区数跟集群机器数量相当就差不多了<ul><li><code>kafka‐producer‐perf‐test.sh&nbsp;‐‐topic&nbsp;test&nbsp;‐‐num‐records&nbsp;1000000&nbsp;‐‐record‐size&nbsp;1024&nbsp;‐‐throughput&nbsp;‐1 ‐‐producer‐props&nbsp;bootstrap.servers=192.168.65.60:9092&nbsp;acks=1</code></li><li>往test里发送一百万消息，每条设置1KB，throughput&nbsp;用来进行限流控制，当设定的值小于&nbsp;0&nbsp;时不限流，当设定的值大于&nbsp;0&nbsp;时，当发送的吞吐量大于该值时就会被阻塞一段时间</li><li>如果分区数设置过大，比如设置10000，可能会设置不成功，后台会报错"java.io.IOException&nbsp;:&nbsp;Too&nbsp;many&nbsp;open&nbsp;files"<ul><li><code>ulimit&nbsp;-n 65535</code> 调大文件描述符</li></ul></li></ul></li><li>消息传递保障<ul><li>at&nbsp;most&nbsp;once（消费者最多收到一次消息，0-1次）：acks&nbsp;=&nbsp;0&nbsp;可以实现</li><li>at&nbsp;least&nbsp;once（消费者至少收到一次消息，1-多次）：ack&nbsp;=&nbsp;all&nbsp;可以实现</li><li>exactly&nbsp;once（消费者刚好收到一次消息）：at&nbsp;least&nbsp;once&nbsp;加上消费者幂等性可以实现，还可以用kafka生产者的幂等性来实现<ul><li>kafka生产者的幂等性：因为发送端重试导致的消息重复发送问题，kafka的幂等性可以保证重复发送的消息只接收一次<ul><li>只需在生产者加上参数&nbsp;<code>props.put("enable.idempotence",&nbsp;true)</code>&nbsp;即可，默认是 false 不开启</li><li>具体实现原理是，kafka每次发送消息会生成PID和Sequence&nbsp;Number，并将这两个属性一起发送给broker，broker会将PID和Sequence&nbsp;Number跟消息绑定一起存起来，下次如果生产者重发相同消息，broker会检查PID和Sequence&nbsp;Number，如果相同不会再接收<ul><li>PID：每个新的&nbsp;Producer&nbsp;在初始化的时候会被分配一个唯一的&nbsp;PID，这个PID&nbsp;对用户完全是透明的。生产者如果重启则会生成新的PID</li><li>Sequence&nbsp;Number：对于每个&nbsp;PID，该&nbsp;Producer&nbsp;发送到每个&nbsp;Partition&nbsp;的数据都有对应的序列号，这些序列号是从0开始单调递增的</li></ul></li><li>但是它只保证了生产者的幂等性，没保证消费者的幂等性，所以保险起见还是要再消费端考虑幂等性的问题</li></ul></li></ul></li></ul></li></ul><hr><h2 id="Kafka事务">Kafka事务</h2><ul><li>kafka的事务：保障一次发送多条消息的事务一致性（流式计算场景）<ul><li>Kafka的事务不同于Rocketmq，Rocketmq是保障本地事务(比如数据库)与mq消息发送的事务一致性，Kafka的事务主要是保障一次发送多条消息的事务一致性(要么同时成功要么同时失败)</li><li>一般在kafka的流式计算场景用得多一点，比如，kafka需要对一个topic里的消息做不同的流式计算处理，处理完分别发到不同的topic里，这些topic分别被不同的下游系统消费(比如hbase，redis，es等)，这种我们肯定希望系统发送到多个topic的数据保持事务一致性。Kafka要实现类似Rocketmq的分布式事务需要额外开发功能</li></ul></li></ul><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token class-name">Properties</span> props <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Properties</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"bootstrap.servers"</span><span class="token punctuation">,</span> <span class="token string">"localhost:9092"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"transactional.id"</span><span class="token punctuation">,</span> <span class="token string">"my‐transactional‐id"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token class-name">Producer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> producer <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">KafkaProducer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span>props<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">StringSerializer</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">StringSerializer</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 初始化事务</span>producer<span class="token punctuation">.</span><span class="token function">initTransactions</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">try</span> <span class="token punctuation">{</span><span class="token comment">// 开启事务</span>producer<span class="token punctuation">.</span><span class="token function">beginTransaction</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 发到不同的主题的不同分区</span>producer<span class="token punctuation">.</span><span class="token function">send</span><span class="token punctuation">(</span><span class="token comment">/*...*/</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 提交事务</span>producer<span class="token punctuation">.</span><span class="token function">commitTransaction</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">ProducerFencedException</span> <span class="token operator">|</span> <span class="token class-name">OutOfOrderSequenceException</span> <span class="token operator">|</span> <span class="token class-name">AuthorizationException</span> e<span class="token punctuation">)</span> <span class="token punctuation">{</span>producer<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">KafkaException</span> e<span class="token punctuation">)</span> <span class="token punctuation">{</span><span class="token comment">// 回滚事务</span>producer<span class="token punctuation">.</span><span class="token function">abortTransaction</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token comment">// 关闭</span>producer<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><hr><h2 id="Kafka高性能原因">Kafka高性能原因</h2><ul><li>kafka高性能的原因<ul><li>磁盘顺序读写：kafka消息不能修改以及不会从文件中间删除保证了磁盘顺序读，kafka的消息写入文件都是追加在文件末尾，不会写入文件中的某个位置(随机写)保证了磁盘顺序写</li><li>读写数据的批量batch处理以及压缩传输</li><li>数据传输的零拷贝<ul><li><img src="/static/IT/Kafka/Kafka-%E4%BC%98%E5%8C%96-2.png" alt="零拷贝"></li></ul></li></ul></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;ul&gt;
&lt;li&gt;环境规划&lt;/li&gt;
&lt;li&gt;线上问题&lt;/li&gt;
&lt;li&gt;Kafka事务&lt;/li&gt;
&lt;li&gt;Kafka高性能原因&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&quot;环境规划&quot;&gt;环境规划&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Kafka可视化管理工具：kafka-manager</summary>
      
    
    
    
    <category term="IT学习笔记" scheme="https://jxch.github.io/categories/IT%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="Kafka" scheme="https://jxch.github.io/tags/Kafka/"/>
    
  </entry>
  
  <entry>
    <title>Kafka-基础</title>
    <link href="https://jxch.github.io/2024/09/04/architect/kafka/kafka-ji-chu/"/>
    <id>https://jxch.github.io/2024/09/04/architect/kafka/kafka-ji-chu/</id>
    <published>2024-09-04T02:17:49.000Z</published>
    <updated>2024-09-04T02:23:16.282Z</updated>
    
    <content type="html"><![CDATA[<ul><li>核心组件</li><li>配置文件</li><li>基础命令</li><li>Topic</li><li>Kafka集群</li><li>Java客户端 &amp; SpringBoot支持</li></ul><hr><h2 id="核心组件">核心组件</h2><table><thead><tr><th>名称</th><th>解释</th></tr></thead><tbody><tr><td>Broker</td><td>消息中间件处理节点，一个Kafka节点就是一个broker，一<br>个或者多个Broker可以组成一个Kafka集群</td></tr><tr><td>Topic</td><td>Kafka根据topic对消息进行归类，发布到Kafka集群的每条<br>消息都需要指定一个topic</td></tr><tr><td>Producer</td><td>消息生产者，向Broker发送消息的客户端</td></tr><tr><td>Consumer</td><td>消息消费者，从Broker读取消息的客户端</td></tr><tr><td>ConsumerGroup</td><td>每个Consumer属于一个特定的Consumer&nbsp;Group，一条消<br>息可以被多个不同的Consumer&nbsp;Group消费，但是一个<br>Consumer&nbsp;Group中只能有一个Consumer能够消费该消息</td></tr><tr><td>Partition</td><td>物理上的概念，一个topic可以分为多个partition，每个<br>partition内部消息是有序的</td></tr></tbody></table><p><img src="/static/IT/Kafka/Kafka-%E5%9F%BA%E7%A1%80-1.png" alt="核心组件"></p><hr><h2 id="配置文件">配置文件</h2><ul><li>配置：<code>server.properties</code></li></ul><pre class="line-numbers language-properties" data-language="properties"><code class="language-properties"><span class="token comment">#broker.id属性在kafka集群中必须要是唯一</span><span class="token key attr-name">broker.id</span><span class="token punctuation">=</span><span class="token value attr-value">0</span><span class="token comment">#kafka部署的机器ip和提供服务的端口号</span><span class="token key attr-name">listeners</span><span class="token punctuation">=</span><span class="token value attr-value">PLAINTEXT://192.168.65.60:9092</span><span class="token comment">#kafka的消息存储文件</span><span class="token key attr-name">log.dir</span><span class="token punctuation">=</span><span class="token value attr-value">/usr/local/data/kafka‐logs</span><span class="token comment">#kafka连接zookeeper的地址</span><span class="token key attr-name">zookeeper.connect</span><span class="token punctuation">=</span><span class="token value attr-value">192.168.65.60:2181</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li>默认配置</li></ul><table><thead><tr><th>Property</th><th>Default</th><th>Description</th></tr></thead><tbody><tr><td><a href="http://broker.id">broker.id</a></td><td>0</td><td>每个broker都可以用一个唯一的非负整数id进行标识；这个id可以作为<br>broker的“名字”，你可以选择任意你喜欢的数字作为id，只要id是唯<br>一的即可</td></tr><tr><td>log.dirs</td><td>/tmp/kafka-logs</td><td>kafka存放数据的路径。这个路径并不是唯一的，可以是多个，路径之间<br>只需要使用逗号分隔即可；每当创建新partition时，都会选择在包含最<br>少partitions的路径下进行</td></tr><tr><td>listeners</td><td>PLAINTEXT://192.168.65.60:909</td><td>server接受客户端连接的端口，ip配置kafka本机ip即可</td></tr><tr><td>zookeeper.connect</td><td>localhost:2181</td><td>zooKeeper连接字符串的格式为：hostname:port，此处hostname和<br>port分别是ZooKeeper集群中某个节点的host和port；zookeeper如果<br>是集群，连接方式为&nbsp;hostname1:port1,&nbsp;hostname2:port2,&nbsp;<br>hostname3:port3</td></tr><tr><td>log.retention.hours</td><td>168</td><td>每个日志文件删除之前保存的时间。默认数据保存时间对所有topic都一样</td></tr><tr><td>num.partitions</td><td>1</td><td>创建topic的默认分区数</td></tr><tr><td>default.replication.factor</td><td>1</td><td>自动创建topic的默认副本数量，建议设置为大于等于2</td></tr><tr><td>min.insync.replicas</td><td>1</td><td>当producer设置acks为-1时，min.insync.replicas指定replicas的最小<br>数目（必须确认每一个repica的写数据都是成功的），如果这个数目没<br>有达到，producer发送消息会产生异常</td></tr><tr><td>delete.topic.enable</td><td>false</td><td>是否允许删除主题</td></tr></tbody></table><hr><h2 id="基础命令">基础命令</h2><ul><li>启动：<code>kafka‐server‐start.sh&nbsp;‐daemon&nbsp;server.properties</code><ul><li>­<code>-daemon</code> 表示以后台进程运行，否则ssh客户端退出后，就会停止服务</li><li>在启动kafka时会使用linux主机名关联的ip地址，所以需要把主机名和linux的ip映射配置到本地host里，用 <code>vim&nbsp;/etc/hosts</code></li></ul></li><li>停止：<code>kafka‐server‐stop.sh</code></li><li>创建主题：当producer发布一个消息到某个指定的Topic，这个Topic如果不存在，就自动创建<ul><li><code>kafka‐topics.sh&nbsp;‐‐create&nbsp;‐‐zookeeper&nbsp;192.168.65.60:2181&nbsp;‐‐replication‐factor&nbsp;1&nbsp;‐‐partitions&nbsp;1&nbsp;‐‐topic&nbsp;test</code></li><li><code>kafka‐topics.sh&nbsp;‐‐create&nbsp;‐‐zookeeper&nbsp;192.168.65.60:2181&nbsp;‐‐replication‐factor&nbsp;1&nbsp;‐‐partitions&nbsp;2&nbsp;‐‐topic&nbsp;test</code></li><li><code>kafka‐topics.sh&nbsp;‐‐list&nbsp;‐‐zookeeper&nbsp;192.168.65.60:2181</code></li></ul></li><li>查看Topic：<code>kafka‐topics.sh&nbsp;‐‐describe&nbsp;‐‐zookeeper&nbsp;192.168.65.60:2181&nbsp;‐‐topic&nbsp;test</code><ul><li>第一行是所有分区的概要信息，之后的每一行表示每一个partition的信息</li><li>leader节点负责给定partition的所有读写请求</li><li>replicas&nbsp;表示某个partition 在哪几个 broker上存在备份。不管这个几点是不是”leader“，甚至这个节点挂了，也会列出</li><li>isr&nbsp;是replicas的一个子集，它只列出当前还存活着的，并且已同步备份了该partition的节点。leader的选举也是从ISR(in-sync&nbsp;replica)中进行的</li></ul></li><li>增加Topic的分区数量（目前不支持减少分区）：<code>kafka‐topics.sh&nbsp;‐alter&nbsp;‐‐partitions&nbsp;3&nbsp;‐‐zookeeper&nbsp;192.168.65.60:2181&nbsp;‐‐topic&nbsp;test</code></li><li>删除主题：<code>kafka‐topics.sh&nbsp;‐‐delete&nbsp;‐‐topic&nbsp;test&nbsp;‐‐zookeeper&nbsp;192.168.65.60:2181</code></li><li>发送消息：<code>kafka‐console‐producer.sh&nbsp;‐‐broker‐list&nbsp;192.168.65.60:9092&nbsp;‐‐topic&nbsp;test</code></li><li>消费消息：默认是消费最新的消息<ul><li><code>kafka‐console‐consumer.sh&nbsp;‐‐bootstrap‐server&nbsp;192.168.65.60:9092&nbsp;‐‐topic&nbsp;test</code></li><li><code>kafka‐console‐consumer.sh&nbsp;‐‐bootstrap‐server&nbsp;192.168.65.60:9092&nbsp;‐‐from‐beginning&nbsp;‐‐topic&nbsp;test</code></li></ul></li><li>消费多主题：<code>kafka‐console‐consumer.sh&nbsp;‐‐bootstrap‐server&nbsp;192.168.65.60:9092&nbsp;‐‐whitelist&nbsp;"test|test‐2"</code></li><li>单播消费：只需让消费者在同一个消费组里即可<ul><li><code>kafka‐console‐consumer.sh&nbsp;‐‐bootstrap‐server&nbsp;192.168.65.60:9092&nbsp;‐‐consumer‐property&nbsp;group.id=testGroup&nbsp;‐‐topic&nbsp;test</code></li></ul></li><li>多播消费：只要保证这些消费者属于不同的消费组即可<ul><li><code>kafka‐console‐consumer.sh&nbsp;‐‐bootstrap‐server&nbsp;192.168.65.60:9092&nbsp;‐‐consumer‐property&nbsp;group.id=testGroup‐2&nbsp;‐‐topic test</code></li></ul></li><li>生产消费集群消息<ul><li><code>kafka‐console‐producer.sh&nbsp;‐‐broker‐list&nbsp;192.168.65.60:9092,192.168.65.60:9093,192.168.65.60:9094&nbsp;‐‐topic&nbsp;my‐replicated‐topic</code></li><li><code>kafka‐console‐consumer.sh&nbsp;‐‐bootstrap‐server&nbsp;192.168.65.60:9092,192.168.65.60:9093,192.168.65.60:9094&nbsp;‐‐from‐beginning&nbsp;‐‐topic&nbsp;my‐replicated‐topic</code></li></ul></li><li>查看消费组名：<code>kafka‐consumer‐groups.sh&nbsp;‐‐bootstrap‐server&nbsp;192.168.65.60:9092&nbsp;‐‐list</code></li><li>查看消费组的消费偏移量：<code>kafka‐consumer‐groups.sh&nbsp;‐‐bootstrap‐server&nbsp;192.168.65.60:9092&nbsp;‐‐describe&nbsp;‐‐group&nbsp;testGroup</code><ul><li>current-offset：当前消费组的已消费偏移量</li><li>log-end-offset：主题对应分区消息的结束偏移量(HW)</li><li>lag：当前消费组未消费的消息数</li></ul></li></ul><hr><h2 id="Topic">Topic</h2><ul><li>同类消息发送到同一个Topic下面。对于每一个Topic，下面可以有多个分区(Partition)日志文件<ul><li><img src="/static/IT/Kafka/Kafka-%E5%9F%BA%E7%A1%80-2.png" alt="Topic"></li><li>Partition是一个有序的message序列，这些message按顺序添加到一个叫做commit&nbsp;log的文件中。每个partition中的消息都有一个唯一的编号，称之为offset，用来唯一标示某个分区中的message</li><li>每个partition，都对应一个commit&nbsp;log文件。一个partition中的message的offset都是唯一的，但是不同的partition中的message的offset可能是相同的</li><li>kafka一般不会删除消息，不管这些消息有没有被消费。只会根据配置的日志保留时间(log.retention.hours)确认消息多久被删除，默认保留最近一周的日志消息。kafka的性能与保留的消息数据量大小没有关系，因此保存大量的数据消息日志信息不会有什么影响</li><li>每个consumer是基于自己在commit&nbsp;log中的消费进度(offset)来进行工作的。在kafka中，消费offset由consumer自己来维护；一般情况下我们按照顺序逐条消费commit&nbsp;log中的消息，当然可以通过指定offset来重复消费某些消息，或者跳过某些消息</li><li>这意味kafka中的consumer对集群的影响是非常小的，添加一个或者减少一个consumer，对于集群或者其他consumer来说，都是没有影响的，因为每个consumer维护各自的消费offset</li></ul></li><li>对Topic下数据进行分区存储<ul><li>commit&nbsp;log文件会受到所在机器的文件系统大小的限制，分区之后可以将不同的分区放在不同的机器上，相当于对数据做了分布式存储，理论上一个topic可以处理任意数量的数据</li><li>提高并行度</li></ul></li></ul><hr><h2 id="Kafka集群">Kafka集群</h2><ul><li>kafka集群：一个单独的broker意味着kafka集群中只有一个节点。要想增加kafka集群中的节点数量，只需要多启动几个broker实例即可<ul><li>kafka将很多集群关键信息记录在zookeeper里，保证自己的无状态，从而在水平扩容时非常方便</li></ul></li><li>集群消费<ul><li>log的partitions分布在kafka集群中不同的broker上，每个broker可以请求备份其他broker上partition上的数据。kafka集群支持配置一个partition备份的数量</li><li>针对每个partition，都有一个broker起到“leader”的作用，0个或多个其他的broker作为“follwers”的作用</li><li>leader处理所有的针对这个partition的读写请求，而followers被动复制leader的结果，不提供读写(主要是为了保证多副本数据与消费的一致性)。如果这个leader失效了，其中的一个follower将会自动的变成新的leader</li></ul></li><li>Producers：生产者将消息发送到topic中去，同时负责选择将message发送到topic的哪一个partition中。通过round­-robin做简单的负载均衡。也可以根据消息中的某一个关键字来进行区分。通常第二种方式使用的更多</li><li>Consumers：consumer&nbsp;group<ul><li>queue 模式：consumer 位于同一个 consumer&nbsp;group&nbsp;下</li><li>publish-subscribe 模式：consumer 有自己唯一的 consumer&nbsp;group</li><li><img src="/static/IT/Kafka/Kafka-%E5%9F%BA%E7%A1%80-3.png" alt="consumer&nbsp;group"></li></ul></li><li>消费顺序：一个partition同一个时刻在一个consumer&nbsp;group中只能有一个consumer&nbsp;instance在消费，从而保证消费顺序<ul><li>Kafka只在partition的范围内保证消息消费的局部顺序性，不能在同一个topic中的多个partition中保证总的消费顺序性</li><li>如果有在总体上保证消费顺序的需求，那么我们可以通过将topic的partition数量设置为1，将consumer&nbsp;group中的consumer&nbsp;instance数量也设置为1，但是这样会影响性能，所以kafka的顺序消费很少用</li><li>consumer&nbsp;group中的consumer&nbsp;instance的数量不能比一个Topic中的partition的数量多，否则，多出来的consumer消费不到消息</li></ul></li></ul><hr><h2 id="Java客户端">Java客户端</h2><ul><li>绑定Kafka服务器</li></ul><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token class-name">Properties</span> props <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Properties</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ProducerConfig</span><span class="token punctuation">.</span><span class="token constant">BOOTSTRAP_SERVERS_CONFIG</span><span class="token punctuation">,</span> <span class="token string">"192.168.65.60:9092,192.168.65.60:9093,192.168.65.60:9094"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 生产者</span><span class="token class-name">Producer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> producer <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">KafkaProducer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span>props<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 消费者</span><span class="token class-name">KafkaConsumer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> consumer <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">KafkaConsumer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span>props<span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li>生产者配置</li></ul><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token comment">/*  * 发出消息持久化机制参数 * acks=0： 表示producer不需要等待任何broker确认收到消息的回复，就可以继续发送下一条消息。性能最高，但是最容易丢消息 * acks=1： 至少要等待leader已经成功将数据写入本地log，但是不需要等待所有follower是否成功写入，就可以继续发送下一条消息 *          如果follower没有成功备份数据，而此时leader又挂掉，则消息会丢失 * acks=‐1或all： 需要等待 min.insync.replicas(默认为1，推荐配置大于等于2) 这个参数配置的副本个数都成功写入日志 *                这种策略会保证只要有一个备份存活就不会丢失数据。这是最强的数据保证。一般除非是金融级别，或跟钱打交道的场景才会使用这种配置 */</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ProducerConfig</span><span class="token punctuation">.</span><span class="token constant">ACKS_CONFIG</span><span class="token punctuation">,</span> <span class="token string">"1"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 发送失败重试次数，重试能保证消息发送的可靠性，但是也可能造成消息重复发送，需要接收者做好消息接收的幂等性处理</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ProducerConfig</span><span class="token punctuation">.</span><span class="token constant">RETRIES_CONFIG</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 重试间隔设置，默认重试间隔100ms</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ProducerConfig</span><span class="token punctuation">.</span><span class="token constant">RETRY_BACKOFF_MS_CONFIG</span><span class="token punctuation">,</span> <span class="token number">300</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 设置发送消息的本地缓冲区，如果设置了该缓冲区，消息会先发送到本地缓冲区，可以提高消息发送性能，默认值是33554432，即32MB</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ProducerConfig</span><span class="token punctuation">.</span><span class="token constant">BUFFER_MEMORY_CONFIG</span><span class="token punctuation">,</span> <span class="token number">33554432</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// kafka本地线程会从缓冲区取数据，批量发送到broker，设置批量发送消息的大小，默认值是16384，即16kb，就是说一个batch满了16kb就发送出去</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ProducerConfig</span><span class="token punctuation">.</span><span class="token constant">BATCH_SIZE_CONFIG</span><span class="token punctuation">,</span> <span class="token number">16384</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">/*  * batch最大的延迟发送时间 * 默认值是0：意思就是消息必须立即被发送，但这样会影响性能 * 一般设置10毫秒左右，就是说这个消息发送完后会进入本地的一个batch，如果10毫秒内，这个batch满了16kb就会随batch一起被发送出去 * 如果10毫秒内，batch没满，那么也必须把消息发送出去，不能让消息的发送延迟时间太长 *  *  消息 -&gt; 本地缓冲区（32M）-&gt; batch（16k）-&gt; 发送（10ms batch不满也发送） */</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ProducerConfig</span><span class="token punctuation">.</span><span class="token constant">LINGER_MS_CONFIG</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 把发送的key和value从字符串序列化为字节数组</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ProducerConfig</span><span class="token punctuation">.</span><span class="token constant">KEY_SERIALIZER_CLASS_CONFIG</span><span class="token punctuation">,</span> <span class="token class-name">StringSerializer</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">.</span><span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ProducerConfig</span><span class="token punctuation">.</span><span class="token constant">VALUE_SERIALIZER_CLASS_CONFIG</span><span class="token punctuation">,</span> <span class="token class-name">StringSerializer</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">.</span><span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li>生产者发送消息：指定分区；不指定分区；同步；异步</li></ul><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token comment">// 指定发送分区</span><span class="token keyword">var</span> producerRecord <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ProducerRecord</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span><span class="token constant">TOPIC_NAME</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> key_json<span class="token punctuation">,</span> value_json<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 未指定发送分区，具体发送的分区计算公式：hash(key) % partitionNum</span><span class="token keyword">var</span> producerRecord <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ProducerRecord</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span><span class="token constant">TOPIC_NAME</span><span class="token punctuation">,</span> key_json<span class="token punctuation">,</span> value_json<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 等待消息发送成功的同步阻塞方法</span><span class="token class-name">RecordMetadata</span> metadata <span class="token operator">=</span> producer<span class="token punctuation">.</span><span class="token function">send</span><span class="token punctuation">(</span>producerRecord<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 异步回调方式发送消息</span>producer<span class="token punctuation">.</span><span class="token function">send</span><span class="token punctuation">(</span>producerRecord<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Callback</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span><span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">onCompletion</span><span class="token punctuation">(</span><span class="token class-name">RecordMetadata</span> metadata<span class="token punctuation">,</span> <span class="token class-name">Exception</span> exception<span class="token punctuation">)</span> <span class="token punctuation">{</span><span class="token comment">// 处理异常</span><span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 关闭</span>producer<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li>消费配置</li></ul><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token comment">// 消费分组名</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ConsumerConfig</span><span class="token punctuation">.</span><span class="token constant">GROUP_ID_CONFIG</span><span class="token punctuation">,</span> <span class="token constant">CONSUMER_GROUP_NAME</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 是否自动提交offset，默认就是true</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ConsumerConfig</span><span class="token punctuation">.</span><span class="token constant">ENABLE_AUTO_COMMIT_CONFIG</span><span class="token punctuation">,</span> <span class="token string">"true"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 自动提交offset的间隔时间</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ConsumerConfig</span><span class="token punctuation">.</span><span class="token constant">AUTO_COMMIT_INTERVAL_MS_CONFIG</span><span class="token punctuation">,</span> <span class="token string">"1000"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">/*  * 当消费主题的是一个新的消费组，或者指定offset的消费方式，offset不存在，那么应该如何消费 * latest(默认) ：只消费自己启动之后发送到主题的消息 * earliest：第一次从头开始消费，以后按照消费offset记录继续消费，这个需要区别于 consumer.seekToBeginning(每次都从头开始消费) */</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ConsumerConfig</span><span class="token punctuation">.</span><span class="token constant">AUTO_OFFSET_RESET_CONFIG</span><span class="token punctuation">,</span> <span class="token string">"earliest"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// consumer给broker发送心跳的间隔时间，broker接收到心跳如果此时有rebalance发生会通过心跳响应将rebalance方案下发给consumer，这个时间可以稍微短一点</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ConsumerConfig</span><span class="token punctuation">.</span><span class="token constant">HEARTBEAT_INTERVAL_MS_CONFIG</span><span class="token punctuation">,</span> <span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 服务端broker多久感知不到一个consumer心跳就认为他故障了，会将其踢出消费组，对应的Partition也会被重新分配给其他consumer，默认是10秒</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ConsumerConfig</span><span class="token punctuation">.</span><span class="token constant">SESSION_TIMEOUT_MS_CONFIG</span><span class="token punctuation">,</span> <span class="token number">10</span> <span class="token operator">*</span> <span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 一次poll最大拉取消息的条数，如果消费者处理速度很快，可以设置大点，如果处理速度一般，可以设置小点</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ConsumerConfig</span><span class="token punctuation">.</span><span class="token constant">MAX_POLL_RECORDS_CONFIG</span><span class="token punctuation">,</span> <span class="token number">500</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 如果两次poll操作间隔超过了这个时间，broker就会认为这个consumer处理能力太弱，会将其踢出消费组，将分区分配给别的consumer消费</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ConsumerConfig</span><span class="token punctuation">.</span><span class="token constant">MAX_POLL_INTERVAL_MS_CONFIG</span><span class="token punctuation">,</span> <span class="token number">30</span> <span class="token operator">*</span> <span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 把发送的key和value从字符串序列化为字节数组</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ConsumerConfig</span><span class="token punctuation">.</span><span class="token constant">KEY_DESERIALIZER_CLASS_CONFIG</span><span class="token punctuation">,</span> <span class="token class-name">StringDeserializer</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">.</span><span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ConsumerConfig</span><span class="token punctuation">.</span><span class="token constant">VALUE_DESERIALIZER_CLASS_CONFIG</span><span class="token punctuation">,</span> <span class="token class-name">StringDeserializer</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">.</span><span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li>消费者接收消息（topic）：指定分区；回溯（从头，指定offset）；拉取集合</li></ul><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token comment">// 订阅Topic</span>consumer<span class="token punctuation">.</span><span class="token function">subscribe</span><span class="token punctuation">(</span><span class="token class-name">Arrays</span><span class="token punctuation">.</span><span class="token function">asList</span><span class="token punctuation">(</span><span class="token constant">TOPIC_NAME</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 消费指定分区</span>consumer<span class="token punctuation">.</span><span class="token function">assign</span><span class="token punctuation">(</span><span class="token class-name">Arrays</span><span class="token punctuation">.</span><span class="token function">asList</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">TopicPartition</span><span class="token punctuation">(</span><span class="token constant">TOPIC_NAME</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 回溯消费（从头消费 - seekToBeginning）</span>consumer<span class="token punctuation">.</span><span class="token function">assign</span><span class="token punctuation">(</span><span class="token class-name">Arrays</span><span class="token punctuation">.</span><span class="token function">asList</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">TopicPartition</span><span class="token punctuation">(</span><span class="token constant">TOPIC_NAME</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>consumer<span class="token punctuation">.</span><span class="token function">seekToBeginning</span><span class="token punctuation">(</span><span class="token class-name">Arrays</span><span class="token punctuation">.</span><span class="token function">asList</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">TopicPartition</span><span class="token punctuation">(</span><span class="token constant">TOPIC_NAME</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 指定offset消费</span>consumer<span class="token punctuation">.</span><span class="token function">assign</span><span class="token punctuation">(</span><span class="token class-name">Arrays</span><span class="token punctuation">.</span><span class="token function">asList</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">TopicPartition</span><span class="token punctuation">(</span><span class="token constant">TOPIC_NAME</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>consumer<span class="token punctuation">.</span><span class="token function">seek</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">TopicPartition</span><span class="token punctuation">(</span><span class="token constant">TOPIC_NAME</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 从指定时间点开始消费 - 1小时前</span><span class="token class-name">List</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">PartitionInfo</span><span class="token punctuation">&gt;</span></span> topicPartitions <span class="token operator">=</span> consumer<span class="token punctuation">.</span><span class="token function">partitionsFor</span><span class="token punctuation">(</span><span class="token constant">TOPIC_NAME</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">long</span> fetchDataTime <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Date</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">getTime</span><span class="token punctuation">(</span><span class="token punctuation">)</span> ‐ <span class="token number">1000</span> <span class="token operator">*</span> <span class="token number">60</span> <span class="token operator">*</span> <span class="token number">60</span><span class="token punctuation">;</span><span class="token class-name">Map</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">TopicPartition</span><span class="token punctuation">,</span> <span class="token class-name">Long</span><span class="token punctuation">&gt;</span></span> map <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">HashMap</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token class-name">PartitionInfo</span> par <span class="token operator">:</span> topicPartitions<span class="token punctuation">)</span> <span class="token punctuation">{</span>map<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">TopicPartition</span><span class="token punctuation">(</span>topicName<span class="token punctuation">,</span> par<span class="token punctuation">.</span><span class="token function">partition</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> fetchDataTime<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token comment">// 遍历 value.offset(); 获取offset，然后指定offset消费</span><span class="token class-name">Map</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">TopicPartition</span><span class="token punctuation">,</span> <span class="token class-name">OffsetAndTimestamp</span><span class="token punctuation">&gt;</span></span> parMap <span class="token operator">=</span> consumer<span class="token punctuation">.</span><span class="token function">offsetsForTimes</span><span class="token punctuation">(</span>map<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 拉取消息集合</span><span class="token class-name">ConsumerRecords</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> records <span class="token operator">=</span> consumer<span class="token punctuation">.</span><span class="token function">poll</span><span class="token punctuation">(</span><span class="token class-name">Duration</span><span class="token punctuation">.</span><span class="token function">ofMillis</span><span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li>消费提交（offset）：同步；异步</li></ul><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token comment">// 手动同步提交offset，当前线程会阻塞直到offset提交成功，一般使用同步提交，因为提交之后一般也没有什么逻辑代码了</span>consumer<span class="token punctuation">.</span><span class="token function">commitSync</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 手动异步提交offset，当前线程提交offset不会阻塞，可以继续处理后面的程序逻辑</span>consumer<span class="token punctuation">.</span><span class="token function">commitAsync</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">OffsetCommitCallback</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span><span class="token annotation punctuation">@Override</span><span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">onComplete</span><span class="token punctuation">(</span><span class="token class-name">Map</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">TopicPartition</span><span class="token punctuation">,</span> <span class="token class-name">OffsetAndMetadata</span><span class="token punctuation">&gt;</span></span> offsets<span class="token punctuation">,</span> <span class="token class-name">Exception</span> ex<span class="token punctuation">)</span> <span class="token punctuation">{</span><span class="token comment">// 处理异常</span><span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><hr><h2 id="SpringBoot支持">SpringBoot支持</h2><ul><li>springboot配置application.yml</li></ul><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token key atrule">spring</span><span class="token punctuation">:</span><span class="token key atrule">kafka</span><span class="token punctuation">:</span><span class="token key atrule">bootstrap‐servers</span><span class="token punctuation">:</span> 192.168.65.60<span class="token punctuation">:</span><span class="token number">9092</span><span class="token punctuation">,</span>192.168.65.60<span class="token punctuation">:</span><span class="token number">9093</span><span class="token punctuation">,</span>192.168.65.60<span class="token punctuation">:</span><span class="token number">9094</span><span class="token key atrule">producer</span><span class="token punctuation">:</span><span class="token key atrule">retries</span><span class="token punctuation">:</span> <span class="token number">3</span><span class="token key atrule">batch‐size</span><span class="token punctuation">:</span> <span class="token number">16384</span><span class="token key atrule">buffer‐memory</span><span class="token punctuation">:</span> <span class="token number">33554432</span><span class="token key atrule">acks</span><span class="token punctuation">:</span> <span class="token number">1</span><span class="token key atrule">key‐serializer</span><span class="token punctuation">:</span> org.apache.kafka.common.serialization.StringSerializer<span class="token key atrule">value‐serializer</span><span class="token punctuation">:</span> org.apache.kafka.common.serialization.StringSerializer<span class="token key atrule">consumer</span><span class="token punctuation">:</span><span class="token key atrule">group‐id</span><span class="token punctuation">:</span> default‐group<span class="token key atrule">enable‐auto‐commit</span><span class="token punctuation">:</span> <span class="token boolean important">false</span><span class="token key atrule">auto‐offset‐reset</span><span class="token punctuation">:</span> earliest<span class="token key atrule">key‐deserializer</span><span class="token punctuation">:</span> xxx.StringDeserializer<span class="token key atrule">value‐deserializer</span><span class="token punctuation">:</span> xxx.StringDeserializer<span class="token key atrule">listener</span><span class="token punctuation">:</span><span class="token key atrule">ack‐mode</span><span class="token punctuation">:</span> manual_immediate<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li>ack‐mode<ul><li>RECORD：当每一条记录被消费者监听器（ListenerConsumer）处理之后提交</li><li>BATCH：当每一批poll()的数据被消费者监听器处理之后提交</li><li>TIME：当每一批poll()的数据被消费者监听器处理之后，距离上次提交时间大于TIME时提交</li><li>COUNT：当每一批poll()的数据被消费者监听器处理之后，被处理record数量大于等于COUNT时提交</li><li>TIME&nbsp;|&nbsp;COUNT：有一个条件满足时提交</li><li>MANUAL：当每一批poll()的数据被消费者监听器处理之后,&nbsp;手动调用Acknowledgment.acknowledge()后提交</li><li>MANUAL_IMMEDIATE：手动调用Acknowledgment.acknowledge()后立即提交，一般使用这种（一次提交一条消息）</li></ul></li><li>生产者</li></ul><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token annotation punctuation">@Autowired</span><span class="token keyword">private</span> <span class="token class-name">KafkaTemplate</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> kafkaTemplate<span class="token punctuation">;</span>kafkaTemplate<span class="token punctuation">.</span><span class="token function">send</span><span class="token punctuation">(</span><span class="token constant">TOPIC_NAME</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token string">"key"</span><span class="token punctuation">,</span> <span class="token string">"this is a msg"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><ul><li>消费者</li></ul><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token annotation punctuation">@KafkaListener</span><span class="token punctuation">(</span>topics <span class="token operator">=</span> <span class="token string">"my‐replicated‐topic"</span><span class="token punctuation">,</span>groupId <span class="token operator">=</span> <span class="token string">"zhugeGroup"</span><span class="token punctuation">)</span><span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">listenZhugeGroup</span><span class="token punctuation">(</span><span class="token class-name">ConsumerRecord</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> record<span class="token punctuation">,</span> <span class="token class-name">Acknowledgment</span> ack<span class="token punctuation">)</span> <span class="token punctuation">{</span><span class="token class-name">String</span> value <span class="token operator">=</span> record<span class="token punctuation">.</span><span class="token function">value</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>ack<span class="token punctuation">.</span><span class="token function">acknowledge</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment">//手动提交offset</span><span class="token punctuation">}</span><span class="token comment">// 配置多个消费组（再写一个消费组处理同一个topic）</span><span class="token annotation punctuation">@KafkaListener</span><span class="token punctuation">(</span>topics <span class="token operator">=</span> <span class="token string">"my‐replicated‐topic"</span><span class="token punctuation">,</span>groupId <span class="token operator">=</span> <span class="token string">"tulingGroup"</span><span class="token punctuation">)</span><span class="token comment">// 配置多个topic，concurrency就是同组下的消费者个数，就是并发消费数，必须小于等于分区总数</span><span class="token annotation punctuation">@KafkaListener</span><span class="token punctuation">(</span>groupId <span class="token operator">=</span> <span class="token string">"testGroup"</span><span class="token punctuation">,</span> topicPartitions <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token annotation punctuation">@TopicPartition</span><span class="token punctuation">(</span>topic <span class="token operator">=</span> <span class="token string">"topic1"</span><span class="token punctuation">,</span> partitions <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">"0"</span><span class="token punctuation">,</span> <span class="token string">"1"</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token annotation punctuation">@TopicPartition</span><span class="token punctuation">(</span>topic <span class="token operator">=</span> <span class="token string">"topic2"</span><span class="token punctuation">,</span> partitions <span class="token operator">=</span> <span class="token string">"0"</span><span class="token punctuation">,</span>partitionOffsets <span class="token operator">=</span> <span class="token annotation punctuation">@PartitionOffset</span><span class="token punctuation">(</span>partition <span class="token operator">=</span> <span class="token string">"1"</span><span class="token punctuation">,</span> initialOffset <span class="token operator">=</span> <span class="token string">"100"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">,</span>concurrency <span class="token operator">=</span> <span class="token string">"6"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><hr><ul><li>Kafka事务</li></ul><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token class-name">Properties</span> props <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Properties</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"bootstrap.servers"</span><span class="token punctuation">,</span> <span class="token string">"localhost:9092"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"transactional.id"</span><span class="token punctuation">,</span> <span class="token string">"my‐transactional‐id"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token class-name">Producer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> producer <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">KafkaProducer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span>props<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">StringSerializer</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">StringSerializer</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>producer<span class="token punctuation">.</span><span class="token function">initTransactions</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>      <span class="token comment">// 初始化事务</span><span class="token keyword">try</span> <span class="token punctuation">{</span>producer<span class="token punctuation">.</span><span class="token function">beginTransaction</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment">// 开启事务</span>producer<span class="token punctuation">.</span><span class="token function">send</span><span class="token punctuation">(</span><span class="token comment">/*...*/</span><span class="token punctuation">)</span><span class="token punctuation">;</span>       <span class="token comment">// 发到不同的主题的不同分区</span>producer<span class="token punctuation">.</span><span class="token function">commitTransaction</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// 提交事务</span><span class="token punctuation">}</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">ProducerFencedException</span> <span class="token operator">|</span> <span class="token class-name">OutOfOrderSequenceException</span> <span class="token operator">|</span> <span class="token class-name">AuthorizationException</span> e<span class="token punctuation">)</span> <span class="token punctuation">{</span>producer<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">KafkaException</span> e<span class="token punctuation">)</span> <span class="token punctuation">{</span>producer<span class="token punctuation">.</span><span class="token function">abortTransaction</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment">// 回滚事务</span><span class="token punctuation">}</span>producer<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;ul&gt;
&lt;li&gt;核心组件&lt;/li&gt;
&lt;li&gt;配置文件&lt;/li&gt;
&lt;li&gt;基础命令&lt;/li&gt;
&lt;li&gt;Topic&lt;/li&gt;
&lt;li&gt;Kafka集群&lt;/li&gt;
&lt;li&gt;Java客户端 &amp;amp; SpringBoot支持&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&quot;核心组件&quot;&gt;</summary>
      
    
    
    
    <category term="IT学习笔记" scheme="https://jxch.github.io/categories/IT%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="Kafka" scheme="https://jxch.github.io/tags/Kafka/"/>
    
  </entry>
  
  <entry>
    <title>Kafka-设计原理</title>
    <link href="https://jxch.github.io/2024/09/04/architect/kafka/kafka-she-ji-yuan-li/"/>
    <id>https://jxch.github.io/2024/09/04/architect/kafka/kafka-she-ji-yuan-li/</id>
    <published>2024-09-04T02:02:49.000Z</published>
    <updated>2024-09-04T02:10:24.605Z</updated>
    
    <content type="html"><![CDATA[<ul><li>Controller</li><li>Leader - Partition</li><li>Rebalance</li><li>消息发布机制</li><li>HW与LEO</li><li>日志分段</li><li>zookeeper</li></ul><hr><h2 id="Controller">Controller</h2><ul><li>Kafka核心总控制器Controller：在Kafka集群中会有一个或者多个broker，其中有一个broker会被选举为控制器（Kafka&nbsp;Controller），它负责管理整个集群中所有分区和副本的状态<ul><li>当某个分区的leader副本出现故障时，由控制器负责为该分区选举新的leader副本</li><li>当检测到某个分区的ISR集合发生变化时，由控制器负责通知所有broker更新其元数据信息</li><li>当使用kafka-topics.sh脚本为某个topic增加分区数量时，同样还是由控制器负责让新分区被其他节点感知到</li></ul></li><li>Controller选举机制<ul><li>zookeeper临时节点的创建来选举controller：在kafka集群启动的时候，会自动选举一台broker作为controller来管理整个集群，选举的过程是集群中每个broker都会尝试在zookeeper上创建一个&nbsp;/controller&nbsp;临时节点，zookeeper会保证有且仅有一个broker能创建成功，这个broker就会成为集群的总控器controller</li><li>controller重新选举：当这个controller角色的broker宕机了，此时zookeeper临时节点会消失，集群里其他broker会一直监听这个临时节点，发现临时节点消失了，就竞争再次创建临时节点，就是我们上面说的选举机制，zookeeper又会保证有一个broker成为新的controller</li></ul></li><li>具备控制器身份的broker需要比其他普通的broker多一份职责，具体细节如下<ul><li>监听broker相关的变化。为Zookeeper中的/brokers/ids/节点添加BrokerChangeListener，用来处理broker增减的变化</li><li>监听topic相关的变化。为Zookeeper中的/brokers/topics节点添加TopicChangeListener，用来处理topic增减的变化；为Zookeeper中的/admin/delete_topics节点添加TopicDeletionListener，用来处理删除topic的动作</li><li>从Zookeeper中读取获取当前所有与topic、partition以及broker有关的信息并进行相应的管理。对于所有topic所对应的Zookeeper中的/brokers/topics/[topic]节点添加PartitionModificationsListener，用来监听topic中的分区分配变化</li><li>更新集群的元数据信息，同步到其他普通的broker节点中</li></ul></li></ul><hr><h2 id="Leader-Partition">Leader - Partition</h2><ul><li>Partition副本选举Leader机制<ul><li>controller感知到分区leader所在的broker挂了（controller监听了很多zk节点可以感知到broker存活）</li><li>controller会从ISR列表(参数unclean.leader.election.enable=false的前提下)里挑第一个broker作为leader(第一个broker最先放进ISR列表，可能是同步数据最多的副本)</li><li>如果参数unclean.leader.election.enable为true，代表在ISR列表里所有副本都挂了的时候可以在ISR列表以外的副本中选leader，这种设置，可以提高可用性，但是选出的新leader有可能数据少很多</li></ul></li><li>副本进入ISR列表有两个条件<ul><li>必须能与zookeeper保持会话以及跟leader副本网络连通</li><li>副本能复制leader上的所有写操作，并且不能落后太多<ul><li>与leader副本同步滞后的副本，是由 <a href="http://replica.lag.time.max.ms">replica.lag.time.max.ms</a>&nbsp;配置决定的，超过这个时间都没有跟leader同步过的一次的副本会被移出ISR列表</li></ul></li></ul></li><li>消费者消费消息的offset记录机制<ul><li>每个consumer会定期将自己消费分区的offset提交给kafka内部topic：__consumer_offsets<ul><li>提交过去的时候，key是consumerGroupId+topic+分区号，value就是当前offset的值</li><li>kafka会定期清理topic里的消息，最后就保留最新的那条数据</li></ul></li><li>因为__consumer_offsets可能会接收高并发的请求，kafka默认给其分配50个分区(可以通过offsets.topic.num.partitions设置)，这样可以通过加机器的方式抗大并发</li></ul></li></ul><hr><h2 id="Rebalance">Rebalance</h2><ul><li>Rebalance分区分配策略（partition.assignment.strategy）：range（默认）、round-robin、sticky<ul><li>range：按照分区序号排序，比如分区0~3给一个consumer，分区4~6给一个consumer，分区7~9给一个consumer</li><li>round-robin：轮询分配，比如分区0、3、6、9给一个consumer，分区1、4、7给一个consumer，分区2、5、8给一个consumer</li><li>sticky：与round-robin类似，但是在rebalance的时候，需要保证如下两个原则（当两者发生冲突时，第一个目标优先于第二个目标）<ul><li>分区的分配要尽可能均匀</li><li>分区的分配尽可能与上次分配的保持相同</li></ul></li></ul></li><li>Rebalance机制：如果消费组里的消费者数量有变化或消费的分区数有变化，kafka会重新分配消费者消费分区的关系。比如consumer&nbsp;group中某个消费者挂了，此时会自动把分配给他的分区交给其他的消费者，如果他又重启了，那么又会把一些分区重新交还给他<ul><li>rebalance只针对subscribe这种不指定分区消费的情况，如果通过assign这种消费方式指定了分区，kafka不会进行rebanlance</li><li>rebalance过程中，消费者无法从kafka消费消息，这对kafka的TPS会有影响，如果kafka集群内节点较多，比如数百个，那重平衡可能会耗时极多，所以应尽量避免在系统高峰期的重平衡发生</li></ul></li><li>触发消费者rebalance<ul><li>消费组里的consumer增加或减少了</li><li>动态给topic增加了分区</li><li>消费组订阅了更多的topic</li></ul></li><li>Rebalance过程：当有消费者加入消费组时，消费者、消费组及组协调器之间会经历以下几个阶段<ol><li>选择组协调器（GroupCoordinator）：每个consumer&nbsp;group都会选择一个broker作为自己的组协调器coordinator，负责监控这个消费组里的所有消费者的心跳，以及判断是否宕机，然后开启消费者rebalance<ul><li>consumer&nbsp;group中的每个consumer启动时会向kafka集群中的某个节点发送FindCoordinatorRequest请求来查找对应的组协调器GroupCoordinator，并跟其建立网络连接</li><li>组协调器选择方式：通过如下公式可以选出consumer消费的offset要提交到__consumer_offsets的哪个分区，这个分区leader对应的broker就是这个consumer&nbsp;group的coordinator。说白了，leader分区所在的节点就是GroupCoordinator</li></ul></li><li>加入消费组（JOIN&nbsp;GROUP），选择消费组协调器<ol><li>在成功找到消费组所对应的&nbsp;GroupCoordinator&nbsp;之后就进入加入消费组的阶段，在此阶段的消费者会向 GroupCoordinator&nbsp;发送&nbsp;JoinGroupRequest&nbsp;请求，并处理响应。</li><li>然后GroupCoordinator&nbsp;从一个consumer&nbsp;group中选择第一个加入group（第一个与GroupCoordinator连接的consumer）的consumer作为leader(消费组协调器)</li><li>把consumer&nbsp;group情况发送给这个leader，接着这个leader会负责制定分区方案</li></ol></li><li>SYNC&nbsp;GROUP<ol><li>consumer&nbsp;leader通过给GroupCoordinator发送SyncGroupRequest</li><li>接着GroupCoordinator就把分区方案下发给各个consumer，他们会根据指定分区的leader&nbsp;broker进行网络连接以及消息消费</li></ol></li></ol></li></ul><p><img src="/static/IT/Kafka/Kafka-%E8%AE%BE%E8%AE%A1%E5%8E%9F%E7%90%86-1.png" alt="Rebalance"></p><hr><h2 id="消息发布机制">消息发布机制</h2><ul><li>producer发布消息机制<ul><li>写入方式：producer&nbsp;采用&nbsp;push&nbsp;模式将消息发布到&nbsp;broker，每条消息都被&nbsp;append&nbsp;到&nbsp;patition&nbsp;中，属于顺序写磁盘（顺序写磁盘效率比随机写内存要高，保障&nbsp;kafka&nbsp;吞吐率）</li><li>消息路由：producer&nbsp;发送消息到&nbsp;broker&nbsp;时，会根据分区算法选择将其存储到哪一个&nbsp;partition<ol><li>指定了&nbsp;patition，则直接使用</li><li>指定&nbsp;patition&nbsp;但指定&nbsp;key，通过对&nbsp;key&nbsp;的&nbsp;value&nbsp;进行 hash&nbsp;选出一个&nbsp;patition</li><li>patition&nbsp;和&nbsp;key&nbsp;都未指定，使用轮询选出一个&nbsp;patition</li></ol></li><li>写入流程<ol><li>producer&nbsp;先从&nbsp;zookeeper&nbsp;的&nbsp;“/brokers/…/state”&nbsp;节点找到该&nbsp;partition&nbsp;的&nbsp;leader</li><li>producer&nbsp;将消息发送给该&nbsp;leader</li><li>leader&nbsp;将消息写入本地&nbsp;log</li><li>followers&nbsp;从&nbsp;leader&nbsp;pull&nbsp;消息，写入本地&nbsp;log&nbsp;后向leader&nbsp;发送&nbsp;ACK</li><li>leader&nbsp;收到所有&nbsp;ISR&nbsp;中的&nbsp;replica&nbsp;的&nbsp;ACK&nbsp;后，增加&nbsp;HW（high&nbsp;watermark，最后&nbsp;commit&nbsp;的&nbsp;offset）&nbsp;并向&nbsp;producer&nbsp;发送&nbsp;ACK</li></ol></li></ul></li></ul><p><img src="/static/IT/Kafka/Kafka-%E8%AE%BE%E8%AE%A1%E5%8E%9F%E7%90%86-2.png" alt="消息发布机制"></p><hr><h2 id="HW与LEO">HW与LEO</h2><ul><li>HW：HW俗称高水位，HighWatermark的缩写，取一个partition对应的ISR中最小的LEO(log-end-offset)作为HW，consumer最多只能消费到HW所在的位置。<ul><li>每个replica都有HW，leader和follower各自负责更新自己的HW的状态。</li><li>对于leader新写入的消息，consumer不能立刻消费，leader会等待该消息被所有ISR中的replicas同步后更新HW，消息才能被consumer消费。</li><li>这样就保证了如果leader所在的broker失效，该消息仍然可以从新选举的leader中获取。</li><li>对于来自内部broker的读取请求，没有HW的限制</li></ul></li><li>当producer生产消息至broker后，ISR以及HW和LEO的流转过程<ul><li><img src="/static/IT/Kafka/Kafka-%E8%AE%BE%E8%AE%A1%E5%8E%9F%E7%90%86-3.png" alt="HW"></li></ul></li><li>Kafka的复制机制既不是完全的同步复制，也不是单纯的异步复制，很好的均衡了确保数据不丢失以及吞吐率</li><li>当 acks=1<ul><li><img src="/static/IT/Kafka/Kafka-%E8%AE%BE%E8%AE%A1%E5%8E%9F%E7%90%86-4.png" alt="acks=1"></li></ul></li></ul><hr><h2 id="日志分段">日志分段</h2><ul><li>日志分段存储：Kafka&nbsp;一个分区的消息数据对应存储在一个文件夹下，以topic名称+分区号命名，消息在分区内是分段(segment)存储，每个段的消息都存储在不一样的log文件里，这种特性方便old&nbsp;segment&nbsp;file快速被删除，kafka规定了一个段位的&nbsp;log&nbsp;文件最大为&nbsp;1G，做这个限制目的是为了方便把&nbsp;log&nbsp;文件加载到内存去操作<ul><li>00000000000000000000.index：部分消息的offset索引文件，kafka每次往分区发4K(可配置)消息就会记录一条当前消息的offset到index文件<ul><li>如果要定位消息的offset会先在这个文件里快速定位，再去log文件里找具体消息</li></ul></li><li>00000000000000000000.log：消息存储文件，主要存offset和消息体</li><li>00000000000000000000.timeindex：息的发送时间索引文件，kafka每次往分区发4K(可配置)消息就会记录一条当前消息的发送时间戳与对应的offset到timeindex文件<ul><li>如果需要按照时间来定位消息的offset，会先在这个文件里查找</li></ul></li><li>文件名00000000000000000000就是表了这个日志段文件里包含的起始&nbsp;Offset</li></ul></li><li>log.segment.bytes：限定了每个日志段文件的大小，最大就是&nbsp;1GB<ul><li>一个日志段文件满了，就自动开一个新的日志段文件来写入，避免单个文件过大，影响文件的读写性能，这个过程叫做log&nbsp;rolling，正在被写入的那个日志段文件，叫做&nbsp;active&nbsp;log&nbsp;segment。</li></ul></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;ul&gt;
&lt;li&gt;Controller&lt;/li&gt;
&lt;li&gt;Leader - Partition&lt;/li&gt;
&lt;li&gt;Rebalance&lt;/li&gt;
&lt;li&gt;消息发布机制&lt;/li&gt;
&lt;li&gt;HW与LEO&lt;/li&gt;
&lt;li&gt;日志分段&lt;/li&gt;
&lt;li&gt;zookeeper&lt;/li&gt;
&lt;/u</summary>
      
    
    
    
    <category term="IT学习笔记" scheme="https://jxch.github.io/categories/IT%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="Kafka" scheme="https://jxch.github.io/tags/Kafka/"/>
    
  </entry>
  
  <entry>
    <title>Linux (Ubuntu) 的流量监控与限制（月100G）</title>
    <link href="https://jxch.github.io/2024/08/21/architect/yun-wei/linux-ubuntu-de-liu-liang-jian-kong-yu-xian-zhi-yue-100g/"/>
    <id>https://jxch.github.io/2024/08/21/architect/yun-wei/linux-ubuntu-de-liu-liang-jian-kong-yu-xian-zhi-yue-100g/</id>
    <published>2024-08-21T01:27:51.000Z</published>
    <updated>2024-08-30T07:33:53.955Z</updated>
    
    <content type="html"><![CDATA[<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">sudo</span> <span class="token function">apt</span> update<span class="token function">sudo</span> <span class="token function">apt</span> <span class="token function">install</span> iptables iproute2 iptables-persistent <span class="token parameter variable">-y</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h2 id="iptables"><code>iptables</code></h2><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 创建一个新的iptables链来跟踪流量</span><span class="token function">sudo</span> iptables <span class="token parameter variable">-N</span> TRAFFIC_TRACKING<span class="token comment"># 将所有流量传送到新链</span><span class="token function">sudo</span> iptables <span class="token parameter variable">-A</span> INPUT <span class="token parameter variable">-j</span> TRAFFIC_TRACKING<span class="token function">sudo</span> iptables <span class="token parameter variable">-A</span> OUTPUT <span class="token parameter variable">-j</span> TRAFFIC_TRACKING<span class="token comment"># 跟踪下载流量（入站流量）</span><span class="token function">sudo</span> iptables <span class="token parameter variable">-A</span> TRAFFIC_TRACKING <span class="token parameter variable">-m</span> conntrack <span class="token parameter variable">--ctstate</span> ESTABLISHED,RELATED <span class="token parameter variable">-j</span> RETURN<span class="token comment"># 确保SSH流量不被限制</span><span class="token function">sudo</span> iptables <span class="token parameter variable">-A</span> TRAFFIC_TRACKING <span class="token parameter variable">-p</span> tcp <span class="token parameter variable">--dport</span> <span class="token number">22</span> <span class="token parameter variable">-j</span> RETURN  <span class="token comment"># 计数流量</span><span class="token function">sudo</span> iptables <span class="token parameter variable">-A</span> TRAFFIC_TRACKING <span class="token parameter variable">-m</span> conntrack <span class="token parameter variable">--ctstate</span> NEW <span class="token parameter variable">-j</span> ACCEPT<span class="token function">sudo</span> iptables <span class="token parameter variable">-A</span> TRAFFIC_TRACKING <span class="token parameter variable">-m</span> conntrack <span class="token parameter variable">--ctstate</span> ESTABLISHED <span class="token parameter variable">-j</span> ACCEPT<span class="token comment"># 记录流量，104857600000字节等于100GB</span><span class="token function">sudo</span> iptables <span class="token parameter variable">-A</span> TRAFFIC_TRACKING <span class="token parameter variable">-m</span> connbytes <span class="token parameter variable">--connbytes</span> <span class="token number">0</span>:104857600000 --connbytes-dir both --connbytes-mode bytes <span class="token parameter variable">-j</span> RETURN<span class="token comment"># 如果流量超过100GB，丢弃新的连接</span><span class="token function">sudo</span> iptables <span class="token parameter variable">-A</span> TRAFFIC_TRACKING <span class="token parameter variable">-m</span> connbytes <span class="token parameter variable">--connbytes</span> <span class="token number">104857600000</span>: --connbytes-dir both --connbytes-mode bytes <span class="token parameter variable">-j</span> DROP<span class="token comment"># 保存并应用iptables规则，确保iptables规则在重启后依然生效</span><span class="token function">sudo</span> <span class="token function">mkdir</span> <span class="token parameter variable">-p</span> /etc/iptables<span class="token function">sudo</span> <span class="token function">sh</span> <span class="token parameter variable">-c</span> <span class="token string">"iptables-save &gt; /etc/iptables/rules.v4"</span><span class="token comment"># 验证流量限制，查看流量统计情况</span><span class="token function">sudo</span> iptables <span class="token parameter variable">-L</span> <span class="token parameter variable">-v</span> <span class="token parameter variable">-n</span> <span class="token parameter variable">-t</span> filter<span class="token function">sudo</span> iptables <span class="token parameter variable">-L</span> TRAFFIC_TRACKING <span class="token parameter variable">-v</span> <span class="token parameter variable">-n</span><span class="token comment"># 定时任务设置每月重置流量计数</span><span class="token function">sudo</span> <span class="token function">crontab</span> <span class="token parameter variable">-e</span><span class="token comment"># 选择1，在文件最后加入一行，CTRL+O保存，Enter确认文件名，CTRL+X退出nano编辑器</span><span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> * * /sbin/iptables <span class="token parameter variable">-Z</span> TRAFFIC_TRACKING<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="netfilter-persistent"><code>netfilter-persistent</code></h2><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 保存iptables规则</span><span class="token function">sudo</span> netfilter-persistent save<span class="token comment"># 重启服务</span><span class="token function">sudo</span> systemctl restart netfilter-persistent<span class="token comment"># 或者刚启动服务</span><span class="token function">sudo</span> systemctl start netfilter-persistent<span class="token function">sudo</span> systemctl <span class="token builtin class-name">enable</span> netfilter-persistent<span class="token function">sudo</span> systemctl status netfilter-persistent<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="监控统计">监控统计</h2><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 一行命令输出已经用了多少GB</span><span class="token function">sudo</span> iptables <span class="token parameter variable">-L</span> TRAFFIC_TRACKING <span class="token parameter variable">-v</span> <span class="token parameter variable">-n</span> <span class="token operator">|</span> <span class="token function">awk</span> <span class="token string">'/0.0.0.0\/0/ {sum += $2} END {print "Used GB: ", sum / 1073741824}'</span><span class="token comment"># 或者</span><span class="token function">sudo</span> iptables <span class="token parameter variable">-L</span> TRAFFIC_TRACKING <span class="token parameter variable">-v</span> <span class="token parameter variable">-n</span> <span class="token operator">|</span> <span class="token function">grep</span> <span class="token string">'0.0.0.0/0'</span> <span class="token operator">|</span> <span class="token function">awk</span> <span class="token string">'{sum += $2} END {print "Used GB: " sum/1073741824}'</span><span class="token comment"># 用了多少MB</span><span class="token function">sudo</span> iptables <span class="token parameter variable">-L</span> TRAFFIC_TRACKING <span class="token parameter variable">-v</span> <span class="token parameter variable">-n</span> <span class="token operator">|</span> <span class="token function">awk</span> <span class="token string">'/0.0.0.0\/0/ {sum += $2} END {print "Used MB: " sum/1048576}'</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;pre class=&quot;line-numbers language-bash&quot; data-language=&quot;bash&quot;&gt;&lt;code class=&quot;language-bash&quot;&gt;&lt;span class=&quot;token function&quot;&gt;sudo&lt;/span&gt; &lt;span clas</summary>
      
    
    
    
    <category term="运维手册" scheme="https://jxch.github.io/categories/%E8%BF%90%E7%BB%B4%E6%89%8B%E5%86%8C/"/>
    
    
    <category term="Linux" scheme="https://jxch.github.io/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>Java并发-synchronized</title>
    <link href="https://jxch.github.io/2024/06/13/architect/java-bing-fa/java-bing-fa-synchronized/"/>
    <id>https://jxch.github.io/2024/06/13/architect/java-bing-fa/java-bing-fa-synchronized/</id>
    <published>2024-06-13T03:46:49.000Z</published>
    <updated>2024-08-30T07:00:54.111Z</updated>
    
    <content type="html"><![CDATA[<ul><li>synchronized是JVM内置锁，基于Monitor机制实现，依赖底层操作系统的互斥原语Mutex（互斥量），被阻塞的线程会被挂起、等待重新调度，会导致“用户态和内核态”两个态之间来回切换，对性能有较大影响</li><li>Monitor，直译为“监视器”，而操作系统领域一般翻译为“管程”。管程是指管理共享变量以及对共享变量操作的过程，让它们支持并发。</li><li>Java&nbsp;参考了&nbsp;MESA&nbsp;模型（管程中引入了条件变量的概念，而且每个条件变量都对应有一个等待队列），语言内置的管程（synchronized）对&nbsp;MESA&nbsp;模型进行了精简。MESA&nbsp;模型中，条件变量可以有多个，Java&nbsp;语言内置的管程里只有一个条件变量</li><li>Object&nbsp;类定义了&nbsp;wait()，notify()，notifyAll()&nbsp;方法，这些方法的具体实现，依赖于&nbsp;ObjectMonitor&nbsp;实现<ul><li>在获取锁时，是将当前线程插入到cxq的头部，而释放锁时，默认策略（QMode=0）是：如果EntryList为空，则将 cxq中的元素按原有顺序插入到EntryList，并唤醒第一个线程，也就是当EntryList为空时，是后来的线程先获取 锁。EntryList不为空，直接从EntryList中唤醒线程</li><li>锁状态被记录在每个对象的对象头的Mark&nbsp;Word中</li></ul></li></ul><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">ObjectMonitor()&nbsp;{_header&nbsp;=&nbsp;NULL;&nbsp;//对象头&nbsp;markOop_recursions&nbsp;=&nbsp;0;&nbsp;//&nbsp;锁的重入次数_object&nbsp;=&nbsp;NULL;&nbsp;//存储锁对象_owner&nbsp;=&nbsp;NULL;&nbsp;//&nbsp;标识拥有该monitor的线程（当前获取锁的线程）_WaitSet&nbsp;=&nbsp;NULL;&nbsp;//&nbsp;等待线程（调用wait）组成的双向循环链表，_WaitSet是第一个节点_cxq&nbsp;=&nbsp;NULL&nbsp;;&nbsp;//多线程竞争锁会先存到这个单向链表中&nbsp;（FILO栈结构）_EntryList&nbsp;=&nbsp;NULL&nbsp;;&nbsp;//存放在进入或重新进入时被阻塞(blocked)的线程&nbsp;(也是竞争锁失败的线程)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="/static/architect/Java%E5%B9%B6%E5%8F%91-synchronized-1.png" alt=""><br><img src="/static/architect/Java%E5%B9%B6%E5%8F%91-synchronized-2.png" alt=""></p><hr><h2 id="对象的内存布局">对象的内存布局</h2><p>Hotspot虚拟机中，对象在内存中存储的布局可以分为三块区域</p><ul><li>对象头（Header）：比如&nbsp;hash码，对象所属的年代，对象锁，锁状态标志，偏向锁（线程）ID，偏向时间，数组长度（数组对象才有）</li><li>实例数据 （Instance&nbsp;Data）：存放类的属性数据信息，包括父类的属性信息</li><li>对齐填充（Padding）：对象起始地址必须是8字节的整数倍</li></ul><p><img src="/static/architect/Java%E5%B9%B6%E5%8F%91-synchronized-3.png" alt=""></p><h3 id="对象头">对象头</h3><p>HotSpot虚拟机的对象头包括</p><ul><li>Mark&nbsp;Word：用于存储对象自身的运行时数据，如哈希码（HashCode）、GC分代年龄、锁状态标志、线程持有的锁、偏向线程ID、偏向时间戳等，这部分数据的长度在32位和64位的虚拟机中分别为32bit和64bit</li><li>Klass&nbsp;Pointer：对象头的另外一部分是klass类型指针，即对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例。&nbsp;32位4字节，64位开启指针压缩或最大堆内存&lt;32g时4字节，否则8字节（-XX:-UseCompressedOops 关闭指针压缩）</li><li>数组长度（只有数组对象有）：如果对象是一个数组,&nbsp;那在对象头中还必须有一块数据用于记录数组长度。&nbsp;4字节</li></ul><p><img src="/static/architect/Java%E5%B9%B6%E5%8F%91-synchronized-4.png" alt=""></p><p>使用JOL工具查看内存布局</p><ul><li>OFFSET：偏移地址，单位字节</li><li>SIZE：占用的内存大小，单位为字节</li><li>TYPE&nbsp;DESCRIPTION：类型描述，其中object&nbsp;header为对象头</li><li>VALUE：对应内存中当前存储的值，二进制32位</li></ul><pre class="line-numbers language-markup" data-language="markup"><code class="language-markup"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>org.openjdk.jol<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span> <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>jol‐core<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token class-name">ClassLayout</span><span class="token punctuation">.</span><span class="token function">parseInstance</span><span class="token punctuation">(</span>obj<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">toPrintable</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="Mark-Word-记录锁状态（markOop-hpp）">Mark&nbsp;Word 记录锁状态（markOop.hpp）</h4><p><img src="/static/architect/Java%E5%B9%B6%E5%8F%91-synchronized-5.png" alt="32位"><br><img src="/static/architect/Java%E5%B9%B6%E5%8F%91-synchronized-6.png" alt="64位"></p><ul><li>hash：&nbsp;保存对象的哈希码。运行期间调用System.identityHashCode()来计算，延迟计算，并把结果赋值到这里</li><li>age：&nbsp;保存对象的分代年龄。表示对象被GC的次数，当该次数到达阈值的时候，对象就会转移到老年代</li><li>biased_lock：&nbsp;偏向锁标识位。由于无锁和偏向锁的锁标识都是&nbsp;01，没办法区分，这里引入一位的偏向锁标识位</li><li>lock：&nbsp;锁状态标识位。区分锁状态，但是11时表示对象待GC回收状态,&nbsp;只有最后2位锁标识(11)有效</li><li>JavaThread*：&nbsp;保存持有偏向锁的线程ID。偏向模式的时候，当某个线程持有对象的时候，对象这里就会被置为该线程的ID。&nbsp;在后面的操作中，就无需再进行尝试获取锁的动作。这个线程ID并不是JVM分配的线程ID号，和Java&nbsp;Thread中的ID是两个概念</li><li>epoch：&nbsp;保存偏向时间戳。偏向锁在CAS锁操作过程中，偏向性标识，表示对象更偏向哪个锁</li><li>ptr_to_lock_record：轻量级锁状态下，指向栈中锁记录的指针。当锁获取是无竞争时，JVM使用原子操作而不是OS互斥，这种技术称为轻量级锁定。在轻量级锁定的情况下，JVM通过CAS操作在对象的Mark&nbsp;Word中设置指向锁记录的指针</li><li>ptr_to_heavyweight_monitor：重量级锁状态下，指向对象监视器Monitor的指针。如果两个不同的线程同时在同一个对象上竞争，则必须将轻量级锁定升级到Monitor以管理等待的线程。在重量级锁定的情况下，JVM在对象的ptr_to_heavyweight_monitor设置指向Monitor的指针</li></ul><p><img src="/static/architect/Java%E5%B9%B6%E5%8F%91-synchronized-7.png" alt=""></p><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">enum&nbsp;{&nbsp;locked_value&nbsp;=&nbsp;0,&nbsp;//00&nbsp;轻量级锁unlocked_value&nbsp;=&nbsp;1,&nbsp;//001&nbsp;无锁monitor_value&nbsp;=&nbsp;2,&nbsp;//10&nbsp;监视器锁，也叫膨胀锁，也叫重量级锁 marked_value&nbsp;=&nbsp;3,&nbsp;//11&nbsp;GC标记biased_lock_pattern&nbsp;=&nbsp;5&nbsp;//101&nbsp;偏向锁};<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><hr><ul><li>偏向锁：偏向锁是一种针对加锁操作的优化手段，经过研究发现，在大多数情况下，锁不仅不存在多 线程竞争，而且总是由同一线程多次获得，因此为了消除数据在无竞争情况下锁重入（CAS操作）的开销而引入偏向锁。对于没有锁竞争的场合，偏向锁有很好的优化效果<ul><li>匿名偏向状态：新创建对象的Mark&nbsp;Word中的Thread&nbsp;Id为0，说明此时处于可偏向但未偏向任何线程，也叫做匿名偏向状态(anonymously&nbsp;biased)</li><li>偏向锁延迟偏向：HotSpot&nbsp;虚拟机在启动后有个&nbsp;4s&nbsp;的延迟才会对每个新建的对象开启偏向锁模式。JVM启动时会进行一系列的复杂活动，比如装载配置，系统类初始化等等。在这个过程中会使用大量synchronized关键字对对象加锁，且这些锁大多数都不是偏向锁。为了减少初始化时间，JVM默认延时加载偏向锁</li><li>偏向锁撤销<ul><li>调用对象HashCode：调用锁对象的obj.hashCode()或System.identityHashCode(obj)方法会导致该对象的偏向锁被撤销。因为对于一个对象，其HashCode只会生成一次并保存，偏向锁是没有地方保存hashcode的<ul><li>轻量级锁会在锁记录中记录&nbsp;hashCode</li><li>重量级锁会在&nbsp;Monitor&nbsp;中记录&nbsp;hashCode</li><li>当对象处于可偏向（也就是线程ID为0）和已偏向的状态下，调用HashCode计算将会使对象再也无法偏向<ul><li>当对象可偏向时，MarkWord将变成未锁定状态，并只能升级成轻量锁</li><li>当对象正处于偏向锁时，调用HashCode将使偏向锁强制升级成重量锁</li></ul></li></ul></li><li>调用wait/notify<ul><li>偏向锁状态执行obj.notify()&nbsp;会升级为轻量级锁</li><li>调用obj.wait(timeout)&nbsp;会升级为重量级锁</li></ul></li></ul></li><li>偏向锁批量重偏向&amp;批量撤销：当只有一个线程反复进入同步块时，偏向锁带来的性能开销基本可以忽略，但是当有其他线程尝试获得锁时，就需要等到safe&nbsp;point时，再将偏向锁撤销为无锁状态或升级为轻量级，会消耗一定的性能，所以在多线程竞争频繁的情况下，偏向锁不仅不能提高性能，还会导致性能下降。于是，就有了批量重偏向与批量撤销的机制<ul><li>批量重偏向：默认class偏向撤销阈值20<ul><li>以class为单位，为每个class维护一个偏向锁撤销计数器，每一次该class的对象发生偏向撤销操作时，该计数器+1，当这个值达到重偏向阈值（默认20）时，JVM就认为该class的偏向锁有问题，因此会进行批量重偏向</li></ul></li><li>批量撤销：默认class偏向撤销阈值40<ul><li>每个class对象会有一个对应的epoch字段，每个处于偏向锁状态对象的Mark&nbsp;Word中也有该字段，其初始值为创建该对象时class中的epoch的值。每次发生批量重偏向时，就将该值+1，同时遍历JVM中所有线程的栈，找到该class所有正处于加锁状态的偏向锁，将其epoch字段改为新值。下次获得锁时，发现当前对象的epoch值和class的epoch不相等，那就算当前已经偏向了其他线程，也不会执行撤销操作，而是直接通过CAS操作将其Mark&nbsp;Word的Thread&nbsp;Id&nbsp;改成当前线程Id</li><li>当达到重偏向阈值（默认20）后，假设该class计数器继续增长，当其达到批量撤销的阈值后（默认40），JVM就认为该class的使用场景存在多线程竞争，会标记该class为不可偏向，之后，对于该class的锁，直接走轻量级锁的逻辑</li></ul></li><li>应用场景<ul><li>批量重偏向（bulk&nbsp;rebias）机制是为了解决：一个线程创建了大量对象并执行了初始的同步操作，后来另一个线程也来将这些对象作为锁对象进行操作，这样会导致大量的偏向锁撤销操作</li><li>批量撤销（bulk&nbsp;revoke）机制是为了解决：在明显多线程竞争剧烈的场景下使用偏向锁是不合适的</li></ul></li><li>JVM参数<ul><li><code>-XX:BiasedLockingBulkRebiasThreshold</code>：偏向锁批量重偏向阈值</li><li><code>-XX:BiasedLockingBulkRevokeThreshold</code>：偏向锁批量撤销阈值</li></ul></li><li>批量重偏向和批量撤销是针对类的优化，和对象无关</li><li>偏向锁重偏向一次之后不可再次重偏向</li><li>当某个类已经触发批量撤销机制后，JVM会默认当前类产生了严重的问题，剥夺了该类的新实例对象使用偏向锁的权利</li></ul></li></ul></li><li>轻量级锁：倘若偏向锁失败，虚拟机并不会立即升级为重量级锁，它还会尝试使用一种称为轻量级锁的优化手段，此时Mark&nbsp;Word&nbsp;的结构也变为轻量级锁的结构。轻量级锁所适应的场景是线程交替执行同步块的场合，如果存在同一时间多个线程访问同一把锁的场合，就会导致轻量级锁膨胀为重量级锁<ul><li>轻量级锁所适应的场景是：线程交替执行同步块</li><li>偏向锁升级轻量级锁</li><li>CAS自旋修改Mark Word中锁记录的地址，失败超过一定次数轻量级锁会膨胀为重量级锁</li></ul></li><li>重量级锁<ul><li>自旋优化：重量级锁竞争的时候，还可以使用自旋来进行优化，如果当前线程自旋成功（即这时候持锁线程已经退出了同步块，释放了锁），这时当前线程就可以避免阻塞<ul><li>自旋会占用&nbsp;CPU&nbsp;时间，单核&nbsp;CPU&nbsp;自旋就是浪费，多核&nbsp;CPU&nbsp;自旋才能发挥优势</li><li>自旋是自适应的，比如对象刚刚的一次自旋操作成功过，那么认为这次自旋成功的可能性会高，就多自旋几次；反之，就少自旋甚至不自旋</li><li>不能控制是否开启自旋功能</li><li>自旋的目的是为了减少线程挂起的次数，尽量避免直接挂起线程（挂起操作涉及系统调用，存在用户态和内核态切换，这才是重量级锁最大的开销）</li></ul></li></ul></li><li>锁粗化：假设一系列的连续操作都会对同一个对象反复加锁及解锁，甚至加锁操作是出现在循环体中的，即使没有出现线程竞争，频繁地进行互斥同步操作也会导致不必要的性能损耗。如果JVM检测到有一连串零碎的操作都是对同一对象的加锁，将会扩大加锁同步的范围（即锁粗化）到整个操作序列的外部</li><li>锁消除：即删除不必要的加锁操作。锁消除是Java虚拟机在JIT编译期间，通过对运行上下文的扫描，去除不可能存在共享资源竞争的锁，通过锁消除，可以节省毫无意义的请求锁时间<ul><li><code>‐XX:+EliminateLocks</code> 开启锁消除</li></ul></li></ul><p><img src="/static/architect/Java%E5%B9%B6%E5%8F%91-synchronized-8.png" alt=""></p><hr><ul><li>逃逸分析（Escape&nbsp;Analysis）：是一种可以有效减少Java&nbsp;程序中同步负载和内存堆分配压力的跨函数全局数据流分析算法。通过逃逸分析，Java&nbsp;Hotspot编译器能够分析出一个新的对象的引用的使用范围从而决定是否要将这个对象分配到堆上<ul><li>逃逸分析的基本行为就是分析对象动态作用域</li><li>方法逃逸：对象逃出当前方法</li><li>线程逃逸：对象逃出当前线程</li><li>使用逃逸分析，编译器可以对代码做如下优化<ul><li>同步省略或锁消除（Synchronization&nbsp;Elimination）。如果一个对象被发现只能从一个线程被访问到，那么对于这个对象的操作可以不考虑同步</li><li>将堆分配转化为栈分配（Stack&nbsp;Allocation）。如果一个对象在子程序中被分配，要使指向该对象的指针永远不会逃逸，对象可能是栈分配的候选，而不是堆分配</li><li>分离对象或标量替换（Scalar&nbsp;Replacement）。有的对象可能不需要作为一个连续的内存结构存在也可以被访问到，那么对象的部分（或全部）可以不存储在内存，而是存储在CPU寄存器中</li></ul></li><li>JVM参数<ul><li><code>‐XX:+DoEscapeAnalysis</code> 开启逃逸分析</li><li><code>‐XX:+EliminateAllocations</code> 开启标量替换</li></ul></li></ul></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;ul&gt;
&lt;li&gt;synchronized是JVM内置锁，基于Monitor机制实现，依赖底层操作系统的互斥原语Mutex（互斥量），被阻塞的线程会被挂起、等待重新调度，会导致“用户态和内核态”两个态之间来回切换，对性能有较大影响&lt;/li&gt;
&lt;li&gt;Monitor，直译为“监视器</summary>
      
    
    
    
    <category term="IT学习笔记" scheme="https://jxch.github.io/categories/IT%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="Java并发" scheme="https://jxch.github.io/tags/Java%E5%B9%B6%E5%8F%91/"/>
    
  </entry>
  
  <entry>
    <title>Java并发-Semaphore &amp; CountDownLatch &amp; CyclicBarrier</title>
    <link href="https://jxch.github.io/2024/06/13/architect/java-bing-fa/java-bing-fa-semaphore-countdownlatch-cyclicbarrier/"/>
    <id>https://jxch.github.io/2024/06/13/architect/java-bing-fa/java-bing-fa-semaphore-countdownlatch-cyclicbarrier/</id>
    <published>2024-06-13T03:45:49.000Z</published>
    <updated>2024-08-30T07:00:48.443Z</updated>
    
    <content type="html"><![CDATA[<ul><li>Semaphore，俗称信号量，它是操作系统中PV操作（P表示通过；V表示释放）的原语在java的实现，它也是基于AbstractQueuedSynchronizer实现的，可以用于做流量控制，特别是公用资源有限的应用场景<ul><li>acquire()&nbsp;表示阻塞并获取许可</li><li>tryAcquire()&nbsp;方法在没有许可的情况下会立即返回&nbsp;false，要获取许可的线程不会阻塞</li><li>release()&nbsp;表示释放许可</li><li>int&nbsp;availablePermits()：返回此信号量中当前可用的许可证数</li><li>int&nbsp;getQueueLength()：返回正在等待获取许可证的线程数</li><li>boolean&nbsp;hasQueuedThreads()：是否有线程正在等待获取许可证</li><li>void&nbsp;reducePermit(int&nbsp;reduction)：减少&nbsp;reduction&nbsp;个许可证</li><li>Collection&nbsp;getQueuedThreads()：返回所有等待获取许可证的线程集合</li></ul></li><li>CountDownLatch（闭锁）是一个同步协助类，允许一个或多个线程等待，直到其他线程完成操作集<ul><li>CountDownLatch使用给定的计数值（count）初始化。await方法会阻塞直到当前的计数值（count）由于countDown方法的调用达到0，count为0之后所有等待的线程都会被释放，并且随后对await方法的调用都会立即返回。这是一个一次性现象&nbsp;——&nbsp;count不会被重置。如果你需要一个重置count的版本，那么请考虑使用CyclicBarrier</li><li>底层基于&nbsp;AbstractQueuedSynchronizer&nbsp;实现，CountDownLatch&nbsp;构造函数中指定的count直接赋给AQS的state；每次countDown()则都是release(1)减1，最后减到0时unpark阻塞线程；这一步是由最后一个执行countdown方法的线程执行的</li><li>调用await()方法时，当前线程就会判断state属性是否为0，如果为0，则继续往下执行，如果不为0，则使当前线程进入等待状态，直到某个线程将state属性置为0，其就会唤醒在await()方法中等待的线程</li></ul></li><li>Thread.&nbsp;join()：&nbsp;的实现原理是不停检查join线程是否存活，如果&nbsp;join&nbsp;线程存活则让当前线程永远等待</li><li>CyclicBarrier：字面意思回环栅栏（循环屏障），通过它可以实现让一组线程等待至某个状态（屏障点）之后再全部同时执行。叫做回环是因为当所有等待线程都被释放以后，CyclicBarrier可以被重用<ul><li>CyclicBarrier&nbsp;可以用于多线程计算数据，最后合并计算结果的场景</li></ul></li><li>CountDownLatch与CyclicBarrier的区别<ul><li>CountDownLatch的计数器只能使用一次，而CyclicBarrier的计数器可以使用reset()&nbsp;方法重置</li><li>CyclicBarrier还提供getNumberWaiting（可以获得CyclicBarrier阻塞的线程数量）、isBroken（用来知道阻塞的线程是否被中断）等方法</li><li>CountDownLatch会阻塞主线程，CyclicBarrier不会阻塞主线程，只会阻塞子线程</li><li>CountDownLatch和CyclicBarrier都能够实现线程之间的等待，只不过它们侧重点不同。CountDownLatch一般用于一个或多个线程，等待其他线程执行完任务后，再执行。CyclicBarrier一般用于一组线程互相等待至某个状态，然后这一组线程再同时执行</li><li>CyclicBarrier&nbsp;还可以提供一个&nbsp;barrierAction，合并多线程计算结果</li><li>CyclicBarrier是通过ReentrantLock的"独占锁"和Conditon来实现一组线程的阻塞唤醒的，而CountDownLatch则是通过AQS的“共享锁”实现</li></ul></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;ul&gt;
&lt;li&gt;Semaphore，俗称信号量，它是操作系统中PV操作（P表示通过；V表示释放）的原语在java的实现，它也是基于AbstractQueuedSynchronizer实现的，可以用于做流量控制，特别是公用资源有限的应用场景
&lt;ul&gt;
&lt;li&gt;acquire()&amp;</summary>
      
    
    
    
    <category term="IT学习笔记" scheme="https://jxch.github.io/categories/IT%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="Java并发" scheme="https://jxch.github.io/tags/Java%E5%B9%B6%E5%8F%91/"/>
    
  </entry>
  
  <entry>
    <title>Java并发-ReentrantReadWriteLock</title>
    <link href="https://jxch.github.io/2024/06/13/architect/java-bing-fa/java-bing-fa-reentrantreadwritelock/"/>
    <id>https://jxch.github.io/2024/06/13/architect/java-bing-fa/java-bing-fa-reentrantreadwritelock/</id>
    <published>2024-06-13T03:42:49.000Z</published>
    <updated>2024-08-30T07:00:42.865Z</updated>
    
    <content type="html"><![CDATA[<ul><li>写锁是独占的，读锁是共享的：读读可以并发；读写，写读，写写互斥。在读多写少的场景中，读写锁能够提供比排它锁更好的并发性和吞吐量<ul><li>读锁不支持条件变量</li><li>重入时升级不支持：持有读锁的情况下去获取写锁，会导致获取永久等待</li><li>重入时支持降级：&nbsp;持有写锁的情况下可以去获取读锁</li></ul></li><li>线程进入读锁的前提条件<ul><li>没有其他线程的写锁</li><li>没有写请求或者有写请求，但调用线程和持有锁的线程是同一个</li></ul></li><li>线程进入写锁的前提条件<ul><li>没有其他线程的读锁</li><li>没有其他线程的写锁</li></ul></li><li>读写锁有以下三个重要的特性<ul><li>公平选择性：支持非公平（默认）和公平的锁获取方式，吞吐量还是非公平优于公平</li><li>可重入：读锁和写锁都支持线程重入。以读写线程为例：读线程获取读锁后，能够再次获取读锁。写线程在获取写锁之后能够再次获取写锁，同时也可以获取读锁</li><li>锁降级：遵循获取写锁、再获取读锁最后释放写锁的次序，写锁能够降级成为读锁</li></ul></li><li>锁降级：锁降级指的是写锁降级成为读锁<ul><li>锁降级是指把持住（当前拥有的）写锁，再获取到读锁，随后释放（先前拥有的）写锁的过程</li><li>如果当前线程拥有写锁，然后将其释放，最后再获取读锁，这种分段完成的过程不能称之为锁降级</li><li>锁降级可以帮助我们拿到当前线程修改后的结果而不被其他线程所破坏，防止更新丢失</li></ul></li><li>锁降级中为什么要获取读锁：主要是为了保证数据的可见性<ul><li>如果当前线程不获取读锁而是直接释放写锁，假设此刻另一个线程（记作线程T）获取了写锁并修改了数据，那么当前线程无法感知线程T的数据更新</li><li>如果当前线程获取读锁，即遵循锁降级的步骤，则线程T将会被阻塞，直到当前线程使用数据并释放读锁之后，线程T才能获取写锁进行数据更新</li></ul></li><li>RentrantReadWriteLock不支持锁升级（把持读锁、获取写锁，最后释放读锁的过程）：目的也是保证数据可见性<ul><li>如果读锁已被多个线程获取，其中任意线程成功获取了写锁并更新了数据，则其更新对其他获取到读锁的线程是不可见的</li></ul></li><li>用一个变量如何维护多种状态：高16为表示读，低16为表示写<ul><li>通过位运算确定读锁和写锁的状态<ul><li>写状态，等于&nbsp;S&nbsp;&amp;&nbsp;0x0000FFFF（将高&nbsp;16&nbsp;位全部抹去）。&nbsp;当写状态加1，等于S+1</li><li>读状态，等于&nbsp;S&nbsp;&gt;&gt;&gt;&nbsp;16&nbsp;(无符号补&nbsp;0&nbsp;右移&nbsp;16&nbsp;位)。当读状态加1，等于 S +（1&lt;&lt;16）,也就是 S+0x00010000</li></ul></li><li>S不等于0时，当写状态（S&amp;0x0000FFFF）等于0时，读状态（S&gt;&gt;&gt;16）大于0，即读锁已被获取</li></ul></li><li>exclusiveCount(int&nbsp;c)&nbsp;静态方法，获得持有写状态的锁的次数</li><li>sharedCount(int&nbsp;c)&nbsp;静态方法，获得持有读状态的锁的线程数量。</li><li>HoldCounter&nbsp;计数器：不同于写锁，读锁可以同时被多个线程持有。而每个线程持有的读锁支持重入的特性，所以需要对每个线程持有的读锁的数量单独计数，这就需要用到&nbsp;HoldCounter&nbsp;计数器<ul><li>读锁的内在机制其实就是一个共享锁。一次共享锁的操作就相当于对HoldCounter&nbsp;计数器的操作。获取共享锁，则该计数器&nbsp;+&nbsp;1，释放共享锁，该计数器&nbsp;-&nbsp;1。只有当线程获取共享锁后才能对共享锁进行释放、重入操作</li><li>通过&nbsp;ThreadLocalHoldCounter&nbsp;类，HoldCounter&nbsp;与线程进行绑定。HoldCounter&nbsp;是绑定线程的一个计数器，而&nbsp;ThreadLocalHoldCounter&nbsp;则是线程绑定的&nbsp;ThreadLocal<ul><li>HoldCounter是用来记录读锁重入数的对象</li><li>ThreadLocalHoldCounter是ThreadLocal变量，用来存放不是第一个获取读锁的线程的其他线程的读锁重入数对象</li></ul></li></ul></li><li>写锁的获取：写锁是一个支持重进入的排它锁。如果当前线程已经获取了写锁，则增加写状态。如果当前线程在获取写锁时，读锁已经被获取（读状态不为0）或者该线程不是已经获取写锁的线程，&nbsp;则当前线程进入等待状态</li></ul><p><img src="/static/architect/Java%E5%B9%B6%E5%8F%91-ReentrantReadWriteLock-1.png" alt="写锁获取"><br><img src="/static/architect/Java%E5%B9%B6%E5%8F%91-ReentrantReadWriteLock-2.png" alt="写锁释放"><br><img src="/static/architect/Java%E5%B9%B6%E5%8F%91-ReentrantReadWriteLock-3.png" alt="读锁获取"><br><img src="/static/architect/Java%E5%B9%B6%E5%8F%91-ReentrantReadWriteLock-4.png" alt="读锁释放"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;ul&gt;
&lt;li&gt;写锁是独占的，读锁是共享的：读读可以并发；读写，写读，写写互斥。在读多写少的场景中，读写锁能够提供比排它锁更好的并发性和吞吐量
&lt;ul&gt;
&lt;li&gt;读锁不支持条件变量&lt;/li&gt;
&lt;li&gt;重入时升级不支持：持有读锁的情况下去获取写锁，会导致获取永久等待&lt;/li&gt;
&lt;</summary>
      
    
    
    
    <category term="IT学习笔记" scheme="https://jxch.github.io/categories/IT%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="Java并发" scheme="https://jxch.github.io/tags/Java%E5%B9%B6%E5%8F%91/"/>
    
  </entry>
  
</feed>

<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>PA &amp; CODING</title>
  
  <subtitle>求仁得仁</subtitle>
  <link href="https://jxch.github.io/atom.xml" rel="self"/>
  
  <link href="https://jxch.github.io/"/>
  <updated>2024-09-04T02:37:22.842Z</updated>
  <id>https://jxch.github.io/</id>
  
  <author>
    <name>钱不寒</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Kafka-代码模板</title>
    <link href="https://jxch.github.io/2024/09/04/architect/kafka/kafka-dai-ma-mo-ban/"/>
    <id>https://jxch.github.io/2024/09/04/architect/kafka/kafka-dai-ma-mo-ban/</id>
    <published>2024-09-04T02:32:49.000Z</published>
    <updated>2024-09-04T02:37:22.842Z</updated>
    
    <content type="html"><![CDATA[<ul><li>配置：<code>server.properties</code></li><li>绑定Kafka服务器</li><li>生产者配置</li><li>生产者发送消息</li><li>消费配置</li><li>消费者接收消息</li><li>消费提交</li><li>springboot 集成<ul><li>ack‐mode</li><li>生产者 &amp; 消费者</li></ul></li><li>Kafka事务</li></ul><hr><h2 id="配置：server-properties">配置：<code>server.properties</code></h2><ul><li>配置：<code>server.properties</code></li></ul><pre class="line-numbers language-properties" data-language="properties"><code class="language-properties"><span class="token comment">#broker.id属性在kafka集群中必须要是唯一</span><span class="token key attr-name">broker.id</span><span class="token punctuation">=</span><span class="token value attr-value">0</span><span class="token comment">#kafka部署的机器ip和提供服务的端口号</span><span class="token key attr-name">listeners</span><span class="token punctuation">=</span><span class="token value attr-value">PLAINTEXT://192.168.65.60:9092</span><span class="token comment">#kafka的消息存储文件</span><span class="token key attr-name">log.dir</span><span class="token punctuation">=</span><span class="token value attr-value">/usr/local/data/kafka‐logs</span><span class="token comment">#kafka连接zookeeper的地址</span><span class="token key attr-name">zookeeper.connect</span><span class="token punctuation">=</span><span class="token value attr-value">192.168.65.60:2181</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="绑定Kafka服务器">绑定Kafka服务器</h2><ul><li>绑定Kafka服务器</li></ul><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token class-name">Properties</span> props <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Properties</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ProducerConfig</span><span class="token punctuation">.</span><span class="token constant">BOOTSTRAP_SERVERS_CONFIG</span><span class="token punctuation">,</span> <span class="token string">"192.168.65.60:9092,192.168.65.60:9093,192.168.65.60:9094"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 生产者</span><span class="token class-name">Producer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> producer <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">KafkaProducer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span>props<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 消费者</span><span class="token class-name">KafkaConsumer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> consumer <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">KafkaConsumer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span>props<span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="生产者配置">生产者配置</h2><ul><li>生产者配置</li></ul><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token comment">/*  * 发出消息持久化机制参数 * acks=0： 表示producer不需要等待任何broker确认收到消息的回复，就可以继续发送下一条消息。性能最高，但是最容易丢消息 * acks=1： 至少要等待leader已经成功将数据写入本地log，但是不需要等待所有follower是否成功写入，就可以继续发送下一条消息 *          如果follower没有成功备份数据，而此时leader又挂掉，则消息会丢失 * acks=‐1或all： 需要等待 min.insync.replicas(默认为1，推荐配置大于等于2) 这个参数配置的副本个数都成功写入日志 *                这种策略会保证只要有一个备份存活就不会丢失数据。这是最强的数据保证。一般除非是金融级别，或跟钱打交道的场景才会使用这种配置 */</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ProducerConfig</span><span class="token punctuation">.</span><span class="token constant">ACKS_CONFIG</span><span class="token punctuation">,</span> <span class="token string">"1"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 发送失败重试次数，重试能保证消息发送的可靠性，但是也可能造成消息重复发送，需要接收者做好消息接收的幂等性处理</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ProducerConfig</span><span class="token punctuation">.</span><span class="token constant">RETRIES_CONFIG</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 重试间隔设置，默认重试间隔100ms</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ProducerConfig</span><span class="token punctuation">.</span><span class="token constant">RETRY_BACKOFF_MS_CONFIG</span><span class="token punctuation">,</span> <span class="token number">300</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 设置发送消息的本地缓冲区，如果设置了该缓冲区，消息会先发送到本地缓冲区，可以提高消息发送性能，默认值是33554432，即32MB</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ProducerConfig</span><span class="token punctuation">.</span><span class="token constant">BUFFER_MEMORY_CONFIG</span><span class="token punctuation">,</span> <span class="token number">33554432</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// kafka本地线程会从缓冲区取数据，批量发送到broker，设置批量发送消息的大小，默认值是16384，即16kb，就是说一个batch满了16kb就发送出去</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ProducerConfig</span><span class="token punctuation">.</span><span class="token constant">BATCH_SIZE_CONFIG</span><span class="token punctuation">,</span> <span class="token number">16384</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">/*  * batch最大的延迟发送时间 * 默认值是0：意思就是消息必须立即被发送，但这样会影响性能 * 一般设置10毫秒左右，就是说这个消息发送完后会进入本地的一个batch，如果10毫秒内，这个batch满了16kb就会随batch一起被发送出去 * 如果10毫秒内，batch没满，那么也必须把消息发送出去，不能让消息的发送延迟时间太长 *  *  消息 -&gt; 本地缓冲区（32M）-&gt; batch（16k）-&gt; 发送（10ms batch不满也发送） */</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ProducerConfig</span><span class="token punctuation">.</span><span class="token constant">LINGER_MS_CONFIG</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 把发送的key和value从字符串序列化为字节数组</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ProducerConfig</span><span class="token punctuation">.</span><span class="token constant">KEY_SERIALIZER_CLASS_CONFIG</span><span class="token punctuation">,</span> <span class="token class-name">StringSerializer</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">.</span><span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ProducerConfig</span><span class="token punctuation">.</span><span class="token constant">VALUE_SERIALIZER_CLASS_CONFIG</span><span class="token punctuation">,</span> <span class="token class-name">StringSerializer</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">.</span><span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="生产者发送消息">生产者发送消息</h2><ul><li>生产者发送消息：指定分区；不指定分区；同步；异步</li></ul><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token comment">// 指定发送分区</span><span class="token keyword">var</span> producerRecord <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ProducerRecord</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span><span class="token constant">TOPIC_NAME</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> key_json<span class="token punctuation">,</span> value_json<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 未指定发送分区，具体发送的分区计算公式：hash(key) % partitionNum</span><span class="token keyword">var</span> producerRecord <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ProducerRecord</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span><span class="token constant">TOPIC_NAME</span><span class="token punctuation">,</span> key_json<span class="token punctuation">,</span> value_json<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 等待消息发送成功的同步阻塞方法</span><span class="token class-name">RecordMetadata</span> metadata <span class="token operator">=</span> producer<span class="token punctuation">.</span><span class="token function">send</span><span class="token punctuation">(</span>producerRecord<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 异步回调方式发送消息</span>producer<span class="token punctuation">.</span><span class="token function">send</span><span class="token punctuation">(</span>producerRecord<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Callback</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span><span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">onCompletion</span><span class="token punctuation">(</span><span class="token class-name">RecordMetadata</span> metadata<span class="token punctuation">,</span> <span class="token class-name">Exception</span> exception<span class="token punctuation">)</span> <span class="token punctuation">{</span><span class="token comment">// 处理异常</span><span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 关闭</span>producer<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="消费配置">消费配置</h2><ul><li>消费配置</li></ul><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token comment">// 消费分组名</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ConsumerConfig</span><span class="token punctuation">.</span><span class="token constant">GROUP_ID_CONFIG</span><span class="token punctuation">,</span> <span class="token constant">CONSUMER_GROUP_NAME</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 是否自动提交offset，默认就是true</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ConsumerConfig</span><span class="token punctuation">.</span><span class="token constant">ENABLE_AUTO_COMMIT_CONFIG</span><span class="token punctuation">,</span> <span class="token string">"true"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 自动提交offset的间隔时间</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ConsumerConfig</span><span class="token punctuation">.</span><span class="token constant">AUTO_COMMIT_INTERVAL_MS_CONFIG</span><span class="token punctuation">,</span> <span class="token string">"1000"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">/*  * 当消费主题的是一个新的消费组，或者指定offset的消费方式，offset不存在，那么应该如何消费 * latest(默认) ：只消费自己启动之后发送到主题的消息 * earliest：第一次从头开始消费，以后按照消费offset记录继续消费，这个需要区别于 consumer.seekToBeginning(每次都从头开始消费) */</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ConsumerConfig</span><span class="token punctuation">.</span><span class="token constant">AUTO_OFFSET_RESET_CONFIG</span><span class="token punctuation">,</span> <span class="token string">"earliest"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// consumer给broker发送心跳的间隔时间，broker接收到心跳如果此时有rebalance发生会通过心跳响应将rebalance方案下发给consumer，这个时间可以稍微短一点</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ConsumerConfig</span><span class="token punctuation">.</span><span class="token constant">HEARTBEAT_INTERVAL_MS_CONFIG</span><span class="token punctuation">,</span> <span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 服务端broker多久感知不到一个consumer心跳就认为他故障了，会将其踢出消费组，对应的Partition也会被重新分配给其他consumer，默认是10秒</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ConsumerConfig</span><span class="token punctuation">.</span><span class="token constant">SESSION_TIMEOUT_MS_CONFIG</span><span class="token punctuation">,</span> <span class="token number">10</span> <span class="token operator">*</span> <span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 一次poll最大拉取消息的条数，如果消费者处理速度很快，可以设置大点，如果处理速度一般，可以设置小点</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ConsumerConfig</span><span class="token punctuation">.</span><span class="token constant">MAX_POLL_RECORDS_CONFIG</span><span class="token punctuation">,</span> <span class="token number">500</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 如果两次poll操作间隔超过了这个时间，broker就会认为这个consumer处理能力太弱，会将其踢出消费组，将分区分配给别的consumer消费</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ConsumerConfig</span><span class="token punctuation">.</span><span class="token constant">MAX_POLL_INTERVAL_MS_CONFIG</span><span class="token punctuation">,</span> <span class="token number">30</span> <span class="token operator">*</span> <span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 把发送的key和value从字符串序列化为字节数组</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ConsumerConfig</span><span class="token punctuation">.</span><span class="token constant">KEY_DESERIALIZER_CLASS_CONFIG</span><span class="token punctuation">,</span> <span class="token class-name">StringDeserializer</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">.</span><span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ConsumerConfig</span><span class="token punctuation">.</span><span class="token constant">VALUE_DESERIALIZER_CLASS_CONFIG</span><span class="token punctuation">,</span> <span class="token class-name">StringDeserializer</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">.</span><span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="消费者接收消息">消费者接收消息</h2><ul><li>消费者接收消息（topic）：指定分区；回溯（从头，指定offset）；拉取集合</li></ul><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token comment">// 订阅Topic</span>consumer<span class="token punctuation">.</span><span class="token function">subscribe</span><span class="token punctuation">(</span><span class="token class-name">Arrays</span><span class="token punctuation">.</span><span class="token function">asList</span><span class="token punctuation">(</span><span class="token constant">TOPIC_NAME</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 消费指定分区</span>consumer<span class="token punctuation">.</span><span class="token function">assign</span><span class="token punctuation">(</span><span class="token class-name">Arrays</span><span class="token punctuation">.</span><span class="token function">asList</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">TopicPartition</span><span class="token punctuation">(</span><span class="token constant">TOPIC_NAME</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 回溯消费（从头消费 - seekToBeginning）</span>consumer<span class="token punctuation">.</span><span class="token function">assign</span><span class="token punctuation">(</span><span class="token class-name">Arrays</span><span class="token punctuation">.</span><span class="token function">asList</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">TopicPartition</span><span class="token punctuation">(</span><span class="token constant">TOPIC_NAME</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>consumer<span class="token punctuation">.</span><span class="token function">seekToBeginning</span><span class="token punctuation">(</span><span class="token class-name">Arrays</span><span class="token punctuation">.</span><span class="token function">asList</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">TopicPartition</span><span class="token punctuation">(</span><span class="token constant">TOPIC_NAME</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 指定offset消费</span>consumer<span class="token punctuation">.</span><span class="token function">assign</span><span class="token punctuation">(</span><span class="token class-name">Arrays</span><span class="token punctuation">.</span><span class="token function">asList</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">TopicPartition</span><span class="token punctuation">(</span><span class="token constant">TOPIC_NAME</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>consumer<span class="token punctuation">.</span><span class="token function">seek</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">TopicPartition</span><span class="token punctuation">(</span><span class="token constant">TOPIC_NAME</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 从指定时间点开始消费 - 1小时前</span><span class="token class-name">List</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">PartitionInfo</span><span class="token punctuation">&gt;</span></span> topicPartitions <span class="token operator">=</span> consumer<span class="token punctuation">.</span><span class="token function">partitionsFor</span><span class="token punctuation">(</span><span class="token constant">TOPIC_NAME</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">long</span> fetchDataTime <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Date</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">getTime</span><span class="token punctuation">(</span><span class="token punctuation">)</span> ‐ <span class="token number">1000</span> <span class="token operator">*</span> <span class="token number">60</span> <span class="token operator">*</span> <span class="token number">60</span><span class="token punctuation">;</span><span class="token class-name">Map</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">TopicPartition</span><span class="token punctuation">,</span> <span class="token class-name">Long</span><span class="token punctuation">&gt;</span></span> map <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">HashMap</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token class-name">PartitionInfo</span> par <span class="token operator">:</span> topicPartitions<span class="token punctuation">)</span> <span class="token punctuation">{</span>map<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">TopicPartition</span><span class="token punctuation">(</span>topicName<span class="token punctuation">,</span> par<span class="token punctuation">.</span><span class="token function">partition</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> fetchDataTime<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token comment">// 遍历 value.offset(); 获取offset，然后指定offset消费</span><span class="token class-name">Map</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">TopicPartition</span><span class="token punctuation">,</span> <span class="token class-name">OffsetAndTimestamp</span><span class="token punctuation">&gt;</span></span> parMap <span class="token operator">=</span> consumer<span class="token punctuation">.</span><span class="token function">offsetsForTimes</span><span class="token punctuation">(</span>map<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 拉取消息集合</span><span class="token class-name">ConsumerRecords</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> records <span class="token operator">=</span> consumer<span class="token punctuation">.</span><span class="token function">poll</span><span class="token punctuation">(</span><span class="token class-name">Duration</span><span class="token punctuation">.</span><span class="token function">ofMillis</span><span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="消费提交">消费提交</h2><ul><li>消费提交（offset）：同步；异步</li></ul><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token comment">// 手动同步提交offset，当前线程会阻塞直到offset提交成功，一般使用同步提交，因为提交之后一般也没有什么逻辑代码了</span>consumer<span class="token punctuation">.</span><span class="token function">commitSync</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 手动异步提交offset，当前线程提交offset不会阻塞，可以继续处理后面的程序逻辑</span>consumer<span class="token punctuation">.</span><span class="token function">commitAsync</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">OffsetCommitCallback</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span><span class="token annotation punctuation">@Override</span><span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">onComplete</span><span class="token punctuation">(</span><span class="token class-name">Map</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">TopicPartition</span><span class="token punctuation">,</span> <span class="token class-name">OffsetAndMetadata</span><span class="token punctuation">&gt;</span></span> offsets<span class="token punctuation">,</span> <span class="token class-name">Exception</span> ex<span class="token punctuation">)</span> <span class="token punctuation">{</span><span class="token comment">// 处理异常</span><span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><hr><h2 id="springboot-集成">springboot 集成</h2><ul><li>springboot配置application.yml</li></ul><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token key atrule">spring</span><span class="token punctuation">:</span><span class="token key atrule">kafka</span><span class="token punctuation">:</span><span class="token key atrule">bootstrap‐servers</span><span class="token punctuation">:</span> 192.168.65.60<span class="token punctuation">:</span><span class="token number">9092</span><span class="token punctuation">,</span>192.168.65.60<span class="token punctuation">:</span><span class="token number">9093</span><span class="token punctuation">,</span>192.168.65.60<span class="token punctuation">:</span><span class="token number">9094</span><span class="token key atrule">producer</span><span class="token punctuation">:</span><span class="token key atrule">retries</span><span class="token punctuation">:</span> <span class="token number">3</span><span class="token key atrule">batch‐size</span><span class="token punctuation">:</span> <span class="token number">16384</span><span class="token key atrule">buffer‐memory</span><span class="token punctuation">:</span> <span class="token number">33554432</span><span class="token key atrule">acks</span><span class="token punctuation">:</span> <span class="token number">1</span><span class="token key atrule">key‐serializer</span><span class="token punctuation">:</span> org.apache.kafka.common.serialization.StringSerializer<span class="token key atrule">value‐serializer</span><span class="token punctuation">:</span> org.apache.kafka.common.serialization.StringSerializer<span class="token key atrule">consumer</span><span class="token punctuation">:</span><span class="token key atrule">group‐id</span><span class="token punctuation">:</span> default‐group<span class="token key atrule">enable‐auto‐commit</span><span class="token punctuation">:</span> <span class="token boolean important">false</span><span class="token key atrule">auto‐offset‐reset</span><span class="token punctuation">:</span> earliest<span class="token key atrule">key‐deserializer</span><span class="token punctuation">:</span> xxx.StringDeserializer<span class="token key atrule">value‐deserializer</span><span class="token punctuation">:</span> xxx.StringDeserializer<span class="token key atrule">listener</span><span class="token punctuation">:</span><span class="token key atrule">ack‐mode</span><span class="token punctuation">:</span> manual_immediate<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="ack‐mode">ack‐mode</h3><ul><li>ack‐mode<ul><li>RECORD：当每一条记录被消费者监听器（ListenerConsumer）处理之后提交</li><li>BATCH：当每一批poll()的数据被消费者监听器处理之后提交</li><li>TIME：当每一批poll()的数据被消费者监听器处理之后，距离上次提交时间大于TIME时提交</li><li>COUNT：当每一批poll()的数据被消费者监听器处理之后，被处理record数量大于等于COUNT时提交</li><li>TIME&nbsp;|&nbsp;COUNT：有一个条件满足时提交</li><li>MANUAL：当每一批poll()的数据被消费者监听器处理之后,&nbsp;手动调用Acknowledgment.acknowledge()后提交</li><li>MANUAL_IMMEDIATE：手动调用Acknowledgment.acknowledge()后立即提交，一般使用这种（一次提交一条消息）</li></ul></li></ul><h3 id="生产者-消费者">生产者 &amp; 消费者</h3><ul><li>生产者</li></ul><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token annotation punctuation">@Autowired</span><span class="token keyword">private</span> <span class="token class-name">KafkaTemplate</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> kafkaTemplate<span class="token punctuation">;</span>kafkaTemplate<span class="token punctuation">.</span><span class="token function">send</span><span class="token punctuation">(</span><span class="token constant">TOPIC_NAME</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token string">"key"</span><span class="token punctuation">,</span> <span class="token string">"this is a msg"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><ul><li>消费者</li></ul><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token annotation punctuation">@KafkaListener</span><span class="token punctuation">(</span>topics <span class="token operator">=</span> <span class="token string">"my‐replicated‐topic"</span><span class="token punctuation">,</span>groupId <span class="token operator">=</span> <span class="token string">"zhugeGroup"</span><span class="token punctuation">)</span><span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">listenZhugeGroup</span><span class="token punctuation">(</span><span class="token class-name">ConsumerRecord</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> record<span class="token punctuation">,</span> <span class="token class-name">Acknowledgment</span> ack<span class="token punctuation">)</span> <span class="token punctuation">{</span><span class="token class-name">String</span> value <span class="token operator">=</span> record<span class="token punctuation">.</span><span class="token function">value</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>ack<span class="token punctuation">.</span><span class="token function">acknowledge</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment">//手动提交offset</span><span class="token punctuation">}</span><span class="token comment">// 配置多个消费组（再写一个消费组处理同一个topic）</span><span class="token annotation punctuation">@KafkaListener</span><span class="token punctuation">(</span>topics <span class="token operator">=</span> <span class="token string">"my‐replicated‐topic"</span><span class="token punctuation">,</span>groupId <span class="token operator">=</span> <span class="token string">"tulingGroup"</span><span class="token punctuation">)</span><span class="token comment">// 配置多个topic，concurrency就是同组下的消费者个数，就是并发消费数，必须小于等于分区总数</span><span class="token annotation punctuation">@KafkaListener</span><span class="token punctuation">(</span>groupId <span class="token operator">=</span> <span class="token string">"testGroup"</span><span class="token punctuation">,</span> topicPartitions <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token annotation punctuation">@TopicPartition</span><span class="token punctuation">(</span>topic <span class="token operator">=</span> <span class="token string">"topic1"</span><span class="token punctuation">,</span> partitions <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">"0"</span><span class="token punctuation">,</span> <span class="token string">"1"</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token annotation punctuation">@TopicPartition</span><span class="token punctuation">(</span>topic <span class="token operator">=</span> <span class="token string">"topic2"</span><span class="token punctuation">,</span> partitions <span class="token operator">=</span> <span class="token string">"0"</span><span class="token punctuation">,</span>partitionOffsets <span class="token operator">=</span> <span class="token annotation punctuation">@PartitionOffset</span><span class="token punctuation">(</span>partition <span class="token operator">=</span> <span class="token string">"1"</span><span class="token punctuation">,</span> initialOffset <span class="token operator">=</span> <span class="token string">"100"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">,</span>concurrency <span class="token operator">=</span> <span class="token string">"6"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><hr><h2 id="Kafka事务">Kafka事务</h2><ul><li>Kafka事务</li></ul><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token class-name">Properties</span> props <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Properties</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"bootstrap.servers"</span><span class="token punctuation">,</span> <span class="token string">"localhost:9092"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"transactional.id"</span><span class="token punctuation">,</span> <span class="token string">"my‐transactional‐id"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token class-name">Producer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> producer <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">KafkaProducer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span>props<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">StringSerializer</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">StringSerializer</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 初始化事务</span>producer<span class="token punctuation">.</span><span class="token function">initTransactions</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">try</span> <span class="token punctuation">{</span><span class="token comment">// 开启事务</span>producer<span class="token punctuation">.</span><span class="token function">beginTransaction</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 发到不同的主题的不同分区</span>producer<span class="token punctuation">.</span><span class="token function">send</span><span class="token punctuation">(</span><span class="token comment">/*...*/</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 提交事务</span>producer<span class="token punctuation">.</span><span class="token function">commitTransaction</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">ProducerFencedException</span> <span class="token operator">|</span> <span class="token class-name">OutOfOrderSequenceException</span> <span class="token operator">|</span> <span class="token class-name">AuthorizationException</span> e<span class="token punctuation">)</span> <span class="token punctuation">{</span>producer<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">KafkaException</span> e<span class="token punctuation">)</span> <span class="token punctuation">{</span><span class="token comment">// 回滚事务</span>producer<span class="token punctuation">.</span><span class="token function">abortTransaction</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token comment">// 关闭</span>producer<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;ul&gt;
&lt;li&gt;配置：&lt;code&gt;server.properties&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;绑定Kafka服务器&lt;/li&gt;
&lt;li&gt;生产者配置&lt;/li&gt;
&lt;li&gt;生产者发送消息&lt;/li&gt;
&lt;li&gt;消费配置&lt;/li&gt;
&lt;li&gt;消费者接收消息&lt;/li&gt;
&lt;li&gt;消费提交&lt;</summary>
      
    
    
    
    <category term="IT学习笔记" scheme="https://jxch.github.io/categories/IT%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="Kafka" scheme="https://jxch.github.io/tags/Kafka/"/>
    
  </entry>
  
  <entry>
    <title>Kafka-优化</title>
    <link href="https://jxch.github.io/2024/09/04/architect/kafka/kafka-you-hua/"/>
    <id>https://jxch.github.io/2024/09/04/architect/kafka/kafka-you-hua/</id>
    <published>2024-09-04T02:27:49.000Z</published>
    <updated>2024-09-04T02:29:51.537Z</updated>
    
    <content type="html"><![CDATA[<ul><li>环境规划</li><li>线上问题</li><li>Kafka事务</li><li>Kafka高性能原因</li></ul><hr><h2 id="环境规划">环境规划</h2><ul><li>Kafka可视化管理工具：kafka-manager</li><li>线上环境规划<ul><li><img src="/static/IT/Kafka/Kafka-%E4%BC%98%E5%8C%96-1.png" alt="环境规划"></li></ul></li><li>JVM参数设置：bin/kafka-start-server.sh 中的jvm设置<ul><li><code>export&nbsp;KAFKA_HEAP_OPTS="‐Xmx16G&nbsp;‐Xms16G&nbsp;‐Xmn10G&nbsp;‐XX:MetaspaceSize=256M&nbsp;‐XX:+UseG1GC&nbsp;‐XX:MaxGCPauseMillis=50&nbsp;‐XX:G1HeapRegionSize=16M"</code></li><li>这种大内存的情况一般都要用G1垃圾收集器，因为年轻代内存比较大，用G1可以设置GC最大停顿时间，不至于一次minor&nbsp;gc就花费太长时间，当然，因为像kafka，rocketmq，es这些中间件，写数据到磁盘会用到操作系统的page&nbsp;cache，所以JVM内存不宜分配过大，需要给操作系统的缓存留出几个G</li></ul></li></ul><hr><h2 id="线上问题">线上问题</h2><ul><li>消息丢失<ul><li>发送端：acks 设置</li><li>消费端：如果消费这边配置的是自动提交，万一消费到数据还没处理完，就自动提交offset了，但是此时你consumer直接宕机了，未处理完的数据丢失了，下次也消费不到了</li></ul></li><li>重复消费：一般消费端都是要做消费幂等处理的<ul><li>发送端：发送消息如果配置了重试机制，比如网络抖动时间过长导致发送端发送超时，实际broker可能已经接收到消息，但发送方会重新发送消息</li><li>消费端：如果消费这边配置的是自动提交，刚拉取了一批数据处理了一部分，但还没来得及提交，服务挂了，下次重启又会拉取相同的一批数据重复处理</li></ul></li><li>消息乱序<ul><li>如果发送端配置了重试机制，kafka不会等之前那条消息完全发送成功才去发送下一条消息，这样可能会出现，发送了1，2，3条消息，第一条超时了，后面两条发送成功，再重试发送第1条消息，这时消息在broker端的顺序就是2，3，1了<ul><li>是否一定要配置重试要根据业务情况而定。也可以用同步发送的模式去发消息，当然acks不能设置为0</li></ul></li><li>kafka保证全链路消息顺序消费，需要从发送端开始，将所有有序消息发送到同一个分区，然后用一个消费者去消费，但是这种性能比较低<ul><li>可以在消费者端接收到消息后将需要保证顺序消费的几条消费发到内存队列(可以搞多个)，一个内存队列开启一个线程顺序处理消息</li></ul></li></ul></li><li>消息积压<ul><li>线上有时因为发送方发送消息速度过快，或者消费方处理消息过慢，可能会导致broker积压大量未消费消息<ul><li>如果积压了上百万未消费消息需要紧急处理，可以修改消费端程序，让其将收到的消息快速转发到其他topic(可以设置很多分区)，然后再启动多个消费者同时消费新主题的不同分区</li></ul></li><li>由于消息数据格式变动或消费者程序有bug，导致消费者一直消费不成功，也可能导致broker积压大量未消费消息<ul><li>可以将这些消费不成功的消息转发到其它队列里去(类似死信队列)，后面再慢慢分析死信队列里的消息处理问题</li></ul></li></ul></li><li>延时队列：消息被发送以后，并不想让消费者立刻获取，而是等待特定的时间后，消费者才能获取这个消息进行消费<ul><li>发送延时消息时先把消息按照不同的延迟时间段发送到指定的队列中（topic_1s，topic_5s，topic_10s，…topic_2h，这个一般不能支持任意时间段的延时）</li><li>通过定时器进行轮训消费这些topic，查看消息是否到期，如果到期就把这个消息发送到具体业务处理的topic中</li><li>队列中消息越靠前的到期时间越早，具体来说就是定时器在一次消费过程中，对消息的发送时间做判断，看下是否延迟到对应时间了，如果到了就转发，如果还没到这一次定时任务就可以提前结束了</li></ul></li><li>消息回溯：对之前已消费的消息重新消费<ul><li>如果某段时间对已消费消息计算的结果觉得有问题，可能是由于程序bug导致的计算错误，当程序bug修复后，这时可能需要对之前已消费的消息重新消费</li><li>可以指定从多久之前的消息回溯消费，这种可以用consumer的offsetsForTimes、seek等方法指定从某个offset偏移的消息开始消费</li></ul></li><li>分区数与吞吐量：一般情况分区数跟集群机器数量相当就差不多了<ul><li><code>kafka‐producer‐perf‐test.sh&nbsp;‐‐topic&nbsp;test&nbsp;‐‐num‐records&nbsp;1000000&nbsp;‐‐record‐size&nbsp;1024&nbsp;‐‐throughput&nbsp;‐1 ‐‐producer‐props&nbsp;bootstrap.servers=192.168.65.60:9092&nbsp;acks=1</code></li><li>往test里发送一百万消息，每条设置1KB，throughput&nbsp;用来进行限流控制，当设定的值小于&nbsp;0&nbsp;时不限流，当设定的值大于&nbsp;0&nbsp;时，当发送的吞吐量大于该值时就会被阻塞一段时间</li><li>如果分区数设置过大，比如设置10000，可能会设置不成功，后台会报错"java.io.IOException&nbsp;:&nbsp;Too&nbsp;many&nbsp;open&nbsp;files"<ul><li><code>ulimit&nbsp;-n 65535</code> 调大文件描述符</li></ul></li></ul></li><li>消息传递保障<ul><li>at&nbsp;most&nbsp;once（消费者最多收到一次消息，0-1次）：acks&nbsp;=&nbsp;0&nbsp;可以实现</li><li>at&nbsp;least&nbsp;once（消费者至少收到一次消息，1-多次）：ack&nbsp;=&nbsp;all&nbsp;可以实现</li><li>exactly&nbsp;once（消费者刚好收到一次消息）：at&nbsp;least&nbsp;once&nbsp;加上消费者幂等性可以实现，还可以用kafka生产者的幂等性来实现<ul><li>kafka生产者的幂等性：因为发送端重试导致的消息重复发送问题，kafka的幂等性可以保证重复发送的消息只接收一次<ul><li>只需在生产者加上参数&nbsp;<code>props.put("enable.idempotence",&nbsp;true)</code>&nbsp;即可，默认是 false 不开启</li><li>具体实现原理是，kafka每次发送消息会生成PID和Sequence&nbsp;Number，并将这两个属性一起发送给broker，broker会将PID和Sequence&nbsp;Number跟消息绑定一起存起来，下次如果生产者重发相同消息，broker会检查PID和Sequence&nbsp;Number，如果相同不会再接收<ul><li>PID：每个新的&nbsp;Producer&nbsp;在初始化的时候会被分配一个唯一的&nbsp;PID，这个PID&nbsp;对用户完全是透明的。生产者如果重启则会生成新的PID</li><li>Sequence&nbsp;Number：对于每个&nbsp;PID，该&nbsp;Producer&nbsp;发送到每个&nbsp;Partition&nbsp;的数据都有对应的序列号，这些序列号是从0开始单调递增的</li></ul></li><li>但是它只保证了生产者的幂等性，没保证消费者的幂等性，所以保险起见还是要再消费端考虑幂等性的问题</li></ul></li></ul></li></ul></li></ul><hr><h2 id="Kafka事务">Kafka事务</h2><ul><li>kafka的事务：保障一次发送多条消息的事务一致性（流式计算场景）<ul><li>Kafka的事务不同于Rocketmq，Rocketmq是保障本地事务(比如数据库)与mq消息发送的事务一致性，Kafka的事务主要是保障一次发送多条消息的事务一致性(要么同时成功要么同时失败)</li><li>一般在kafka的流式计算场景用得多一点，比如，kafka需要对一个topic里的消息做不同的流式计算处理，处理完分别发到不同的topic里，这些topic分别被不同的下游系统消费(比如hbase，redis，es等)，这种我们肯定希望系统发送到多个topic的数据保持事务一致性。Kafka要实现类似Rocketmq的分布式事务需要额外开发功能</li></ul></li></ul><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token class-name">Properties</span> props <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Properties</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"bootstrap.servers"</span><span class="token punctuation">,</span> <span class="token string">"localhost:9092"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"transactional.id"</span><span class="token punctuation">,</span> <span class="token string">"my‐transactional‐id"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token class-name">Producer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> producer <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">KafkaProducer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span>props<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">StringSerializer</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">StringSerializer</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 初始化事务</span>producer<span class="token punctuation">.</span><span class="token function">initTransactions</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">try</span> <span class="token punctuation">{</span><span class="token comment">// 开启事务</span>producer<span class="token punctuation">.</span><span class="token function">beginTransaction</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 发到不同的主题的不同分区</span>producer<span class="token punctuation">.</span><span class="token function">send</span><span class="token punctuation">(</span><span class="token comment">/*...*/</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 提交事务</span>producer<span class="token punctuation">.</span><span class="token function">commitTransaction</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">ProducerFencedException</span> <span class="token operator">|</span> <span class="token class-name">OutOfOrderSequenceException</span> <span class="token operator">|</span> <span class="token class-name">AuthorizationException</span> e<span class="token punctuation">)</span> <span class="token punctuation">{</span>producer<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">KafkaException</span> e<span class="token punctuation">)</span> <span class="token punctuation">{</span><span class="token comment">// 回滚事务</span>producer<span class="token punctuation">.</span><span class="token function">abortTransaction</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token comment">// 关闭</span>producer<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><hr><h2 id="Kafka高性能原因">Kafka高性能原因</h2><ul><li>kafka高性能的原因<ul><li>磁盘顺序读写：kafka消息不能修改以及不会从文件中间删除保证了磁盘顺序读，kafka的消息写入文件都是追加在文件末尾，不会写入文件中的某个位置(随机写)保证了磁盘顺序写</li><li>读写数据的批量batch处理以及压缩传输</li><li>数据传输的零拷贝<ul><li><img src="/static/IT/Kafka/Kafka-%E4%BC%98%E5%8C%96-2.png" alt="零拷贝"></li></ul></li></ul></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;ul&gt;
&lt;li&gt;环境规划&lt;/li&gt;
&lt;li&gt;线上问题&lt;/li&gt;
&lt;li&gt;Kafka事务&lt;/li&gt;
&lt;li&gt;Kafka高性能原因&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&quot;环境规划&quot;&gt;环境规划&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Kafka可视化管理工具：kafka-manager</summary>
      
    
    
    
    <category term="IT学习笔记" scheme="https://jxch.github.io/categories/IT%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="Kafka" scheme="https://jxch.github.io/tags/Kafka/"/>
    
  </entry>
  
  <entry>
    <title>Kafka-基础</title>
    <link href="https://jxch.github.io/2024/09/04/architect/kafka/kafka-ji-chu/"/>
    <id>https://jxch.github.io/2024/09/04/architect/kafka/kafka-ji-chu/</id>
    <published>2024-09-04T02:17:49.000Z</published>
    <updated>2024-09-04T02:23:16.282Z</updated>
    
    <content type="html"><![CDATA[<ul><li>核心组件</li><li>配置文件</li><li>基础命令</li><li>Topic</li><li>Kafka集群</li><li>Java客户端 &amp; SpringBoot支持</li></ul><hr><h2 id="核心组件">核心组件</h2><table><thead><tr><th>名称</th><th>解释</th></tr></thead><tbody><tr><td>Broker</td><td>消息中间件处理节点，一个Kafka节点就是一个broker，一<br>个或者多个Broker可以组成一个Kafka集群</td></tr><tr><td>Topic</td><td>Kafka根据topic对消息进行归类，发布到Kafka集群的每条<br>消息都需要指定一个topic</td></tr><tr><td>Producer</td><td>消息生产者，向Broker发送消息的客户端</td></tr><tr><td>Consumer</td><td>消息消费者，从Broker读取消息的客户端</td></tr><tr><td>ConsumerGroup</td><td>每个Consumer属于一个特定的Consumer&nbsp;Group，一条消<br>息可以被多个不同的Consumer&nbsp;Group消费，但是一个<br>Consumer&nbsp;Group中只能有一个Consumer能够消费该消息</td></tr><tr><td>Partition</td><td>物理上的概念，一个topic可以分为多个partition，每个<br>partition内部消息是有序的</td></tr></tbody></table><p><img src="/static/IT/Kafka/Kafka-%E5%9F%BA%E7%A1%80-1.png" alt="核心组件"></p><hr><h2 id="配置文件">配置文件</h2><ul><li>配置：<code>server.properties</code></li></ul><pre class="line-numbers language-properties" data-language="properties"><code class="language-properties"><span class="token comment">#broker.id属性在kafka集群中必须要是唯一</span><span class="token key attr-name">broker.id</span><span class="token punctuation">=</span><span class="token value attr-value">0</span><span class="token comment">#kafka部署的机器ip和提供服务的端口号</span><span class="token key attr-name">listeners</span><span class="token punctuation">=</span><span class="token value attr-value">PLAINTEXT://192.168.65.60:9092</span><span class="token comment">#kafka的消息存储文件</span><span class="token key attr-name">log.dir</span><span class="token punctuation">=</span><span class="token value attr-value">/usr/local/data/kafka‐logs</span><span class="token comment">#kafka连接zookeeper的地址</span><span class="token key attr-name">zookeeper.connect</span><span class="token punctuation">=</span><span class="token value attr-value">192.168.65.60:2181</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li>默认配置</li></ul><table><thead><tr><th>Property</th><th>Default</th><th>Description</th></tr></thead><tbody><tr><td><a href="http://broker.id">broker.id</a></td><td>0</td><td>每个broker都可以用一个唯一的非负整数id进行标识；这个id可以作为<br>broker的“名字”，你可以选择任意你喜欢的数字作为id，只要id是唯<br>一的即可</td></tr><tr><td>log.dirs</td><td>/tmp/kafka-logs</td><td>kafka存放数据的路径。这个路径并不是唯一的，可以是多个，路径之间<br>只需要使用逗号分隔即可；每当创建新partition时，都会选择在包含最<br>少partitions的路径下进行</td></tr><tr><td>listeners</td><td>PLAINTEXT://192.168.65.60:909</td><td>server接受客户端连接的端口，ip配置kafka本机ip即可</td></tr><tr><td>zookeeper.connect</td><td>localhost:2181</td><td>zooKeeper连接字符串的格式为：hostname:port，此处hostname和<br>port分别是ZooKeeper集群中某个节点的host和port；zookeeper如果<br>是集群，连接方式为&nbsp;hostname1:port1,&nbsp;hostname2:port2,&nbsp;<br>hostname3:port3</td></tr><tr><td>log.retention.hours</td><td>168</td><td>每个日志文件删除之前保存的时间。默认数据保存时间对所有topic都一样</td></tr><tr><td>num.partitions</td><td>1</td><td>创建topic的默认分区数</td></tr><tr><td>default.replication.factor</td><td>1</td><td>自动创建topic的默认副本数量，建议设置为大于等于2</td></tr><tr><td>min.insync.replicas</td><td>1</td><td>当producer设置acks为-1时，min.insync.replicas指定replicas的最小<br>数目（必须确认每一个repica的写数据都是成功的），如果这个数目没<br>有达到，producer发送消息会产生异常</td></tr><tr><td>delete.topic.enable</td><td>false</td><td>是否允许删除主题</td></tr></tbody></table><hr><h2 id="基础命令">基础命令</h2><ul><li>启动：<code>kafka‐server‐start.sh&nbsp;‐daemon&nbsp;server.properties</code><ul><li>­<code>-daemon</code> 表示以后台进程运行，否则ssh客户端退出后，就会停止服务</li><li>在启动kafka时会使用linux主机名关联的ip地址，所以需要把主机名和linux的ip映射配置到本地host里，用 <code>vim&nbsp;/etc/hosts</code></li></ul></li><li>停止：<code>kafka‐server‐stop.sh</code></li><li>创建主题：当producer发布一个消息到某个指定的Topic，这个Topic如果不存在，就自动创建<ul><li><code>kafka‐topics.sh&nbsp;‐‐create&nbsp;‐‐zookeeper&nbsp;192.168.65.60:2181&nbsp;‐‐replication‐factor&nbsp;1&nbsp;‐‐partitions&nbsp;1&nbsp;‐‐topic&nbsp;test</code></li><li><code>kafka‐topics.sh&nbsp;‐‐create&nbsp;‐‐zookeeper&nbsp;192.168.65.60:2181&nbsp;‐‐replication‐factor&nbsp;1&nbsp;‐‐partitions&nbsp;2&nbsp;‐‐topic&nbsp;test</code></li><li><code>kafka‐topics.sh&nbsp;‐‐list&nbsp;‐‐zookeeper&nbsp;192.168.65.60:2181</code></li></ul></li><li>查看Topic：<code>kafka‐topics.sh&nbsp;‐‐describe&nbsp;‐‐zookeeper&nbsp;192.168.65.60:2181&nbsp;‐‐topic&nbsp;test</code><ul><li>第一行是所有分区的概要信息，之后的每一行表示每一个partition的信息</li><li>leader节点负责给定partition的所有读写请求</li><li>replicas&nbsp;表示某个partition 在哪几个 broker上存在备份。不管这个几点是不是”leader“，甚至这个节点挂了，也会列出</li><li>isr&nbsp;是replicas的一个子集，它只列出当前还存活着的，并且已同步备份了该partition的节点。leader的选举也是从ISR(in-sync&nbsp;replica)中进行的</li></ul></li><li>增加Topic的分区数量（目前不支持减少分区）：<code>kafka‐topics.sh&nbsp;‐alter&nbsp;‐‐partitions&nbsp;3&nbsp;‐‐zookeeper&nbsp;192.168.65.60:2181&nbsp;‐‐topic&nbsp;test</code></li><li>删除主题：<code>kafka‐topics.sh&nbsp;‐‐delete&nbsp;‐‐topic&nbsp;test&nbsp;‐‐zookeeper&nbsp;192.168.65.60:2181</code></li><li>发送消息：<code>kafka‐console‐producer.sh&nbsp;‐‐broker‐list&nbsp;192.168.65.60:9092&nbsp;‐‐topic&nbsp;test</code></li><li>消费消息：默认是消费最新的消息<ul><li><code>kafka‐console‐consumer.sh&nbsp;‐‐bootstrap‐server&nbsp;192.168.65.60:9092&nbsp;‐‐topic&nbsp;test</code></li><li><code>kafka‐console‐consumer.sh&nbsp;‐‐bootstrap‐server&nbsp;192.168.65.60:9092&nbsp;‐‐from‐beginning&nbsp;‐‐topic&nbsp;test</code></li></ul></li><li>消费多主题：<code>kafka‐console‐consumer.sh&nbsp;‐‐bootstrap‐server&nbsp;192.168.65.60:9092&nbsp;‐‐whitelist&nbsp;"test|test‐2"</code></li><li>单播消费：只需让消费者在同一个消费组里即可<ul><li><code>kafka‐console‐consumer.sh&nbsp;‐‐bootstrap‐server&nbsp;192.168.65.60:9092&nbsp;‐‐consumer‐property&nbsp;group.id=testGroup&nbsp;‐‐topic&nbsp;test</code></li></ul></li><li>多播消费：只要保证这些消费者属于不同的消费组即可<ul><li><code>kafka‐console‐consumer.sh&nbsp;‐‐bootstrap‐server&nbsp;192.168.65.60:9092&nbsp;‐‐consumer‐property&nbsp;group.id=testGroup‐2&nbsp;‐‐topic test</code></li></ul></li><li>生产消费集群消息<ul><li><code>kafka‐console‐producer.sh&nbsp;‐‐broker‐list&nbsp;192.168.65.60:9092,192.168.65.60:9093,192.168.65.60:9094&nbsp;‐‐topic&nbsp;my‐replicated‐topic</code></li><li><code>kafka‐console‐consumer.sh&nbsp;‐‐bootstrap‐server&nbsp;192.168.65.60:9092,192.168.65.60:9093,192.168.65.60:9094&nbsp;‐‐from‐beginning&nbsp;‐‐topic&nbsp;my‐replicated‐topic</code></li></ul></li><li>查看消费组名：<code>kafka‐consumer‐groups.sh&nbsp;‐‐bootstrap‐server&nbsp;192.168.65.60:9092&nbsp;‐‐list</code></li><li>查看消费组的消费偏移量：<code>kafka‐consumer‐groups.sh&nbsp;‐‐bootstrap‐server&nbsp;192.168.65.60:9092&nbsp;‐‐describe&nbsp;‐‐group&nbsp;testGroup</code><ul><li>current-offset：当前消费组的已消费偏移量</li><li>log-end-offset：主题对应分区消息的结束偏移量(HW)</li><li>lag：当前消费组未消费的消息数</li></ul></li></ul><hr><h2 id="Topic">Topic</h2><ul><li>同类消息发送到同一个Topic下面。对于每一个Topic，下面可以有多个分区(Partition)日志文件<ul><li><img src="/static/IT/Kafka/Kafka-%E5%9F%BA%E7%A1%80-2.png" alt="Topic"></li><li>Partition是一个有序的message序列，这些message按顺序添加到一个叫做commit&nbsp;log的文件中。每个partition中的消息都有一个唯一的编号，称之为offset，用来唯一标示某个分区中的message</li><li>每个partition，都对应一个commit&nbsp;log文件。一个partition中的message的offset都是唯一的，但是不同的partition中的message的offset可能是相同的</li><li>kafka一般不会删除消息，不管这些消息有没有被消费。只会根据配置的日志保留时间(log.retention.hours)确认消息多久被删除，默认保留最近一周的日志消息。kafka的性能与保留的消息数据量大小没有关系，因此保存大量的数据消息日志信息不会有什么影响</li><li>每个consumer是基于自己在commit&nbsp;log中的消费进度(offset)来进行工作的。在kafka中，消费offset由consumer自己来维护；一般情况下我们按照顺序逐条消费commit&nbsp;log中的消息，当然可以通过指定offset来重复消费某些消息，或者跳过某些消息</li><li>这意味kafka中的consumer对集群的影响是非常小的，添加一个或者减少一个consumer，对于集群或者其他consumer来说，都是没有影响的，因为每个consumer维护各自的消费offset</li></ul></li><li>对Topic下数据进行分区存储<ul><li>commit&nbsp;log文件会受到所在机器的文件系统大小的限制，分区之后可以将不同的分区放在不同的机器上，相当于对数据做了分布式存储，理论上一个topic可以处理任意数量的数据</li><li>提高并行度</li></ul></li></ul><hr><h2 id="Kafka集群">Kafka集群</h2><ul><li>kafka集群：一个单独的broker意味着kafka集群中只有一个节点。要想增加kafka集群中的节点数量，只需要多启动几个broker实例即可<ul><li>kafka将很多集群关键信息记录在zookeeper里，保证自己的无状态，从而在水平扩容时非常方便</li></ul></li><li>集群消费<ul><li>log的partitions分布在kafka集群中不同的broker上，每个broker可以请求备份其他broker上partition上的数据。kafka集群支持配置一个partition备份的数量</li><li>针对每个partition，都有一个broker起到“leader”的作用，0个或多个其他的broker作为“follwers”的作用</li><li>leader处理所有的针对这个partition的读写请求，而followers被动复制leader的结果，不提供读写(主要是为了保证多副本数据与消费的一致性)。如果这个leader失效了，其中的一个follower将会自动的变成新的leader</li></ul></li><li>Producers：生产者将消息发送到topic中去，同时负责选择将message发送到topic的哪一个partition中。通过round­-robin做简单的负载均衡。也可以根据消息中的某一个关键字来进行区分。通常第二种方式使用的更多</li><li>Consumers：consumer&nbsp;group<ul><li>queue 模式：consumer 位于同一个 consumer&nbsp;group&nbsp;下</li><li>publish-subscribe 模式：consumer 有自己唯一的 consumer&nbsp;group</li><li><img src="/static/IT/Kafka/Kafka-%E5%9F%BA%E7%A1%80-3.png" alt="consumer&nbsp;group"></li></ul></li><li>消费顺序：一个partition同一个时刻在一个consumer&nbsp;group中只能有一个consumer&nbsp;instance在消费，从而保证消费顺序<ul><li>Kafka只在partition的范围内保证消息消费的局部顺序性，不能在同一个topic中的多个partition中保证总的消费顺序性</li><li>如果有在总体上保证消费顺序的需求，那么我们可以通过将topic的partition数量设置为1，将consumer&nbsp;group中的consumer&nbsp;instance数量也设置为1，但是这样会影响性能，所以kafka的顺序消费很少用</li><li>consumer&nbsp;group中的consumer&nbsp;instance的数量不能比一个Topic中的partition的数量多，否则，多出来的consumer消费不到消息</li></ul></li></ul><hr><h2 id="Java客户端">Java客户端</h2><ul><li>绑定Kafka服务器</li></ul><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token class-name">Properties</span> props <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Properties</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ProducerConfig</span><span class="token punctuation">.</span><span class="token constant">BOOTSTRAP_SERVERS_CONFIG</span><span class="token punctuation">,</span> <span class="token string">"192.168.65.60:9092,192.168.65.60:9093,192.168.65.60:9094"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 生产者</span><span class="token class-name">Producer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> producer <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">KafkaProducer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span>props<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 消费者</span><span class="token class-name">KafkaConsumer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> consumer <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">KafkaConsumer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span>props<span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li>生产者配置</li></ul><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token comment">/*  * 发出消息持久化机制参数 * acks=0： 表示producer不需要等待任何broker确认收到消息的回复，就可以继续发送下一条消息。性能最高，但是最容易丢消息 * acks=1： 至少要等待leader已经成功将数据写入本地log，但是不需要等待所有follower是否成功写入，就可以继续发送下一条消息 *          如果follower没有成功备份数据，而此时leader又挂掉，则消息会丢失 * acks=‐1或all： 需要等待 min.insync.replicas(默认为1，推荐配置大于等于2) 这个参数配置的副本个数都成功写入日志 *                这种策略会保证只要有一个备份存活就不会丢失数据。这是最强的数据保证。一般除非是金融级别，或跟钱打交道的场景才会使用这种配置 */</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ProducerConfig</span><span class="token punctuation">.</span><span class="token constant">ACKS_CONFIG</span><span class="token punctuation">,</span> <span class="token string">"1"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 发送失败重试次数，重试能保证消息发送的可靠性，但是也可能造成消息重复发送，需要接收者做好消息接收的幂等性处理</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ProducerConfig</span><span class="token punctuation">.</span><span class="token constant">RETRIES_CONFIG</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 重试间隔设置，默认重试间隔100ms</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ProducerConfig</span><span class="token punctuation">.</span><span class="token constant">RETRY_BACKOFF_MS_CONFIG</span><span class="token punctuation">,</span> <span class="token number">300</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 设置发送消息的本地缓冲区，如果设置了该缓冲区，消息会先发送到本地缓冲区，可以提高消息发送性能，默认值是33554432，即32MB</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ProducerConfig</span><span class="token punctuation">.</span><span class="token constant">BUFFER_MEMORY_CONFIG</span><span class="token punctuation">,</span> <span class="token number">33554432</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// kafka本地线程会从缓冲区取数据，批量发送到broker，设置批量发送消息的大小，默认值是16384，即16kb，就是说一个batch满了16kb就发送出去</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ProducerConfig</span><span class="token punctuation">.</span><span class="token constant">BATCH_SIZE_CONFIG</span><span class="token punctuation">,</span> <span class="token number">16384</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">/*  * batch最大的延迟发送时间 * 默认值是0：意思就是消息必须立即被发送，但这样会影响性能 * 一般设置10毫秒左右，就是说这个消息发送完后会进入本地的一个batch，如果10毫秒内，这个batch满了16kb就会随batch一起被发送出去 * 如果10毫秒内，batch没满，那么也必须把消息发送出去，不能让消息的发送延迟时间太长 *  *  消息 -&gt; 本地缓冲区（32M）-&gt; batch（16k）-&gt; 发送（10ms batch不满也发送） */</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ProducerConfig</span><span class="token punctuation">.</span><span class="token constant">LINGER_MS_CONFIG</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 把发送的key和value从字符串序列化为字节数组</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ProducerConfig</span><span class="token punctuation">.</span><span class="token constant">KEY_SERIALIZER_CLASS_CONFIG</span><span class="token punctuation">,</span> <span class="token class-name">StringSerializer</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">.</span><span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ProducerConfig</span><span class="token punctuation">.</span><span class="token constant">VALUE_SERIALIZER_CLASS_CONFIG</span><span class="token punctuation">,</span> <span class="token class-name">StringSerializer</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">.</span><span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li>生产者发送消息：指定分区；不指定分区；同步；异步</li></ul><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token comment">// 指定发送分区</span><span class="token keyword">var</span> producerRecord <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ProducerRecord</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span><span class="token constant">TOPIC_NAME</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> key_json<span class="token punctuation">,</span> value_json<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 未指定发送分区，具体发送的分区计算公式：hash(key) % partitionNum</span><span class="token keyword">var</span> producerRecord <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ProducerRecord</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span><span class="token constant">TOPIC_NAME</span><span class="token punctuation">,</span> key_json<span class="token punctuation">,</span> value_json<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 等待消息发送成功的同步阻塞方法</span><span class="token class-name">RecordMetadata</span> metadata <span class="token operator">=</span> producer<span class="token punctuation">.</span><span class="token function">send</span><span class="token punctuation">(</span>producerRecord<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 异步回调方式发送消息</span>producer<span class="token punctuation">.</span><span class="token function">send</span><span class="token punctuation">(</span>producerRecord<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Callback</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span><span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">onCompletion</span><span class="token punctuation">(</span><span class="token class-name">RecordMetadata</span> metadata<span class="token punctuation">,</span> <span class="token class-name">Exception</span> exception<span class="token punctuation">)</span> <span class="token punctuation">{</span><span class="token comment">// 处理异常</span><span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 关闭</span>producer<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li>消费配置</li></ul><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token comment">// 消费分组名</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ConsumerConfig</span><span class="token punctuation">.</span><span class="token constant">GROUP_ID_CONFIG</span><span class="token punctuation">,</span> <span class="token constant">CONSUMER_GROUP_NAME</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 是否自动提交offset，默认就是true</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ConsumerConfig</span><span class="token punctuation">.</span><span class="token constant">ENABLE_AUTO_COMMIT_CONFIG</span><span class="token punctuation">,</span> <span class="token string">"true"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 自动提交offset的间隔时间</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ConsumerConfig</span><span class="token punctuation">.</span><span class="token constant">AUTO_COMMIT_INTERVAL_MS_CONFIG</span><span class="token punctuation">,</span> <span class="token string">"1000"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">/*  * 当消费主题的是一个新的消费组，或者指定offset的消费方式，offset不存在，那么应该如何消费 * latest(默认) ：只消费自己启动之后发送到主题的消息 * earliest：第一次从头开始消费，以后按照消费offset记录继续消费，这个需要区别于 consumer.seekToBeginning(每次都从头开始消费) */</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ConsumerConfig</span><span class="token punctuation">.</span><span class="token constant">AUTO_OFFSET_RESET_CONFIG</span><span class="token punctuation">,</span> <span class="token string">"earliest"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// consumer给broker发送心跳的间隔时间，broker接收到心跳如果此时有rebalance发生会通过心跳响应将rebalance方案下发给consumer，这个时间可以稍微短一点</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ConsumerConfig</span><span class="token punctuation">.</span><span class="token constant">HEARTBEAT_INTERVAL_MS_CONFIG</span><span class="token punctuation">,</span> <span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 服务端broker多久感知不到一个consumer心跳就认为他故障了，会将其踢出消费组，对应的Partition也会被重新分配给其他consumer，默认是10秒</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ConsumerConfig</span><span class="token punctuation">.</span><span class="token constant">SESSION_TIMEOUT_MS_CONFIG</span><span class="token punctuation">,</span> <span class="token number">10</span> <span class="token operator">*</span> <span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 一次poll最大拉取消息的条数，如果消费者处理速度很快，可以设置大点，如果处理速度一般，可以设置小点</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ConsumerConfig</span><span class="token punctuation">.</span><span class="token constant">MAX_POLL_RECORDS_CONFIG</span><span class="token punctuation">,</span> <span class="token number">500</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 如果两次poll操作间隔超过了这个时间，broker就会认为这个consumer处理能力太弱，会将其踢出消费组，将分区分配给别的consumer消费</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ConsumerConfig</span><span class="token punctuation">.</span><span class="token constant">MAX_POLL_INTERVAL_MS_CONFIG</span><span class="token punctuation">,</span> <span class="token number">30</span> <span class="token operator">*</span> <span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 把发送的key和value从字符串序列化为字节数组</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ConsumerConfig</span><span class="token punctuation">.</span><span class="token constant">KEY_DESERIALIZER_CLASS_CONFIG</span><span class="token punctuation">,</span> <span class="token class-name">StringDeserializer</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">.</span><span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ConsumerConfig</span><span class="token punctuation">.</span><span class="token constant">VALUE_DESERIALIZER_CLASS_CONFIG</span><span class="token punctuation">,</span> <span class="token class-name">StringDeserializer</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">.</span><span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li>消费者接收消息（topic）：指定分区；回溯（从头，指定offset）；拉取集合</li></ul><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token comment">// 订阅Topic</span>consumer<span class="token punctuation">.</span><span class="token function">subscribe</span><span class="token punctuation">(</span><span class="token class-name">Arrays</span><span class="token punctuation">.</span><span class="token function">asList</span><span class="token punctuation">(</span><span class="token constant">TOPIC_NAME</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 消费指定分区</span>consumer<span class="token punctuation">.</span><span class="token function">assign</span><span class="token punctuation">(</span><span class="token class-name">Arrays</span><span class="token punctuation">.</span><span class="token function">asList</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">TopicPartition</span><span class="token punctuation">(</span><span class="token constant">TOPIC_NAME</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 回溯消费（从头消费 - seekToBeginning）</span>consumer<span class="token punctuation">.</span><span class="token function">assign</span><span class="token punctuation">(</span><span class="token class-name">Arrays</span><span class="token punctuation">.</span><span class="token function">asList</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">TopicPartition</span><span class="token punctuation">(</span><span class="token constant">TOPIC_NAME</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>consumer<span class="token punctuation">.</span><span class="token function">seekToBeginning</span><span class="token punctuation">(</span><span class="token class-name">Arrays</span><span class="token punctuation">.</span><span class="token function">asList</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">TopicPartition</span><span class="token punctuation">(</span><span class="token constant">TOPIC_NAME</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 指定offset消费</span>consumer<span class="token punctuation">.</span><span class="token function">assign</span><span class="token punctuation">(</span><span class="token class-name">Arrays</span><span class="token punctuation">.</span><span class="token function">asList</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">TopicPartition</span><span class="token punctuation">(</span><span class="token constant">TOPIC_NAME</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>consumer<span class="token punctuation">.</span><span class="token function">seek</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">TopicPartition</span><span class="token punctuation">(</span><span class="token constant">TOPIC_NAME</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 从指定时间点开始消费 - 1小时前</span><span class="token class-name">List</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">PartitionInfo</span><span class="token punctuation">&gt;</span></span> topicPartitions <span class="token operator">=</span> consumer<span class="token punctuation">.</span><span class="token function">partitionsFor</span><span class="token punctuation">(</span><span class="token constant">TOPIC_NAME</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">long</span> fetchDataTime <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Date</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">getTime</span><span class="token punctuation">(</span><span class="token punctuation">)</span> ‐ <span class="token number">1000</span> <span class="token operator">*</span> <span class="token number">60</span> <span class="token operator">*</span> <span class="token number">60</span><span class="token punctuation">;</span><span class="token class-name">Map</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">TopicPartition</span><span class="token punctuation">,</span> <span class="token class-name">Long</span><span class="token punctuation">&gt;</span></span> map <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">HashMap</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token class-name">PartitionInfo</span> par <span class="token operator">:</span> topicPartitions<span class="token punctuation">)</span> <span class="token punctuation">{</span>map<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">TopicPartition</span><span class="token punctuation">(</span>topicName<span class="token punctuation">,</span> par<span class="token punctuation">.</span><span class="token function">partition</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> fetchDataTime<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token comment">// 遍历 value.offset(); 获取offset，然后指定offset消费</span><span class="token class-name">Map</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">TopicPartition</span><span class="token punctuation">,</span> <span class="token class-name">OffsetAndTimestamp</span><span class="token punctuation">&gt;</span></span> parMap <span class="token operator">=</span> consumer<span class="token punctuation">.</span><span class="token function">offsetsForTimes</span><span class="token punctuation">(</span>map<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 拉取消息集合</span><span class="token class-name">ConsumerRecords</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> records <span class="token operator">=</span> consumer<span class="token punctuation">.</span><span class="token function">poll</span><span class="token punctuation">(</span><span class="token class-name">Duration</span><span class="token punctuation">.</span><span class="token function">ofMillis</span><span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li>消费提交（offset）：同步；异步</li></ul><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token comment">// 手动同步提交offset，当前线程会阻塞直到offset提交成功，一般使用同步提交，因为提交之后一般也没有什么逻辑代码了</span>consumer<span class="token punctuation">.</span><span class="token function">commitSync</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 手动异步提交offset，当前线程提交offset不会阻塞，可以继续处理后面的程序逻辑</span>consumer<span class="token punctuation">.</span><span class="token function">commitAsync</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">OffsetCommitCallback</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span><span class="token annotation punctuation">@Override</span><span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">onComplete</span><span class="token punctuation">(</span><span class="token class-name">Map</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">TopicPartition</span><span class="token punctuation">,</span> <span class="token class-name">OffsetAndMetadata</span><span class="token punctuation">&gt;</span></span> offsets<span class="token punctuation">,</span> <span class="token class-name">Exception</span> ex<span class="token punctuation">)</span> <span class="token punctuation">{</span><span class="token comment">// 处理异常</span><span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><hr><h2 id="SpringBoot支持">SpringBoot支持</h2><ul><li>springboot配置application.yml</li></ul><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token key atrule">spring</span><span class="token punctuation">:</span><span class="token key atrule">kafka</span><span class="token punctuation">:</span><span class="token key atrule">bootstrap‐servers</span><span class="token punctuation">:</span> 192.168.65.60<span class="token punctuation">:</span><span class="token number">9092</span><span class="token punctuation">,</span>192.168.65.60<span class="token punctuation">:</span><span class="token number">9093</span><span class="token punctuation">,</span>192.168.65.60<span class="token punctuation">:</span><span class="token number">9094</span><span class="token key atrule">producer</span><span class="token punctuation">:</span><span class="token key atrule">retries</span><span class="token punctuation">:</span> <span class="token number">3</span><span class="token key atrule">batch‐size</span><span class="token punctuation">:</span> <span class="token number">16384</span><span class="token key atrule">buffer‐memory</span><span class="token punctuation">:</span> <span class="token number">33554432</span><span class="token key atrule">acks</span><span class="token punctuation">:</span> <span class="token number">1</span><span class="token key atrule">key‐serializer</span><span class="token punctuation">:</span> org.apache.kafka.common.serialization.StringSerializer<span class="token key atrule">value‐serializer</span><span class="token punctuation">:</span> org.apache.kafka.common.serialization.StringSerializer<span class="token key atrule">consumer</span><span class="token punctuation">:</span><span class="token key atrule">group‐id</span><span class="token punctuation">:</span> default‐group<span class="token key atrule">enable‐auto‐commit</span><span class="token punctuation">:</span> <span class="token boolean important">false</span><span class="token key atrule">auto‐offset‐reset</span><span class="token punctuation">:</span> earliest<span class="token key atrule">key‐deserializer</span><span class="token punctuation">:</span> xxx.StringDeserializer<span class="token key atrule">value‐deserializer</span><span class="token punctuation">:</span> xxx.StringDeserializer<span class="token key atrule">listener</span><span class="token punctuation">:</span><span class="token key atrule">ack‐mode</span><span class="token punctuation">:</span> manual_immediate<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li>ack‐mode<ul><li>RECORD：当每一条记录被消费者监听器（ListenerConsumer）处理之后提交</li><li>BATCH：当每一批poll()的数据被消费者监听器处理之后提交</li><li>TIME：当每一批poll()的数据被消费者监听器处理之后，距离上次提交时间大于TIME时提交</li><li>COUNT：当每一批poll()的数据被消费者监听器处理之后，被处理record数量大于等于COUNT时提交</li><li>TIME&nbsp;|&nbsp;COUNT：有一个条件满足时提交</li><li>MANUAL：当每一批poll()的数据被消费者监听器处理之后,&nbsp;手动调用Acknowledgment.acknowledge()后提交</li><li>MANUAL_IMMEDIATE：手动调用Acknowledgment.acknowledge()后立即提交，一般使用这种（一次提交一条消息）</li></ul></li><li>生产者</li></ul><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token annotation punctuation">@Autowired</span><span class="token keyword">private</span> <span class="token class-name">KafkaTemplate</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> kafkaTemplate<span class="token punctuation">;</span>kafkaTemplate<span class="token punctuation">.</span><span class="token function">send</span><span class="token punctuation">(</span><span class="token constant">TOPIC_NAME</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token string">"key"</span><span class="token punctuation">,</span> <span class="token string">"this is a msg"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><ul><li>消费者</li></ul><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token annotation punctuation">@KafkaListener</span><span class="token punctuation">(</span>topics <span class="token operator">=</span> <span class="token string">"my‐replicated‐topic"</span><span class="token punctuation">,</span>groupId <span class="token operator">=</span> <span class="token string">"zhugeGroup"</span><span class="token punctuation">)</span><span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">listenZhugeGroup</span><span class="token punctuation">(</span><span class="token class-name">ConsumerRecord</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> record<span class="token punctuation">,</span> <span class="token class-name">Acknowledgment</span> ack<span class="token punctuation">)</span> <span class="token punctuation">{</span><span class="token class-name">String</span> value <span class="token operator">=</span> record<span class="token punctuation">.</span><span class="token function">value</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>ack<span class="token punctuation">.</span><span class="token function">acknowledge</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment">//手动提交offset</span><span class="token punctuation">}</span><span class="token comment">// 配置多个消费组（再写一个消费组处理同一个topic）</span><span class="token annotation punctuation">@KafkaListener</span><span class="token punctuation">(</span>topics <span class="token operator">=</span> <span class="token string">"my‐replicated‐topic"</span><span class="token punctuation">,</span>groupId <span class="token operator">=</span> <span class="token string">"tulingGroup"</span><span class="token punctuation">)</span><span class="token comment">// 配置多个topic，concurrency就是同组下的消费者个数，就是并发消费数，必须小于等于分区总数</span><span class="token annotation punctuation">@KafkaListener</span><span class="token punctuation">(</span>groupId <span class="token operator">=</span> <span class="token string">"testGroup"</span><span class="token punctuation">,</span> topicPartitions <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token annotation punctuation">@TopicPartition</span><span class="token punctuation">(</span>topic <span class="token operator">=</span> <span class="token string">"topic1"</span><span class="token punctuation">,</span> partitions <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">"0"</span><span class="token punctuation">,</span> <span class="token string">"1"</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token annotation punctuation">@TopicPartition</span><span class="token punctuation">(</span>topic <span class="token operator">=</span> <span class="token string">"topic2"</span><span class="token punctuation">,</span> partitions <span class="token operator">=</span> <span class="token string">"0"</span><span class="token punctuation">,</span>partitionOffsets <span class="token operator">=</span> <span class="token annotation punctuation">@PartitionOffset</span><span class="token punctuation">(</span>partition <span class="token operator">=</span> <span class="token string">"1"</span><span class="token punctuation">,</span> initialOffset <span class="token operator">=</span> <span class="token string">"100"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">,</span>concurrency <span class="token operator">=</span> <span class="token string">"6"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><hr><ul><li>Kafka事务</li></ul><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token class-name">Properties</span> props <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Properties</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"bootstrap.servers"</span><span class="token punctuation">,</span> <span class="token string">"localhost:9092"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"transactional.id"</span><span class="token punctuation">,</span> <span class="token string">"my‐transactional‐id"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token class-name">Producer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> producer <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">KafkaProducer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span>props<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">StringSerializer</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">StringSerializer</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>producer<span class="token punctuation">.</span><span class="token function">initTransactions</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>      <span class="token comment">// 初始化事务</span><span class="token keyword">try</span> <span class="token punctuation">{</span>producer<span class="token punctuation">.</span><span class="token function">beginTransaction</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment">// 开启事务</span>producer<span class="token punctuation">.</span><span class="token function">send</span><span class="token punctuation">(</span><span class="token comment">/*...*/</span><span class="token punctuation">)</span><span class="token punctuation">;</span>       <span class="token comment">// 发到不同的主题的不同分区</span>producer<span class="token punctuation">.</span><span class="token function">commitTransaction</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// 提交事务</span><span class="token punctuation">}</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">ProducerFencedException</span> <span class="token operator">|</span> <span class="token class-name">OutOfOrderSequenceException</span> <span class="token operator">|</span> <span class="token class-name">AuthorizationException</span> e<span class="token punctuation">)</span> <span class="token punctuation">{</span>producer<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">KafkaException</span> e<span class="token punctuation">)</span> <span class="token punctuation">{</span>producer<span class="token punctuation">.</span><span class="token function">abortTransaction</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment">// 回滚事务</span><span class="token punctuation">}</span>producer<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;ul&gt;
&lt;li&gt;核心组件&lt;/li&gt;
&lt;li&gt;配置文件&lt;/li&gt;
&lt;li&gt;基础命令&lt;/li&gt;
&lt;li&gt;Topic&lt;/li&gt;
&lt;li&gt;Kafka集群&lt;/li&gt;
&lt;li&gt;Java客户端 &amp;amp; SpringBoot支持&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&quot;核心组件&quot;&gt;</summary>
      
    
    
    
    <category term="IT学习笔记" scheme="https://jxch.github.io/categories/IT%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="Kafka" scheme="https://jxch.github.io/tags/Kafka/"/>
    
  </entry>
  
  <entry>
    <title>Kafka-设计原理</title>
    <link href="https://jxch.github.io/2024/09/04/architect/kafka/kafka-she-ji-yuan-li/"/>
    <id>https://jxch.github.io/2024/09/04/architect/kafka/kafka-she-ji-yuan-li/</id>
    <published>2024-09-04T02:02:49.000Z</published>
    <updated>2024-09-04T02:10:24.605Z</updated>
    
    <content type="html"><![CDATA[<ul><li>Controller</li><li>Leader - Partition</li><li>Rebalance</li><li>消息发布机制</li><li>HW与LEO</li><li>日志分段</li><li>zookeeper</li></ul><hr><h2 id="Controller">Controller</h2><ul><li>Kafka核心总控制器Controller：在Kafka集群中会有一个或者多个broker，其中有一个broker会被选举为控制器（Kafka&nbsp;Controller），它负责管理整个集群中所有分区和副本的状态<ul><li>当某个分区的leader副本出现故障时，由控制器负责为该分区选举新的leader副本</li><li>当检测到某个分区的ISR集合发生变化时，由控制器负责通知所有broker更新其元数据信息</li><li>当使用kafka-topics.sh脚本为某个topic增加分区数量时，同样还是由控制器负责让新分区被其他节点感知到</li></ul></li><li>Controller选举机制<ul><li>zookeeper临时节点的创建来选举controller：在kafka集群启动的时候，会自动选举一台broker作为controller来管理整个集群，选举的过程是集群中每个broker都会尝试在zookeeper上创建一个&nbsp;/controller&nbsp;临时节点，zookeeper会保证有且仅有一个broker能创建成功，这个broker就会成为集群的总控器controller</li><li>controller重新选举：当这个controller角色的broker宕机了，此时zookeeper临时节点会消失，集群里其他broker会一直监听这个临时节点，发现临时节点消失了，就竞争再次创建临时节点，就是我们上面说的选举机制，zookeeper又会保证有一个broker成为新的controller</li></ul></li><li>具备控制器身份的broker需要比其他普通的broker多一份职责，具体细节如下<ul><li>监听broker相关的变化。为Zookeeper中的/brokers/ids/节点添加BrokerChangeListener，用来处理broker增减的变化</li><li>监听topic相关的变化。为Zookeeper中的/brokers/topics节点添加TopicChangeListener，用来处理topic增减的变化；为Zookeeper中的/admin/delete_topics节点添加TopicDeletionListener，用来处理删除topic的动作</li><li>从Zookeeper中读取获取当前所有与topic、partition以及broker有关的信息并进行相应的管理。对于所有topic所对应的Zookeeper中的/brokers/topics/[topic]节点添加PartitionModificationsListener，用来监听topic中的分区分配变化</li><li>更新集群的元数据信息，同步到其他普通的broker节点中</li></ul></li></ul><hr><h2 id="Leader-Partition">Leader - Partition</h2><ul><li>Partition副本选举Leader机制<ul><li>controller感知到分区leader所在的broker挂了（controller监听了很多zk节点可以感知到broker存活）</li><li>controller会从ISR列表(参数unclean.leader.election.enable=false的前提下)里挑第一个broker作为leader(第一个broker最先放进ISR列表，可能是同步数据最多的副本)</li><li>如果参数unclean.leader.election.enable为true，代表在ISR列表里所有副本都挂了的时候可以在ISR列表以外的副本中选leader，这种设置，可以提高可用性，但是选出的新leader有可能数据少很多</li></ul></li><li>副本进入ISR列表有两个条件<ul><li>必须能与zookeeper保持会话以及跟leader副本网络连通</li><li>副本能复制leader上的所有写操作，并且不能落后太多<ul><li>与leader副本同步滞后的副本，是由 <a href="http://replica.lag.time.max.ms">replica.lag.time.max.ms</a>&nbsp;配置决定的，超过这个时间都没有跟leader同步过的一次的副本会被移出ISR列表</li></ul></li></ul></li><li>消费者消费消息的offset记录机制<ul><li>每个consumer会定期将自己消费分区的offset提交给kafka内部topic：__consumer_offsets<ul><li>提交过去的时候，key是consumerGroupId+topic+分区号，value就是当前offset的值</li><li>kafka会定期清理topic里的消息，最后就保留最新的那条数据</li></ul></li><li>因为__consumer_offsets可能会接收高并发的请求，kafka默认给其分配50个分区(可以通过offsets.topic.num.partitions设置)，这样可以通过加机器的方式抗大并发</li></ul></li></ul><hr><h2 id="Rebalance">Rebalance</h2><ul><li>Rebalance分区分配策略（partition.assignment.strategy）：range（默认）、round-robin、sticky<ul><li>range：按照分区序号排序，比如分区0~3给一个consumer，分区4~6给一个consumer，分区7~9给一个consumer</li><li>round-robin：轮询分配，比如分区0、3、6、9给一个consumer，分区1、4、7给一个consumer，分区2、5、8给一个consumer</li><li>sticky：与round-robin类似，但是在rebalance的时候，需要保证如下两个原则（当两者发生冲突时，第一个目标优先于第二个目标）<ul><li>分区的分配要尽可能均匀</li><li>分区的分配尽可能与上次分配的保持相同</li></ul></li></ul></li><li>Rebalance机制：如果消费组里的消费者数量有变化或消费的分区数有变化，kafka会重新分配消费者消费分区的关系。比如consumer&nbsp;group中某个消费者挂了，此时会自动把分配给他的分区交给其他的消费者，如果他又重启了，那么又会把一些分区重新交还给他<ul><li>rebalance只针对subscribe这种不指定分区消费的情况，如果通过assign这种消费方式指定了分区，kafka不会进行rebanlance</li><li>rebalance过程中，消费者无法从kafka消费消息，这对kafka的TPS会有影响，如果kafka集群内节点较多，比如数百个，那重平衡可能会耗时极多，所以应尽量避免在系统高峰期的重平衡发生</li></ul></li><li>触发消费者rebalance<ul><li>消费组里的consumer增加或减少了</li><li>动态给topic增加了分区</li><li>消费组订阅了更多的topic</li></ul></li><li>Rebalance过程：当有消费者加入消费组时，消费者、消费组及组协调器之间会经历以下几个阶段<ol><li>选择组协调器（GroupCoordinator）：每个consumer&nbsp;group都会选择一个broker作为自己的组协调器coordinator，负责监控这个消费组里的所有消费者的心跳，以及判断是否宕机，然后开启消费者rebalance<ul><li>consumer&nbsp;group中的每个consumer启动时会向kafka集群中的某个节点发送FindCoordinatorRequest请求来查找对应的组协调器GroupCoordinator，并跟其建立网络连接</li><li>组协调器选择方式：通过如下公式可以选出consumer消费的offset要提交到__consumer_offsets的哪个分区，这个分区leader对应的broker就是这个consumer&nbsp;group的coordinator。说白了，leader分区所在的节点就是GroupCoordinator</li></ul></li><li>加入消费组（JOIN&nbsp;GROUP），选择消费组协调器<ol><li>在成功找到消费组所对应的&nbsp;GroupCoordinator&nbsp;之后就进入加入消费组的阶段，在此阶段的消费者会向 GroupCoordinator&nbsp;发送&nbsp;JoinGroupRequest&nbsp;请求，并处理响应。</li><li>然后GroupCoordinator&nbsp;从一个consumer&nbsp;group中选择第一个加入group（第一个与GroupCoordinator连接的consumer）的consumer作为leader(消费组协调器)</li><li>把consumer&nbsp;group情况发送给这个leader，接着这个leader会负责制定分区方案</li></ol></li><li>SYNC&nbsp;GROUP<ol><li>consumer&nbsp;leader通过给GroupCoordinator发送SyncGroupRequest</li><li>接着GroupCoordinator就把分区方案下发给各个consumer，他们会根据指定分区的leader&nbsp;broker进行网络连接以及消息消费</li></ol></li></ol></li></ul><p><img src="/static/IT/Kafka/Kafka-%E8%AE%BE%E8%AE%A1%E5%8E%9F%E7%90%86-1.png" alt="Rebalance"></p><hr><h2 id="消息发布机制">消息发布机制</h2><ul><li>producer发布消息机制<ul><li>写入方式：producer&nbsp;采用&nbsp;push&nbsp;模式将消息发布到&nbsp;broker，每条消息都被&nbsp;append&nbsp;到&nbsp;patition&nbsp;中，属于顺序写磁盘（顺序写磁盘效率比随机写内存要高，保障&nbsp;kafka&nbsp;吞吐率）</li><li>消息路由：producer&nbsp;发送消息到&nbsp;broker&nbsp;时，会根据分区算法选择将其存储到哪一个&nbsp;partition<ol><li>指定了&nbsp;patition，则直接使用</li><li>指定&nbsp;patition&nbsp;但指定&nbsp;key，通过对&nbsp;key&nbsp;的&nbsp;value&nbsp;进行 hash&nbsp;选出一个&nbsp;patition</li><li>patition&nbsp;和&nbsp;key&nbsp;都未指定，使用轮询选出一个&nbsp;patition</li></ol></li><li>写入流程<ol><li>producer&nbsp;先从&nbsp;zookeeper&nbsp;的&nbsp;“/brokers/…/state”&nbsp;节点找到该&nbsp;partition&nbsp;的&nbsp;leader</li><li>producer&nbsp;将消息发送给该&nbsp;leader</li><li>leader&nbsp;将消息写入本地&nbsp;log</li><li>followers&nbsp;从&nbsp;leader&nbsp;pull&nbsp;消息，写入本地&nbsp;log&nbsp;后向leader&nbsp;发送&nbsp;ACK</li><li>leader&nbsp;收到所有&nbsp;ISR&nbsp;中的&nbsp;replica&nbsp;的&nbsp;ACK&nbsp;后，增加&nbsp;HW（high&nbsp;watermark，最后&nbsp;commit&nbsp;的&nbsp;offset）&nbsp;并向&nbsp;producer&nbsp;发送&nbsp;ACK</li></ol></li></ul></li></ul><p><img src="/static/IT/Kafka/Kafka-%E8%AE%BE%E8%AE%A1%E5%8E%9F%E7%90%86-2.png" alt="消息发布机制"></p><hr><h2 id="HW与LEO">HW与LEO</h2><ul><li>HW：HW俗称高水位，HighWatermark的缩写，取一个partition对应的ISR中最小的LEO(log-end-offset)作为HW，consumer最多只能消费到HW所在的位置。<ul><li>每个replica都有HW，leader和follower各自负责更新自己的HW的状态。</li><li>对于leader新写入的消息，consumer不能立刻消费，leader会等待该消息被所有ISR中的replicas同步后更新HW，消息才能被consumer消费。</li><li>这样就保证了如果leader所在的broker失效，该消息仍然可以从新选举的leader中获取。</li><li>对于来自内部broker的读取请求，没有HW的限制</li></ul></li><li>当producer生产消息至broker后，ISR以及HW和LEO的流转过程<ul><li><img src="/static/IT/Kafka/Kafka-%E8%AE%BE%E8%AE%A1%E5%8E%9F%E7%90%86-3.png" alt="HW"></li></ul></li><li>Kafka的复制机制既不是完全的同步复制，也不是单纯的异步复制，很好的均衡了确保数据不丢失以及吞吐率</li><li>当 acks=1<ul><li><img src="/static/IT/Kafka/Kafka-%E8%AE%BE%E8%AE%A1%E5%8E%9F%E7%90%86-4.png" alt="acks=1"></li></ul></li></ul><hr><h2 id="日志分段">日志分段</h2><ul><li>日志分段存储：Kafka&nbsp;一个分区的消息数据对应存储在一个文件夹下，以topic名称+分区号命名，消息在分区内是分段(segment)存储，每个段的消息都存储在不一样的log文件里，这种特性方便old&nbsp;segment&nbsp;file快速被删除，kafka规定了一个段位的&nbsp;log&nbsp;文件最大为&nbsp;1G，做这个限制目的是为了方便把&nbsp;log&nbsp;文件加载到内存去操作<ul><li>00000000000000000000.index：部分消息的offset索引文件，kafka每次往分区发4K(可配置)消息就会记录一条当前消息的offset到index文件<ul><li>如果要定位消息的offset会先在这个文件里快速定位，再去log文件里找具体消息</li></ul></li><li>00000000000000000000.log：消息存储文件，主要存offset和消息体</li><li>00000000000000000000.timeindex：息的发送时间索引文件，kafka每次往分区发4K(可配置)消息就会记录一条当前消息的发送时间戳与对应的offset到timeindex文件<ul><li>如果需要按照时间来定位消息的offset，会先在这个文件里查找</li></ul></li><li>文件名00000000000000000000就是表了这个日志段文件里包含的起始&nbsp;Offset</li></ul></li><li>log.segment.bytes：限定了每个日志段文件的大小，最大就是&nbsp;1GB<ul><li>一个日志段文件满了，就自动开一个新的日志段文件来写入，避免单个文件过大，影响文件的读写性能，这个过程叫做log&nbsp;rolling，正在被写入的那个日志段文件，叫做&nbsp;active&nbsp;log&nbsp;segment。</li></ul></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;ul&gt;
&lt;li&gt;Controller&lt;/li&gt;
&lt;li&gt;Leader - Partition&lt;/li&gt;
&lt;li&gt;Rebalance&lt;/li&gt;
&lt;li&gt;消息发布机制&lt;/li&gt;
&lt;li&gt;HW与LEO&lt;/li&gt;
&lt;li&gt;日志分段&lt;/li&gt;
&lt;li&gt;zookeeper&lt;/li&gt;
&lt;/u</summary>
      
    
    
    
    <category term="IT学习笔记" scheme="https://jxch.github.io/categories/IT%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="Kafka" scheme="https://jxch.github.io/tags/Kafka/"/>
    
  </entry>
  
  <entry>
    <title>Linux (Ubuntu) 的流量监控与限制（月100G）</title>
    <link href="https://jxch.github.io/2024/08/21/architect/yun-wei/linux-ubuntu-de-liu-liang-jian-kong-yu-xian-zhi-yue-100g/"/>
    <id>https://jxch.github.io/2024/08/21/architect/yun-wei/linux-ubuntu-de-liu-liang-jian-kong-yu-xian-zhi-yue-100g/</id>
    <published>2024-08-21T01:27:51.000Z</published>
    <updated>2024-08-30T07:33:53.955Z</updated>
    
    <content type="html"><![CDATA[<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">sudo</span> <span class="token function">apt</span> update<span class="token function">sudo</span> <span class="token function">apt</span> <span class="token function">install</span> iptables iproute2 iptables-persistent <span class="token parameter variable">-y</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h2 id="iptables"><code>iptables</code></h2><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 创建一个新的iptables链来跟踪流量</span><span class="token function">sudo</span> iptables <span class="token parameter variable">-N</span> TRAFFIC_TRACKING<span class="token comment"># 将所有流量传送到新链</span><span class="token function">sudo</span> iptables <span class="token parameter variable">-A</span> INPUT <span class="token parameter variable">-j</span> TRAFFIC_TRACKING<span class="token function">sudo</span> iptables <span class="token parameter variable">-A</span> OUTPUT <span class="token parameter variable">-j</span> TRAFFIC_TRACKING<span class="token comment"># 跟踪下载流量（入站流量）</span><span class="token function">sudo</span> iptables <span class="token parameter variable">-A</span> TRAFFIC_TRACKING <span class="token parameter variable">-m</span> conntrack <span class="token parameter variable">--ctstate</span> ESTABLISHED,RELATED <span class="token parameter variable">-j</span> RETURN<span class="token comment"># 确保SSH流量不被限制</span><span class="token function">sudo</span> iptables <span class="token parameter variable">-A</span> TRAFFIC_TRACKING <span class="token parameter variable">-p</span> tcp <span class="token parameter variable">--dport</span> <span class="token number">22</span> <span class="token parameter variable">-j</span> RETURN  <span class="token comment"># 计数流量</span><span class="token function">sudo</span> iptables <span class="token parameter variable">-A</span> TRAFFIC_TRACKING <span class="token parameter variable">-m</span> conntrack <span class="token parameter variable">--ctstate</span> NEW <span class="token parameter variable">-j</span> ACCEPT<span class="token function">sudo</span> iptables <span class="token parameter variable">-A</span> TRAFFIC_TRACKING <span class="token parameter variable">-m</span> conntrack <span class="token parameter variable">--ctstate</span> ESTABLISHED <span class="token parameter variable">-j</span> ACCEPT<span class="token comment"># 记录流量，104857600000字节等于100GB</span><span class="token function">sudo</span> iptables <span class="token parameter variable">-A</span> TRAFFIC_TRACKING <span class="token parameter variable">-m</span> connbytes <span class="token parameter variable">--connbytes</span> <span class="token number">0</span>:104857600000 --connbytes-dir both --connbytes-mode bytes <span class="token parameter variable">-j</span> RETURN<span class="token comment"># 如果流量超过100GB，丢弃新的连接</span><span class="token function">sudo</span> iptables <span class="token parameter variable">-A</span> TRAFFIC_TRACKING <span class="token parameter variable">-m</span> connbytes <span class="token parameter variable">--connbytes</span> <span class="token number">104857600000</span>: --connbytes-dir both --connbytes-mode bytes <span class="token parameter variable">-j</span> DROP<span class="token comment"># 保存并应用iptables规则，确保iptables规则在重启后依然生效</span><span class="token function">sudo</span> <span class="token function">mkdir</span> <span class="token parameter variable">-p</span> /etc/iptables<span class="token function">sudo</span> <span class="token function">sh</span> <span class="token parameter variable">-c</span> <span class="token string">"iptables-save &gt; /etc/iptables/rules.v4"</span><span class="token comment"># 验证流量限制，查看流量统计情况</span><span class="token function">sudo</span> iptables <span class="token parameter variable">-L</span> <span class="token parameter variable">-v</span> <span class="token parameter variable">-n</span> <span class="token parameter variable">-t</span> filter<span class="token function">sudo</span> iptables <span class="token parameter variable">-L</span> TRAFFIC_TRACKING <span class="token parameter variable">-v</span> <span class="token parameter variable">-n</span><span class="token comment"># 定时任务设置每月重置流量计数</span><span class="token function">sudo</span> <span class="token function">crontab</span> <span class="token parameter variable">-e</span><span class="token comment"># 选择1，在文件最后加入一行，CTRL+O保存，Enter确认文件名，CTRL+X退出nano编辑器</span><span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> * * /sbin/iptables <span class="token parameter variable">-Z</span> TRAFFIC_TRACKING<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="netfilter-persistent"><code>netfilter-persistent</code></h2><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 保存iptables规则</span><span class="token function">sudo</span> netfilter-persistent save<span class="token comment"># 重启服务</span><span class="token function">sudo</span> systemctl restart netfilter-persistent<span class="token comment"># 或者刚启动服务</span><span class="token function">sudo</span> systemctl start netfilter-persistent<span class="token function">sudo</span> systemctl <span class="token builtin class-name">enable</span> netfilter-persistent<span class="token function">sudo</span> systemctl status netfilter-persistent<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="监控统计">监控统计</h2><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 一行命令输出已经用了多少GB</span><span class="token function">sudo</span> iptables <span class="token parameter variable">-L</span> TRAFFIC_TRACKING <span class="token parameter variable">-v</span> <span class="token parameter variable">-n</span> <span class="token operator">|</span> <span class="token function">awk</span> <span class="token string">'/0.0.0.0\/0/ {sum += $2} END {print "Used GB: ", sum / 1073741824}'</span><span class="token comment"># 或者</span><span class="token function">sudo</span> iptables <span class="token parameter variable">-L</span> TRAFFIC_TRACKING <span class="token parameter variable">-v</span> <span class="token parameter variable">-n</span> <span class="token operator">|</span> <span class="token function">grep</span> <span class="token string">'0.0.0.0/0'</span> <span class="token operator">|</span> <span class="token function">awk</span> <span class="token string">'{sum += $2} END {print "Used GB: " sum/1073741824}'</span><span class="token comment"># 用了多少MB</span><span class="token function">sudo</span> iptables <span class="token parameter variable">-L</span> TRAFFIC_TRACKING <span class="token parameter variable">-v</span> <span class="token parameter variable">-n</span> <span class="token operator">|</span> <span class="token function">awk</span> <span class="token string">'/0.0.0.0\/0/ {sum += $2} END {print "Used MB: " sum/1048576}'</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;pre class=&quot;line-numbers language-bash&quot; data-language=&quot;bash&quot;&gt;&lt;code class=&quot;language-bash&quot;&gt;&lt;span class=&quot;token function&quot;&gt;sudo&lt;/span&gt; &lt;span clas</summary>
      
    
    
    
    <category term="运维手册" scheme="https://jxch.github.io/categories/%E8%BF%90%E7%BB%B4%E6%89%8B%E5%86%8C/"/>
    
    
    <category term="Linux" scheme="https://jxch.github.io/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>Java并发-synchronized</title>
    <link href="https://jxch.github.io/2024/06/13/architect/java-bing-fa/java-bing-fa-synchronized/"/>
    <id>https://jxch.github.io/2024/06/13/architect/java-bing-fa/java-bing-fa-synchronized/</id>
    <published>2024-06-13T03:46:49.000Z</published>
    <updated>2024-08-30T07:00:54.111Z</updated>
    
    <content type="html"><![CDATA[<ul><li>synchronized是JVM内置锁，基于Monitor机制实现，依赖底层操作系统的互斥原语Mutex（互斥量），被阻塞的线程会被挂起、等待重新调度，会导致“用户态和内核态”两个态之间来回切换，对性能有较大影响</li><li>Monitor，直译为“监视器”，而操作系统领域一般翻译为“管程”。管程是指管理共享变量以及对共享变量操作的过程，让它们支持并发。</li><li>Java&nbsp;参考了&nbsp;MESA&nbsp;模型（管程中引入了条件变量的概念，而且每个条件变量都对应有一个等待队列），语言内置的管程（synchronized）对&nbsp;MESA&nbsp;模型进行了精简。MESA&nbsp;模型中，条件变量可以有多个，Java&nbsp;语言内置的管程里只有一个条件变量</li><li>Object&nbsp;类定义了&nbsp;wait()，notify()，notifyAll()&nbsp;方法，这些方法的具体实现，依赖于&nbsp;ObjectMonitor&nbsp;实现<ul><li>在获取锁时，是将当前线程插入到cxq的头部，而释放锁时，默认策略（QMode=0）是：如果EntryList为空，则将 cxq中的元素按原有顺序插入到EntryList，并唤醒第一个线程，也就是当EntryList为空时，是后来的线程先获取 锁。EntryList不为空，直接从EntryList中唤醒线程</li><li>锁状态被记录在每个对象的对象头的Mark&nbsp;Word中</li></ul></li></ul><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">ObjectMonitor()&nbsp;{_header&nbsp;=&nbsp;NULL;&nbsp;//对象头&nbsp;markOop_recursions&nbsp;=&nbsp;0;&nbsp;//&nbsp;锁的重入次数_object&nbsp;=&nbsp;NULL;&nbsp;//存储锁对象_owner&nbsp;=&nbsp;NULL;&nbsp;//&nbsp;标识拥有该monitor的线程（当前获取锁的线程）_WaitSet&nbsp;=&nbsp;NULL;&nbsp;//&nbsp;等待线程（调用wait）组成的双向循环链表，_WaitSet是第一个节点_cxq&nbsp;=&nbsp;NULL&nbsp;;&nbsp;//多线程竞争锁会先存到这个单向链表中&nbsp;（FILO栈结构）_EntryList&nbsp;=&nbsp;NULL&nbsp;;&nbsp;//存放在进入或重新进入时被阻塞(blocked)的线程&nbsp;(也是竞争锁失败的线程)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="/static/architect/Java%E5%B9%B6%E5%8F%91-synchronized-1.png" alt=""><br><img src="/static/architect/Java%E5%B9%B6%E5%8F%91-synchronized-2.png" alt=""></p><hr><h2 id="对象的内存布局">对象的内存布局</h2><p>Hotspot虚拟机中，对象在内存中存储的布局可以分为三块区域</p><ul><li>对象头（Header）：比如&nbsp;hash码，对象所属的年代，对象锁，锁状态标志，偏向锁（线程）ID，偏向时间，数组长度（数组对象才有）</li><li>实例数据 （Instance&nbsp;Data）：存放类的属性数据信息，包括父类的属性信息</li><li>对齐填充（Padding）：对象起始地址必须是8字节的整数倍</li></ul><p><img src="/static/architect/Java%E5%B9%B6%E5%8F%91-synchronized-3.png" alt=""></p><h3 id="对象头">对象头</h3><p>HotSpot虚拟机的对象头包括</p><ul><li>Mark&nbsp;Word：用于存储对象自身的运行时数据，如哈希码（HashCode）、GC分代年龄、锁状态标志、线程持有的锁、偏向线程ID、偏向时间戳等，这部分数据的长度在32位和64位的虚拟机中分别为32bit和64bit</li><li>Klass&nbsp;Pointer：对象头的另外一部分是klass类型指针，即对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例。&nbsp;32位4字节，64位开启指针压缩或最大堆内存&lt;32g时4字节，否则8字节（-XX:-UseCompressedOops 关闭指针压缩）</li><li>数组长度（只有数组对象有）：如果对象是一个数组,&nbsp;那在对象头中还必须有一块数据用于记录数组长度。&nbsp;4字节</li></ul><p><img src="/static/architect/Java%E5%B9%B6%E5%8F%91-synchronized-4.png" alt=""></p><p>使用JOL工具查看内存布局</p><ul><li>OFFSET：偏移地址，单位字节</li><li>SIZE：占用的内存大小，单位为字节</li><li>TYPE&nbsp;DESCRIPTION：类型描述，其中object&nbsp;header为对象头</li><li>VALUE：对应内存中当前存储的值，二进制32位</li></ul><pre class="line-numbers language-markup" data-language="markup"><code class="language-markup"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>org.openjdk.jol<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span> <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>jol‐core<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token class-name">ClassLayout</span><span class="token punctuation">.</span><span class="token function">parseInstance</span><span class="token punctuation">(</span>obj<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">toPrintable</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="Mark-Word-记录锁状态（markOop-hpp）">Mark&nbsp;Word 记录锁状态（markOop.hpp）</h4><p><img src="/static/architect/Java%E5%B9%B6%E5%8F%91-synchronized-5.png" alt="32位"><br><img src="/static/architect/Java%E5%B9%B6%E5%8F%91-synchronized-6.png" alt="64位"></p><ul><li>hash：&nbsp;保存对象的哈希码。运行期间调用System.identityHashCode()来计算，延迟计算，并把结果赋值到这里</li><li>age：&nbsp;保存对象的分代年龄。表示对象被GC的次数，当该次数到达阈值的时候，对象就会转移到老年代</li><li>biased_lock：&nbsp;偏向锁标识位。由于无锁和偏向锁的锁标识都是&nbsp;01，没办法区分，这里引入一位的偏向锁标识位</li><li>lock：&nbsp;锁状态标识位。区分锁状态，但是11时表示对象待GC回收状态,&nbsp;只有最后2位锁标识(11)有效</li><li>JavaThread*：&nbsp;保存持有偏向锁的线程ID。偏向模式的时候，当某个线程持有对象的时候，对象这里就会被置为该线程的ID。&nbsp;在后面的操作中，就无需再进行尝试获取锁的动作。这个线程ID并不是JVM分配的线程ID号，和Java&nbsp;Thread中的ID是两个概念</li><li>epoch：&nbsp;保存偏向时间戳。偏向锁在CAS锁操作过程中，偏向性标识，表示对象更偏向哪个锁</li><li>ptr_to_lock_record：轻量级锁状态下，指向栈中锁记录的指针。当锁获取是无竞争时，JVM使用原子操作而不是OS互斥，这种技术称为轻量级锁定。在轻量级锁定的情况下，JVM通过CAS操作在对象的Mark&nbsp;Word中设置指向锁记录的指针</li><li>ptr_to_heavyweight_monitor：重量级锁状态下，指向对象监视器Monitor的指针。如果两个不同的线程同时在同一个对象上竞争，则必须将轻量级锁定升级到Monitor以管理等待的线程。在重量级锁定的情况下，JVM在对象的ptr_to_heavyweight_monitor设置指向Monitor的指针</li></ul><p><img src="/static/architect/Java%E5%B9%B6%E5%8F%91-synchronized-7.png" alt=""></p><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">enum&nbsp;{&nbsp;locked_value&nbsp;=&nbsp;0,&nbsp;//00&nbsp;轻量级锁unlocked_value&nbsp;=&nbsp;1,&nbsp;//001&nbsp;无锁monitor_value&nbsp;=&nbsp;2,&nbsp;//10&nbsp;监视器锁，也叫膨胀锁，也叫重量级锁 marked_value&nbsp;=&nbsp;3,&nbsp;//11&nbsp;GC标记biased_lock_pattern&nbsp;=&nbsp;5&nbsp;//101&nbsp;偏向锁};<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><hr><ul><li>偏向锁：偏向锁是一种针对加锁操作的优化手段，经过研究发现，在大多数情况下，锁不仅不存在多 线程竞争，而且总是由同一线程多次获得，因此为了消除数据在无竞争情况下锁重入（CAS操作）的开销而引入偏向锁。对于没有锁竞争的场合，偏向锁有很好的优化效果<ul><li>匿名偏向状态：新创建对象的Mark&nbsp;Word中的Thread&nbsp;Id为0，说明此时处于可偏向但未偏向任何线程，也叫做匿名偏向状态(anonymously&nbsp;biased)</li><li>偏向锁延迟偏向：HotSpot&nbsp;虚拟机在启动后有个&nbsp;4s&nbsp;的延迟才会对每个新建的对象开启偏向锁模式。JVM启动时会进行一系列的复杂活动，比如装载配置，系统类初始化等等。在这个过程中会使用大量synchronized关键字对对象加锁，且这些锁大多数都不是偏向锁。为了减少初始化时间，JVM默认延时加载偏向锁</li><li>偏向锁撤销<ul><li>调用对象HashCode：调用锁对象的obj.hashCode()或System.identityHashCode(obj)方法会导致该对象的偏向锁被撤销。因为对于一个对象，其HashCode只会生成一次并保存，偏向锁是没有地方保存hashcode的<ul><li>轻量级锁会在锁记录中记录&nbsp;hashCode</li><li>重量级锁会在&nbsp;Monitor&nbsp;中记录&nbsp;hashCode</li><li>当对象处于可偏向（也就是线程ID为0）和已偏向的状态下，调用HashCode计算将会使对象再也无法偏向<ul><li>当对象可偏向时，MarkWord将变成未锁定状态，并只能升级成轻量锁</li><li>当对象正处于偏向锁时，调用HashCode将使偏向锁强制升级成重量锁</li></ul></li></ul></li><li>调用wait/notify<ul><li>偏向锁状态执行obj.notify()&nbsp;会升级为轻量级锁</li><li>调用obj.wait(timeout)&nbsp;会升级为重量级锁</li></ul></li></ul></li><li>偏向锁批量重偏向&amp;批量撤销：当只有一个线程反复进入同步块时，偏向锁带来的性能开销基本可以忽略，但是当有其他线程尝试获得锁时，就需要等到safe&nbsp;point时，再将偏向锁撤销为无锁状态或升级为轻量级，会消耗一定的性能，所以在多线程竞争频繁的情况下，偏向锁不仅不能提高性能，还会导致性能下降。于是，就有了批量重偏向与批量撤销的机制<ul><li>批量重偏向：默认class偏向撤销阈值20<ul><li>以class为单位，为每个class维护一个偏向锁撤销计数器，每一次该class的对象发生偏向撤销操作时，该计数器+1，当这个值达到重偏向阈值（默认20）时，JVM就认为该class的偏向锁有问题，因此会进行批量重偏向</li></ul></li><li>批量撤销：默认class偏向撤销阈值40<ul><li>每个class对象会有一个对应的epoch字段，每个处于偏向锁状态对象的Mark&nbsp;Word中也有该字段，其初始值为创建该对象时class中的epoch的值。每次发生批量重偏向时，就将该值+1，同时遍历JVM中所有线程的栈，找到该class所有正处于加锁状态的偏向锁，将其epoch字段改为新值。下次获得锁时，发现当前对象的epoch值和class的epoch不相等，那就算当前已经偏向了其他线程，也不会执行撤销操作，而是直接通过CAS操作将其Mark&nbsp;Word的Thread&nbsp;Id&nbsp;改成当前线程Id</li><li>当达到重偏向阈值（默认20）后，假设该class计数器继续增长，当其达到批量撤销的阈值后（默认40），JVM就认为该class的使用场景存在多线程竞争，会标记该class为不可偏向，之后，对于该class的锁，直接走轻量级锁的逻辑</li></ul></li><li>应用场景<ul><li>批量重偏向（bulk&nbsp;rebias）机制是为了解决：一个线程创建了大量对象并执行了初始的同步操作，后来另一个线程也来将这些对象作为锁对象进行操作，这样会导致大量的偏向锁撤销操作</li><li>批量撤销（bulk&nbsp;revoke）机制是为了解决：在明显多线程竞争剧烈的场景下使用偏向锁是不合适的</li></ul></li><li>JVM参数<ul><li><code>-XX:BiasedLockingBulkRebiasThreshold</code>：偏向锁批量重偏向阈值</li><li><code>-XX:BiasedLockingBulkRevokeThreshold</code>：偏向锁批量撤销阈值</li></ul></li><li>批量重偏向和批量撤销是针对类的优化，和对象无关</li><li>偏向锁重偏向一次之后不可再次重偏向</li><li>当某个类已经触发批量撤销机制后，JVM会默认当前类产生了严重的问题，剥夺了该类的新实例对象使用偏向锁的权利</li></ul></li></ul></li><li>轻量级锁：倘若偏向锁失败，虚拟机并不会立即升级为重量级锁，它还会尝试使用一种称为轻量级锁的优化手段，此时Mark&nbsp;Word&nbsp;的结构也变为轻量级锁的结构。轻量级锁所适应的场景是线程交替执行同步块的场合，如果存在同一时间多个线程访问同一把锁的场合，就会导致轻量级锁膨胀为重量级锁<ul><li>轻量级锁所适应的场景是：线程交替执行同步块</li><li>偏向锁升级轻量级锁</li><li>CAS自旋修改Mark Word中锁记录的地址，失败超过一定次数轻量级锁会膨胀为重量级锁</li></ul></li><li>重量级锁<ul><li>自旋优化：重量级锁竞争的时候，还可以使用自旋来进行优化，如果当前线程自旋成功（即这时候持锁线程已经退出了同步块，释放了锁），这时当前线程就可以避免阻塞<ul><li>自旋会占用&nbsp;CPU&nbsp;时间，单核&nbsp;CPU&nbsp;自旋就是浪费，多核&nbsp;CPU&nbsp;自旋才能发挥优势</li><li>自旋是自适应的，比如对象刚刚的一次自旋操作成功过，那么认为这次自旋成功的可能性会高，就多自旋几次；反之，就少自旋甚至不自旋</li><li>不能控制是否开启自旋功能</li><li>自旋的目的是为了减少线程挂起的次数，尽量避免直接挂起线程（挂起操作涉及系统调用，存在用户态和内核态切换，这才是重量级锁最大的开销）</li></ul></li></ul></li><li>锁粗化：假设一系列的连续操作都会对同一个对象反复加锁及解锁，甚至加锁操作是出现在循环体中的，即使没有出现线程竞争，频繁地进行互斥同步操作也会导致不必要的性能损耗。如果JVM检测到有一连串零碎的操作都是对同一对象的加锁，将会扩大加锁同步的范围（即锁粗化）到整个操作序列的外部</li><li>锁消除：即删除不必要的加锁操作。锁消除是Java虚拟机在JIT编译期间，通过对运行上下文的扫描，去除不可能存在共享资源竞争的锁，通过锁消除，可以节省毫无意义的请求锁时间<ul><li><code>‐XX:+EliminateLocks</code> 开启锁消除</li></ul></li></ul><p><img src="/static/architect/Java%E5%B9%B6%E5%8F%91-synchronized-8.png" alt=""></p><hr><ul><li>逃逸分析（Escape&nbsp;Analysis）：是一种可以有效减少Java&nbsp;程序中同步负载和内存堆分配压力的跨函数全局数据流分析算法。通过逃逸分析，Java&nbsp;Hotspot编译器能够分析出一个新的对象的引用的使用范围从而决定是否要将这个对象分配到堆上<ul><li>逃逸分析的基本行为就是分析对象动态作用域</li><li>方法逃逸：对象逃出当前方法</li><li>线程逃逸：对象逃出当前线程</li><li>使用逃逸分析，编译器可以对代码做如下优化<ul><li>同步省略或锁消除（Synchronization&nbsp;Elimination）。如果一个对象被发现只能从一个线程被访问到，那么对于这个对象的操作可以不考虑同步</li><li>将堆分配转化为栈分配（Stack&nbsp;Allocation）。如果一个对象在子程序中被分配，要使指向该对象的指针永远不会逃逸，对象可能是栈分配的候选，而不是堆分配</li><li>分离对象或标量替换（Scalar&nbsp;Replacement）。有的对象可能不需要作为一个连续的内存结构存在也可以被访问到，那么对象的部分（或全部）可以不存储在内存，而是存储在CPU寄存器中</li></ul></li><li>JVM参数<ul><li><code>‐XX:+DoEscapeAnalysis</code> 开启逃逸分析</li><li><code>‐XX:+EliminateAllocations</code> 开启标量替换</li></ul></li></ul></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;ul&gt;
&lt;li&gt;synchronized是JVM内置锁，基于Monitor机制实现，依赖底层操作系统的互斥原语Mutex（互斥量），被阻塞的线程会被挂起、等待重新调度，会导致“用户态和内核态”两个态之间来回切换，对性能有较大影响&lt;/li&gt;
&lt;li&gt;Monitor，直译为“监视器</summary>
      
    
    
    
    <category term="IT学习笔记" scheme="https://jxch.github.io/categories/IT%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="Java并发" scheme="https://jxch.github.io/tags/Java%E5%B9%B6%E5%8F%91/"/>
    
  </entry>
  
  <entry>
    <title>Java并发-Semaphore &amp; CountDownLatch &amp; CyclicBarrier</title>
    <link href="https://jxch.github.io/2024/06/13/architect/java-bing-fa/java-bing-fa-semaphore-countdownlatch-cyclicbarrier/"/>
    <id>https://jxch.github.io/2024/06/13/architect/java-bing-fa/java-bing-fa-semaphore-countdownlatch-cyclicbarrier/</id>
    <published>2024-06-13T03:45:49.000Z</published>
    <updated>2024-08-30T07:00:48.443Z</updated>
    
    <content type="html"><![CDATA[<ul><li>Semaphore，俗称信号量，它是操作系统中PV操作（P表示通过；V表示释放）的原语在java的实现，它也是基于AbstractQueuedSynchronizer实现的，可以用于做流量控制，特别是公用资源有限的应用场景<ul><li>acquire()&nbsp;表示阻塞并获取许可</li><li>tryAcquire()&nbsp;方法在没有许可的情况下会立即返回&nbsp;false，要获取许可的线程不会阻塞</li><li>release()&nbsp;表示释放许可</li><li>int&nbsp;availablePermits()：返回此信号量中当前可用的许可证数</li><li>int&nbsp;getQueueLength()：返回正在等待获取许可证的线程数</li><li>boolean&nbsp;hasQueuedThreads()：是否有线程正在等待获取许可证</li><li>void&nbsp;reducePermit(int&nbsp;reduction)：减少&nbsp;reduction&nbsp;个许可证</li><li>Collection&nbsp;getQueuedThreads()：返回所有等待获取许可证的线程集合</li></ul></li><li>CountDownLatch（闭锁）是一个同步协助类，允许一个或多个线程等待，直到其他线程完成操作集<ul><li>CountDownLatch使用给定的计数值（count）初始化。await方法会阻塞直到当前的计数值（count）由于countDown方法的调用达到0，count为0之后所有等待的线程都会被释放，并且随后对await方法的调用都会立即返回。这是一个一次性现象&nbsp;——&nbsp;count不会被重置。如果你需要一个重置count的版本，那么请考虑使用CyclicBarrier</li><li>底层基于&nbsp;AbstractQueuedSynchronizer&nbsp;实现，CountDownLatch&nbsp;构造函数中指定的count直接赋给AQS的state；每次countDown()则都是release(1)减1，最后减到0时unpark阻塞线程；这一步是由最后一个执行countdown方法的线程执行的</li><li>调用await()方法时，当前线程就会判断state属性是否为0，如果为0，则继续往下执行，如果不为0，则使当前线程进入等待状态，直到某个线程将state属性置为0，其就会唤醒在await()方法中等待的线程</li></ul></li><li>Thread.&nbsp;join()：&nbsp;的实现原理是不停检查join线程是否存活，如果&nbsp;join&nbsp;线程存活则让当前线程永远等待</li><li>CyclicBarrier：字面意思回环栅栏（循环屏障），通过它可以实现让一组线程等待至某个状态（屏障点）之后再全部同时执行。叫做回环是因为当所有等待线程都被释放以后，CyclicBarrier可以被重用<ul><li>CyclicBarrier&nbsp;可以用于多线程计算数据，最后合并计算结果的场景</li></ul></li><li>CountDownLatch与CyclicBarrier的区别<ul><li>CountDownLatch的计数器只能使用一次，而CyclicBarrier的计数器可以使用reset()&nbsp;方法重置</li><li>CyclicBarrier还提供getNumberWaiting（可以获得CyclicBarrier阻塞的线程数量）、isBroken（用来知道阻塞的线程是否被中断）等方法</li><li>CountDownLatch会阻塞主线程，CyclicBarrier不会阻塞主线程，只会阻塞子线程</li><li>CountDownLatch和CyclicBarrier都能够实现线程之间的等待，只不过它们侧重点不同。CountDownLatch一般用于一个或多个线程，等待其他线程执行完任务后，再执行。CyclicBarrier一般用于一组线程互相等待至某个状态，然后这一组线程再同时执行</li><li>CyclicBarrier&nbsp;还可以提供一个&nbsp;barrierAction，合并多线程计算结果</li><li>CyclicBarrier是通过ReentrantLock的"独占锁"和Conditon来实现一组线程的阻塞唤醒的，而CountDownLatch则是通过AQS的“共享锁”实现</li></ul></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;ul&gt;
&lt;li&gt;Semaphore，俗称信号量，它是操作系统中PV操作（P表示通过；V表示释放）的原语在java的实现，它也是基于AbstractQueuedSynchronizer实现的，可以用于做流量控制，特别是公用资源有限的应用场景
&lt;ul&gt;
&lt;li&gt;acquire()&amp;</summary>
      
    
    
    
    <category term="IT学习笔记" scheme="https://jxch.github.io/categories/IT%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="Java并发" scheme="https://jxch.github.io/tags/Java%E5%B9%B6%E5%8F%91/"/>
    
  </entry>
  
  <entry>
    <title>Java并发-ReentrantReadWriteLock</title>
    <link href="https://jxch.github.io/2024/06/13/architect/java-bing-fa/java-bing-fa-reentrantreadwritelock/"/>
    <id>https://jxch.github.io/2024/06/13/architect/java-bing-fa/java-bing-fa-reentrantreadwritelock/</id>
    <published>2024-06-13T03:42:49.000Z</published>
    <updated>2024-08-30T07:00:42.865Z</updated>
    
    <content type="html"><![CDATA[<ul><li>写锁是独占的，读锁是共享的：读读可以并发；读写，写读，写写互斥。在读多写少的场景中，读写锁能够提供比排它锁更好的并发性和吞吐量<ul><li>读锁不支持条件变量</li><li>重入时升级不支持：持有读锁的情况下去获取写锁，会导致获取永久等待</li><li>重入时支持降级：&nbsp;持有写锁的情况下可以去获取读锁</li></ul></li><li>线程进入读锁的前提条件<ul><li>没有其他线程的写锁</li><li>没有写请求或者有写请求，但调用线程和持有锁的线程是同一个</li></ul></li><li>线程进入写锁的前提条件<ul><li>没有其他线程的读锁</li><li>没有其他线程的写锁</li></ul></li><li>读写锁有以下三个重要的特性<ul><li>公平选择性：支持非公平（默认）和公平的锁获取方式，吞吐量还是非公平优于公平</li><li>可重入：读锁和写锁都支持线程重入。以读写线程为例：读线程获取读锁后，能够再次获取读锁。写线程在获取写锁之后能够再次获取写锁，同时也可以获取读锁</li><li>锁降级：遵循获取写锁、再获取读锁最后释放写锁的次序，写锁能够降级成为读锁</li></ul></li><li>锁降级：锁降级指的是写锁降级成为读锁<ul><li>锁降级是指把持住（当前拥有的）写锁，再获取到读锁，随后释放（先前拥有的）写锁的过程</li><li>如果当前线程拥有写锁，然后将其释放，最后再获取读锁，这种分段完成的过程不能称之为锁降级</li><li>锁降级可以帮助我们拿到当前线程修改后的结果而不被其他线程所破坏，防止更新丢失</li></ul></li><li>锁降级中为什么要获取读锁：主要是为了保证数据的可见性<ul><li>如果当前线程不获取读锁而是直接释放写锁，假设此刻另一个线程（记作线程T）获取了写锁并修改了数据，那么当前线程无法感知线程T的数据更新</li><li>如果当前线程获取读锁，即遵循锁降级的步骤，则线程T将会被阻塞，直到当前线程使用数据并释放读锁之后，线程T才能获取写锁进行数据更新</li></ul></li><li>RentrantReadWriteLock不支持锁升级（把持读锁、获取写锁，最后释放读锁的过程）：目的也是保证数据可见性<ul><li>如果读锁已被多个线程获取，其中任意线程成功获取了写锁并更新了数据，则其更新对其他获取到读锁的线程是不可见的</li></ul></li><li>用一个变量如何维护多种状态：高16为表示读，低16为表示写<ul><li>通过位运算确定读锁和写锁的状态<ul><li>写状态，等于&nbsp;S&nbsp;&amp;&nbsp;0x0000FFFF（将高&nbsp;16&nbsp;位全部抹去）。&nbsp;当写状态加1，等于S+1</li><li>读状态，等于&nbsp;S&nbsp;&gt;&gt;&gt;&nbsp;16&nbsp;(无符号补&nbsp;0&nbsp;右移&nbsp;16&nbsp;位)。当读状态加1，等于 S +（1&lt;&lt;16）,也就是 S+0x00010000</li></ul></li><li>S不等于0时，当写状态（S&amp;0x0000FFFF）等于0时，读状态（S&gt;&gt;&gt;16）大于0，即读锁已被获取</li></ul></li><li>exclusiveCount(int&nbsp;c)&nbsp;静态方法，获得持有写状态的锁的次数</li><li>sharedCount(int&nbsp;c)&nbsp;静态方法，获得持有读状态的锁的线程数量。</li><li>HoldCounter&nbsp;计数器：不同于写锁，读锁可以同时被多个线程持有。而每个线程持有的读锁支持重入的特性，所以需要对每个线程持有的读锁的数量单独计数，这就需要用到&nbsp;HoldCounter&nbsp;计数器<ul><li>读锁的内在机制其实就是一个共享锁。一次共享锁的操作就相当于对HoldCounter&nbsp;计数器的操作。获取共享锁，则该计数器&nbsp;+&nbsp;1，释放共享锁，该计数器&nbsp;-&nbsp;1。只有当线程获取共享锁后才能对共享锁进行释放、重入操作</li><li>通过&nbsp;ThreadLocalHoldCounter&nbsp;类，HoldCounter&nbsp;与线程进行绑定。HoldCounter&nbsp;是绑定线程的一个计数器，而&nbsp;ThreadLocalHoldCounter&nbsp;则是线程绑定的&nbsp;ThreadLocal<ul><li>HoldCounter是用来记录读锁重入数的对象</li><li>ThreadLocalHoldCounter是ThreadLocal变量，用来存放不是第一个获取读锁的线程的其他线程的读锁重入数对象</li></ul></li></ul></li><li>写锁的获取：写锁是一个支持重进入的排它锁。如果当前线程已经获取了写锁，则增加写状态。如果当前线程在获取写锁时，读锁已经被获取（读状态不为0）或者该线程不是已经获取写锁的线程，&nbsp;则当前线程进入等待状态</li></ul><p><img src="/static/architect/Java%E5%B9%B6%E5%8F%91-ReentrantReadWriteLock-1.png" alt="写锁获取"><br><img src="/static/architect/Java%E5%B9%B6%E5%8F%91-ReentrantReadWriteLock-2.png" alt="写锁释放"><br><img src="/static/architect/Java%E5%B9%B6%E5%8F%91-ReentrantReadWriteLock-3.png" alt="读锁获取"><br><img src="/static/architect/Java%E5%B9%B6%E5%8F%91-ReentrantReadWriteLock-4.png" alt="读锁释放"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;ul&gt;
&lt;li&gt;写锁是独占的，读锁是共享的：读读可以并发；读写，写读，写写互斥。在读多写少的场景中，读写锁能够提供比排它锁更好的并发性和吞吐量
&lt;ul&gt;
&lt;li&gt;读锁不支持条件变量&lt;/li&gt;
&lt;li&gt;重入时升级不支持：持有读锁的情况下去获取写锁，会导致获取永久等待&lt;/li&gt;
&lt;</summary>
      
    
    
    
    <category term="IT学习笔记" scheme="https://jxch.github.io/categories/IT%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="Java并发" scheme="https://jxch.github.io/tags/Java%E5%B9%B6%E5%8F%91/"/>
    
  </entry>
  
  <entry>
    <title>Java并发-ReentrantLock</title>
    <link href="https://jxch.github.io/2024/06/13/architect/java-bing-fa/java-bing-fa-reentrantlock/"/>
    <id>https://jxch.github.io/2024/06/13/architect/java-bing-fa/java-bing-fa-reentrantlock/</id>
    <published>2024-06-13T03:41:49.000Z</published>
    <updated>2024-08-30T07:00:37.197Z</updated>
    
    <content type="html"><![CDATA[<p>ReentrantLock是一种基于AQS框架的应用实现，是JDK中的一种线程并发访问的同步手段，它的功能类似于synchronized是一种互斥锁，可以保证线程安全。相对于&nbsp;synchronized，&nbsp;ReentrantLock具备如下特点：</p><ul><li>可中断</li><li>可以设置超时时间</li><li>可以设置为公平锁（ReentrantLock&nbsp;默认是不公平的）</li><li>支持多个条件变量</li><li>与&nbsp;synchronized&nbsp;一样，都支持可重入</li></ul><p><img src="/static/architect/Java%E5%B9%B6%E5%8F%91-ReentrantLock-1.png" alt="加锁入队"><br><img src="/static/architect/Java%E5%B9%B6%E5%8F%91-ReentrantLock-2.png" alt="解锁出队"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;ReentrantLock是一种基于AQS框架的应用实现，是JDK中的一种线程并发访问的同步手段，它的功能类似于synchronized是一种互斥锁，可以保证线程安全。相对于&amp;nbsp;synchronized，&amp;nbsp;ReentrantLock具备如下特点：&lt;/p&gt;
</summary>
      
    
    
    
    <category term="IT学习笔记" scheme="https://jxch.github.io/categories/IT%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="Java并发" scheme="https://jxch.github.io/tags/Java%E5%B9%B6%E5%8F%91/"/>
    
  </entry>
  
  <entry>
    <title>Java并发-JMM</title>
    <link href="https://jxch.github.io/2024/06/13/architect/java-bing-fa/java-bing-fa-jmm/"/>
    <id>https://jxch.github.io/2024/06/13/architect/java-bing-fa/java-bing-fa-jmm/</id>
    <published>2024-06-13T03:39:49.000Z</published>
    <updated>2024-08-30T07:00:31.293Z</updated>
    
    <content type="html"><![CDATA[<p>并发三大特性</p><ul><li>可见性：volatile；内存屏障；synchronized；Lock；final</li><li>有序性（指令重排序）：volatile；内存屏障；synchronized；Lock</li><li>原子性：synchronized；Lock；CAS</li></ul><hr><ul><li>Java内存模型（Java Memory Model，JMM）：用于屏蔽掉各种硬件和操作系统的内存访问差异，以实现让Java程序在各种平台下都能达到一致的并发效果<ul><li>规定了一个线程如何和何时可以看到由其他线程修改过后的共享变量的值，以及在必须时如何同步的访问共享变量</li><li>JMM是围绕原子性、有序性、可见性展开的</li></ul></li><li>内存交互操作：关于主内存与工作内存之间的具体交互协议，即一个变量如何从主内存拷贝到工作内存、如何从工作内存同步到主内存之间的实现细节，Java内存模型定义了以下八种操作来完成<ul><li>lock（锁定）：作用于主内存的变量，把一个变量标识为一条线程独占状态。</li><li>unlock（解锁）：作用于主内存变量，把一个处于锁定状态的变量释放出来，释放后的变量才可以被其他线程锁定。</li><li>read（读取）：作用于主内存变量，把一个变量值从主内存传输到线程的工作内存中，以便随后的load动作使用</li><li>load（载入）：作用于工作内存的变量，它把read操作从主内存中得到的变量值放入工作内存的变量副本中。</li><li>use（使用）：作用于工作内存的变量，把工作内存中的一个变量值传递给执行引擎，每当虚拟机遇到一个需要使用变量的值的字节码指令时将会执行这个操作。</li><li>assign（赋值）：作用于工作内存的变量，它把一个从执行引擎接收到的值赋值给工作内存的变量，每当虚拟机遇到一个给变量赋值的字节码指令时执行这个操作。</li><li>store（存储）：作用于工作内存的变量，把工作内存中的一个变量的值传送到主内存中，以便随后的write的操作。</li><li>write（写入）：作用于主内存的变量，它把store操作从工作内存中一个变量的值传送到主内存的变量中。</li><li><img src="/static/architect/Java%E5%B9%B6%E5%8F%91-JMM-1.png" alt=""></li></ul></li><li>Java内存模型还规定了在执行上述八种基本操作时，必须满足如下规则<ul><li>如果要把一个变量从主内存中复制到工作内存，就需要按顺寻地执行read和load操作， 如果把变量从工作内存中同步回主内存中，就要按顺序地执行store和write操作。但Java内存模型只要求上述操作必须按顺序执行，而没有保证必须是连续执行。</li><li>不允许read和load、store和write操作之一单独出现</li><li>不允许一个线程丢弃它的最近assign的操作，即变量在工作内存中改变了之后必须同步到主内存中。</li><li>不允许一个线程无原因地（没有发生过任何assign操作）把数据从工作内存同步回主内存中。</li><li>一个新的变量只能在主内存中诞生，不允许在工作内存中直接使用一个未被初始化（load或assign）的变量。即就是对一个变量实施use和store操作之前，必须先执行过了assign和load操作。</li><li>一个变量在同一时刻只允许一条线程对其进行lock操作，但lock操作可以被同一条线程重复执行多次，多次执行lock后，只有执行相同次数的unlock操作，变量才会被解锁。lock和unlock必须成对出现</li><li>如果对一个变量执行lock操作，将会清空工作内存中此变量的值，在执行引擎使用这个变量前需要重新执行load或assign操作初始化变量的值</li><li>如果一个变量事先没有被lock操作锁定，则不允许对它执行unlock操作；也不允许去unlock一个被其他线程锁定的变量。</li><li>对一个变量执行unlock操作之前，必须先把此变量同步到主内存中（执行store和write操作）。</li></ul></li><li>JMM的内存可见性保证<ul><li>单线程程序。单线程程序不会出现内存可见性问题。编译器、runtime和处理器会共同确保单线程程序的执行结果与该程序在顺序一致性模型中的执行结果相同。</li><li>正确同步的多线程程序。正确同步的多线程程序的执行将具有顺序一致性（程序的执行结果与该程序在顺序一致性内存模型中的执行结果相同）。这是JMM关注的重点，JMM通过限制编译器和处理器的重排序来为程序员提供内存可见性保证。</li><li>未同步/未正确同步的多线程程序。JMM为它们提供了最小安全性保障：线程执行时读取到的值，要么是之前某个线程写入的值，要么是默认值，未同步程序在JMM中的执行时，整体上是无序的，其执行结果无法预知。 JMM不保证未同步程序的执行结果与该程序在顺序一致性模型中的执行结果一致。<ul><li>未同步程序在JMM中的执行时，整体上是无序的，其执行结果无法预知。未同步程序在两个模型中的执行特性有如下几个差异<ul><li>顺序一致性模型保证单线程内的操作会按程序的顺序执行，而JMM不保证单线程内的操作会按程序的顺序执行，比如正确同步的多线程程序在临界区内的重排序</li><li>顺序一致性模型保证所有线程只能看到一致的操作执行顺序，而JMM不保证所有线程能看到一致的操作执行顺序</li><li>顺序一致性模型保证对所有的内存读/写操作都具有原子性，而JMM不保证对64位的long型和double型变量的写操作具有原子性（32位处理器）<ul><li>JVM在32位处理器上运行时，可能会把一个64位long/double型变量的写操作拆分为两个32位的写操作来执行。这两个32位的写操作可能会被分配到不同的总线事务中执行，此时对这个64位变量的写操作将不具有原子性。从JSR-133内存模型开始（即从JDK5开始），仅仅只允许把一个64位long/double型变量的写操作拆分为两个32位的写操作来执行，任意的读操作在JSR-133中都必须具有原子性</li></ul></li></ul></li></ul></li></ul></li></ul><hr><ul><li>volatile<ul><li>可见性：对一个volatile变量的读，总是能看到（任意线程）对这个volatile变量最后的写入<ul><li>内存交互层面：volatile修饰的变量的read、load、use操作和assign、store、write必须是连续的，即修改后必须立即同步回主内存，使用时必须从主内存刷新，由此保证volatile变量操作对多线程的可见性</li><li>硬件层面：通过lock前缀指令，会锁定变量缓存行区域并写回主内存，这个操作称为“缓存锁定”，缓存一致性机制会阻止同时修改被两个以上处理器缓存的内存区域数据。一个处理器的缓存回写到内存会导致其他处理器的缓存无效</li></ul></li><li>原子性：对任意单个volatile变量的读/写具有原子性，但类似于volatile++这种复合操作不具有原子性（基于这点，我们通过会认为volatile不具备原子性）。volatile仅仅保证对单个volatile变量的读/写具有原子性，而锁的互斥执行的特性可以确保对整个临界区代码的执行具有原子性<ul><li>64位的long型和double型变量，只要它是volatile变量，对该变量的读/写就具有原子性</li></ul></li><li>有序性：对volatile修饰的变量的读写操作前后加上各种特定的内存屏障来禁止指令重排序来保障有序性<ul><li>在JSR-133之前的旧Java内存模型中，虽然不允许volatile变量之间重排序，但旧的Java内存模型允许volatile变量与普通变量重排序。为了提供一种比锁更轻量级的线程之间通信的机制，JSR-133专家组决定增强volatile的内存语义：严格限制编译器和处理器对volatile变量与普通变量的重排序，确保volatile的写-读和锁的释放-获取具有相同的内存语义</li></ul></li><li>内存语义<ul><li>当写一个volatile变量时，JMM会把该线程对应的本地内存中的共享变量值刷新到主内存</li><li>当读一个volatile变量时，JMM会把该线程对应的本地内存置为无效，线程接下来将从主内存中读取共享变量</li></ul></li><li>hotspot<ul><li>字节码解释器：<code>if (cache -&gt; is_volatile()) { OrderAccess::storeload(); }</code></li><li>模板解释器：对每个指令都写了一段对应的汇编代码，启动时将每个指令与对应汇编代码入口绑定。x86处理器中利用lock实现类似内存屏障的效果：<code>lock addl $0, $0(%rsp)</code>。</li></ul></li></ul></li></ul><hr><ul><li>LOCK 前缀指令：<ul><li>确保后续指令执行的原子性。在Pentium及之前的处理器中，带有lock前缀的指令在执行期间会锁住总线，使得其它处理器暂时无法通过总线访问内存，很显然，这个开销很大。在新的处理器中，Intel使用缓存锁定来保证指令执行的原子性，缓存锁定将大大降低lock前缀指令的执行开销。</li><li>LOCK前缀指令具有类似于内存屏障的功能，禁止该指令与前面和后面的读写指令重排序。</li><li>LOCK前缀指令会等待它之前所有的指令完成、并且所有缓冲的写操作写回内存(也就是将store buffer中的内容写入内存)之后才开始执行，并且根据缓存一致性协议，刷新store buffer的操作会导致其他cache中的副本失效。</li><li>汇编层面（日志）：<code>-XX:+UnlockDiagnosticVMOptions -XX:+PrintAssembly -Xcomp</code></li><li>硬件层面：32位的IA-32处理器支持对系统内存中的位置进行锁定的原子操作。这些操作通常用于管理共享的数据结构（如信号量、段描述符、系统段或页表），在这些结构中，两个或多个处理器可能同时试图修改相同的字段或标志。处理器使用三种相互依赖的机制来执行锁定的原子操作<ul><li>有保证的原子操作；总线锁定，使用LOCK#信号和LOCK指令前缀；缓存一致性协议，确保原子操作可以在缓存的数据结构上执行（缓存锁，这种机制出现在Pentium4、Intel Xeon和P6系列处理器中）</li></ul></li></ul></li></ul><hr><ul><li>指令重排序：JVM线程内部维持顺序化语义。即只要程序的最终结果与它顺序化情况的结果相等，那么指令的执行顺序可以与代码顺序不一致，此过程叫指令的重排序。</li><li>指令重排序的意义：JVM能根据处理器特性（CPU多级缓存系统、多核处理器等）适当的对机器指令进行重排序，使机器指令能更符合CPU的执行特性，最大限度的发挥机器性能。在编译器与CPU处理器中都能执行指令重排优化操作</li><li><img src="/static/architect/Java%E5%B9%B6%E5%8F%91-JMM-2.png" alt=""></li><li>volatile重排序规则</li><li><img src="/static/architect/Java%E5%B9%B6%E5%8F%91-JMM-3.png" alt=""></li><li>volatile禁止重排序场景<ul><li>第二个操作是volatile写，不管第一个操作是什么都不会重排序</li><li>第一个操作是volatile读，不管第二个操作是什么都不会重排序</li><li>第一个操作是volatile写，第二个操作是volatile读，也不会发生重排序</li></ul></li><li>JMM内存屏障插入策略<ul><li>在每个volatile写操作的前面插入一个StoreStore屏障</li><li>在每个volatile写操作的后面插入一个StoreLoad屏障</li><li>在每个volatile读操作的后面插入一个LoadLoad屏障</li><li>在每个volatile读操作的后面插入一个LoadStore屏障</li><li>x86处理器不会对读-读、读-写和写-写操作做重排序, 会省略掉这3种操作类型对应的内存屏障。仅会对写-读操作做重排序，所以volatile写-读操作只需要在volatile写后插入StoreLoad屏障</li></ul></li><li><img src="/static/architect/Java%E5%B9%B6%E5%8F%91-JMM-4.png" alt=""></li><li>JVM层面的内存屏障：JSR规范中定义了4种内存屏障<ul><li>LoadLoad屏障：（指令Load1; LoadLoad; Load2），在Load2及后续读取操作要读取的数据被访问前，保证Load1要读取的数据被读取完毕。</li><li>LoadStore屏障：（指令Load1; LoadStore; Store2），在Store2及后续写入操作被刷出前，保证Load1要读取的数据被读取完毕。</li><li>StoreStore屏障：（指令Store1; StoreStore; Store2），在Store2及后续写入操作执行前，保证Store1的写入操作对其它处理器可见。</li><li>StoreLoad屏障：（指令Store1; StoreLoad; Load2），在Load2及后续所有读取操作执行前，保证Store1的写入对所有处理器可见。它的开销是四种屏障中最大的。在大多数处理器的实现中，这个屏障是个万能屏障，兼具其它三种内存屏障的功能</li><li>由于x86只有store load可能会重排序，所以只有JSR的StoreLoad屏障对应它的mfence或lock前缀指令，其他屏障对应空操作</li></ul></li><li>硬件层内存屏障：硬件层提供了一系列的内存屏障 memory barrier / memory fence(Intel的提法)来提供一致性的能力。拿X86平台来说，有几种主要的内存屏障<ul><li>lfence，是一种 Load Barrier 读屏障</li><li>sfence, 是一种 Store Barrier 写屏障</li><li>mfence, 是一种全能型的屏障，具备lfence和sfence的能力</li><li>Lock前缀，Lock不是一种内存屏障，但是它能完成类似内存屏障的功能。Lock会对CPU总线和高速缓存加锁，可以理解为CPU指令级的一种锁。它后面可以跟ADD, ADC, AND, BTC, BTR, BTS, CMPXCHG, CMPXCH8B, DEC, INC, NEG, NOT, OR, SBB, SUB, XOR, XADD, and XCHG等指令</li></ul></li><li>内存屏障有两个能力：阻止屏障两边的指令重排序；刷新处理器缓存/冲刷处理器缓存<ul><li>对Load Barrier来说，在读指令前插入读屏障，可以让高速缓存中的数据失效，重新从主内存加载数据；</li><li>对Store Barrier来说，在写指令之后插入写屏障，能让写入缓存的最新数据写回到主内存。</li><li>Lock前缀实现了类似的能力，它先对总线和缓存加锁，然后执行后面的指令，最后释放锁后会把高速缓存中的数据刷新回主内存。在Lock锁住总线的时候，其他CPU的读写请求都会被阻塞，直到锁释放。</li></ul></li><li>不同硬件实现内存屏障的方式不同，Java内存模型屏蔽了这种底层硬件平台的差异，由JVM来为不同的平台生成相应的机器码。</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;并发三大特性&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;可见性：volatile；内存屏障；synchronized；Lock；final&lt;/li&gt;
&lt;li&gt;有序性（指令重排序）：volatile；内存屏障；synchronized；Lock&lt;/li&gt;
&lt;li&gt;原子性：synchroniz</summary>
      
    
    
    
    <category term="IT学习笔记" scheme="https://jxch.github.io/categories/IT%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="Java并发" scheme="https://jxch.github.io/tags/Java%E5%B9%B6%E5%8F%91/"/>
    
  </entry>
  
  <entry>
    <title>Java并发-happens-before</title>
    <link href="https://jxch.github.io/2024/06/13/architect/java-bing-fa/java-bing-fa-happens-before/"/>
    <id>https://jxch.github.io/2024/06/13/architect/java-bing-fa/java-bing-fa-happens-before/</id>
    <published>2024-06-13T03:38:49.000Z</published>
    <updated>2024-08-30T07:00:26.344Z</updated>
    
    <content type="html"><![CDATA[<ul><li>as-if-serial：不管怎么重排序（编译器和处理器为了提高并行度），（单线程）程序的执行结果不能被改变。编译器、runtime和处理器都必须遵守as-if-serial语义<ul><li>为了遵守as-if-serial语义，编译器和处理器不会对存在数据依赖关系的操作做重排序，因为这种重排序会改变执行结果。但是，如果操作之间不存在数据依赖关系，这些操作就可能被编译器和处理器重排序</li></ul></li><li>happens-before：从JDK 5 开始，JMM使用happens-before的概念来阐述多线程之间的内存可见性。在JMM中，如果一个操作执行的结果需要对另一个操作可见，那么这两个操作之间必须存在happens-before关系<ul><li>它是判断数据是否存在竞争、线程是否安全的主要依据，依靠这个原则，我们解决在并发环境下两操作之间是否可能存在冲突的所有问题</li></ul></li><li>happens-before原则定义<ul><li>如果一个操作happens-before另一个操作，那么第一个操作的执行结果将对第二个操作可见，而且第一个操作的执行顺序排在第二个操作之前。</li><li>两个操作之间存在happens-before关系，并不意味着一定要按照happens-before原则制定的顺序来执行。如果重排序之后的执行结果与按照happens-before关系来执行的结果一致，那么这种重排序并不非法。</li></ul></li><li>happens-before原则规则<ul><li>程序次序规则：一个线程内，按照代码顺序，书写在前面的操作先行发生于书写在后面的操作；</li><li>锁定规则：一个unLock操作先行发生于后面对同一个锁的lock操作；</li><li>volatile变量规则：对一个变量的写操作先行发生于后面对这个变量的读操作；</li><li>传递规则：如果操作A先行发生于操作B，而操作B又先行发生于操作C，则可以得出操作A先行发生于操作C；</li><li>线程启动规则：Thread对象的start()方法先行发生于此线程的每个一个动作；</li><li>线程中断规则：对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生；</li><li>线程终结规则：线程中所有的操作都先行发生于线程的终止检测，我们可以通过Thread.join()方法结束、Thread.isAlive()的返回值手段检测到线程已经终止执行；</li><li>对象终结规则：一个对象的初始化完成先行发生于他的finalize()方法的开始；</li></ul></li><li>如果两个操作不存在上述任一一个happens-before规则，那么这两个操作就没有顺序的保障，JVM可以对这两个操作进行重排序。如果操作A happens-before操作 B，那么操作A在内存上所做的操作对操作B都是可见的</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;ul&gt;
&lt;li&gt;as-if-serial：不管怎么重排序（编译器和处理器为了提高并行度），（单线程）程序的执行结果不能被改变。编译器、runtime和处理器都必须遵守as-if-serial语义
&lt;ul&gt;
&lt;li&gt;为了遵守as-if-serial语义，编译器和处理器不会对存在数</summary>
      
    
    
    
    <category term="IT学习笔记" scheme="https://jxch.github.io/categories/IT%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="Java并发" scheme="https://jxch.github.io/tags/Java%E5%B9%B6%E5%8F%91/"/>
    
  </entry>
  
  <entry>
    <title>Java并发-Future</title>
    <link href="https://jxch.github.io/2024/06/13/architect/java-bing-fa/java-bing-fa-future/"/>
    <id>https://jxch.github.io/2024/06/13/architect/java-bing-fa/java-bing-fa-future/</id>
    <published>2024-06-13T03:37:49.000Z</published>
    <updated>2024-08-30T07:00:21.125Z</updated>
    
    <content type="html"><![CDATA[<ul><li>FutureTask: 存储任务的处理结果，更新任务的状态<ul><li>既可以被当做Runnable来执行，也可以被当做Future来获取Callable的返回结果</li></ul></li><li>Future: <code>cancel isCancelled isDone get</code></li><li>CompletionService 一边生成任务，一边获取任务的返回值，任务之间不会互相阻塞，可以实现先执行完的先取结果，不再依赖任务顺序了<ul><li>内部通过阻塞队列+FutureTask，实现了任务先完成可优先获取到，即结果按照完成先后顺序排序</li><li>内部有一个先进先出的阻塞队列，用于保存已经执行完成的Future，通过调用它的take方法或poll方法可以获取到一个已经执行完成的Future，进而通过调用Future接口实现类的get方法获取最终的结果</li></ul></li><li>CompletionStage 执行某一个阶段，可向下执行后续阶段。异步执行，默认线程池是 <code>ForkJoinPool.commonPool()</code></li><li>CompletableFuture 实现了对任务的编排能力（业务逻辑处理存在串行[依赖]、并行、聚合的关系）<ul><li>获取结果<ul><li>join 抛出的是 uncheck 异常（即未经检查的异常),不会强制开发者抛出</li><li>get 抛出的是经过检查的异常，ExecutionException,&nbsp;InterruptedException&nbsp;需要用户手动处理</li></ul></li><li>结果处理：<code>whenComplete whenCompleteAsync exceptionally</code><ul><li>当 CompletableFuture 的计算结果完成，或者抛出异常的时候，我们可以执行特定的&nbsp;Action</li><li>Action的类型是 <code>BiConsumer&lt;?&nbsp;super&nbsp;T,?&nbsp;super&nbsp;Throwable&gt;</code>，它可以处理正常的计算结果，或者异常情况</li><li>方法不以Async结尾，意味着Action使用相同的线程执行，而Async可能会使用其它的线程去执行（如果使用相同的线程池，也可能会被同一个线程选中执行）</li><li>这几个方法都会返回CompletableFuture，当Action执行完毕后它的结果返回原始的CompletableFuture的计算结果或者返回异常</li></ul></li><li>结果消费：结果消费系列函数只对结果执行Action，而不返回新的计算值<ul><li>thenAccept系列（<code>thenAccept thenAcceptAsync</code>）：对单个结果进行消费</li><li>thenAcceptBoth系列（<code>thenAcceptBoth thenAcceptBothAsync</code>）：对两个结果进行消费<ul><li>当两个&nbsp;CompletionStage&nbsp;都正常完成计算的时候，就会执行提供的 action 消费两个异步的结果</li></ul></li><li>thenRun系列（<code>thenRun thenRunAsync</code>）：不关心结果，只对结果执行Action<ul><li>也是对线程任务结果的一种消费函数，与 thenAccept 不同的是，thenRun&nbsp;会在上一阶段&nbsp;CompletableFuture&nbsp;计算完成的时候执行一个Runnable，Runnable 并不使用该&nbsp;CompletableFuture&nbsp;计算的结果</li></ul></li></ul></li><li>依赖关系（结果转换）<ul><li>thenApply()&nbsp;把前面异步任务的结果，交给后面的Function<ul><li>thenApply&nbsp;转换的是泛型中的类型，返回的是同一个CompletableFuture</li></ul></li><li>thenCompose() 用来连接两个有依赖关系的任务，结果由第二个任务返回<ul><li>thenCompose&nbsp;将内部的&nbsp;CompletableFuture&nbsp;调用展开来并使用上一个CompletableFutre&nbsp;调用的结果在下一步的&nbsp;CompletableFuture&nbsp;调用中进行运算，是生成一个新的CompletableFuture</li></ul></li></ul></li><li>and聚合关系（结果组合）：合并线程任务的结果，并进一步处理<ul><li>thenCombine 任务合并，有返回值</li><li>thenAccepetBoth 两个任务执行完成后，将结果交给thenAccepetBoth消耗，无返回值</li><li>runAfterBoth 两个任务都执行完成后，执行下一步操作（Runnable）</li></ul></li><li>or聚合关系（任务交互：将两个线程任务获取结果的速度相比较，按一定的规则进行下一步处理）<ul><li>applyToEither 两个任务谁执行的快，就使用那一个结果，有返回值</li><li>acceptEither 两个任务谁执行的快，就消费那一个结果，无返回值</li><li>runAfterEither 两个线程任意一个任务执行完成，进行下一步操作 (Runnable)</li><li>runAfterBoth 两个线程任务相比较，两个全部执行完成，才进行下一步操作，不关心运行结果</li></ul></li><li>并行执行（多个 CompletableFuture 并行执行）<ul><li><code>CompletableFuture#anyOf</code> anyOf&nbsp;方法的参数是多个给定的&nbsp;CompletableFuture，当其中的任何一个完成时，方法返回这个&nbsp;CompletableFuture</li><li><code>CompletableFuture#allOf</code> allOf方法用来实现多&nbsp;CompletableFuture&nbsp;的同时返回</li></ul></li><li>异步操作<ul><li>runAsync 无返回值</li><li>supplyAsync 有返回值</li></ul></li></ul></li></ul><p><img src="/static/architect/Java%E5%B9%B6%E5%8F%91-Future.png" alt=""></p>]]></content>
    
    
      
      
    <summary type="html">&lt;ul&gt;
&lt;li&gt;FutureTask: 存储任务的处理结果，更新任务的状态
&lt;ul&gt;
&lt;li&gt;既可以被当做Runnable来执行，也可以被当做Future来获取Callable的返回结果&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Future: &lt;code&gt;cancel isC</summary>
      
    
    
    
    <category term="IT学习笔记" scheme="https://jxch.github.io/categories/IT%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="Java并发" scheme="https://jxch.github.io/tags/Java%E5%B9%B6%E5%8F%91/"/>
    
  </entry>
  
  <entry>
    <title>Java并发-ForkJoin</title>
    <link href="https://jxch.github.io/2024/06/13/architect/java-bing-fa/java-bing-fa-forkjoin/"/>
    <id>https://jxch.github.io/2024/06/13/architect/java-bing-fa/java-bing-fa-forkjoin/</id>
    <published>2024-06-13T03:35:49.000Z</published>
    <updated>2024-08-30T07:00:16.024Z</updated>
    
    <content type="html"><![CDATA[<ul><li>线程数计算方法：<code>线程数&nbsp;=&nbsp;CPU&nbsp;核心数&nbsp;*（1+平均等待时间/平均工作时间）</code><ul><li>CPU密集型任务：线程数为 CPU&nbsp;核心数的&nbsp;1~2&nbsp;倍</li><li>IO密集型任务：线程数一般会大于&nbsp;CPU&nbsp;核心数很多倍</li></ul></li><li>分治算法：将一个规模为N的问题分解为K个规模较小的子问题，这些子问题相互独立且与原问题性质相同。求出子问题的解，就可得到原问题的解<ul><li>步骤：分解；求解；合并</li><li>在分治法中，子问题一般是相互独立的，因此，经常通过递归调用算法来求解子问题</li></ul></li><li>Fork/Join：ForkJoinPool允许其他线程向它提交任务，并根据设定将这些任务拆分为粒度更细的子任务，这些子任务将由ForkJoinPool内部的工作线程来并行执行，并且工作线程之间可以窃取彼此之间的任务<ul><li>最适合计算密集型任务，而且最好是非阻塞任务</li></ul></li><li>ForkJoinPool 是用于执行&nbsp;ForkJoinTask&nbsp;任务的执行池<ul><li>维护了一个队列数组&nbsp;WorkQueue（WorkQueue[]），这样在提交任务和线程任务的时候大幅度减少碰撞</li><li>四个核心参数：并行数、工作线程的创建、异常处理和模式指定</li><li>任务提交<ul><li>提交异步执行：execute</li><li>等待并获取结果：invoke</li><li>提交执行获取Future结果：submit</li></ul></li></ul></li><li>ForkJoinTask 定义了任务执行时的具体逻辑和拆分逻辑，继承了Future接口<ul><li>fork() 提交任务：用于向当前任务所运行的线程池中提交任务。如果当前线程是ForkJoinWorkerThread类型，将会放入该线程的工作队列，否则放入common线程池的工作队列中</li><li>join() 获取任务执行结果：调用join()时，将阻塞当前线程直到对应的子任务完成运行并返回结果</li><li>通常情况下我们不需要直接继承ForkJoinTask类，而只需要继承它的子类<ul><li>RecursiveAction 用于递归执行但不需要返回结果的任务</li><li>RecursiveTask 用于递归执行需要返回结果的任务</li><li><code>CountedCompleter&lt;T&gt;</code> 在任务完成执行后会触发执行一个自定义的钩子函数</li></ul></li></ul></li><li>ForkJoinPool&nbsp;的工作原理<ul><li>ForkJoinPool&nbsp;内部有多个工作队列，当我们通过&nbsp;ForkJoinPool&nbsp;的&nbsp;invoke()&nbsp;或者&nbsp;submit()&nbsp;方法提交任务时，ForkJoinPool&nbsp;根据一定的路由规则把任务提交到一个工作队列中，如果任务在执行过程中会创建出子任务，那么子任务会提交到工作线程对应的工作队列中</li><li>ForkJoinPool&nbsp;的每个工作线程都维护着一个工作队列（WorkQueue），这是一个双端队列（Deque），里面存放的对象是任务（ForkJoinTask）</li><li>每个工作线程在运行中产生新的任务（通常是因为调用了&nbsp;fork()）时，会放入工作队列的top，并且工作线程在处理自己的工作队列时，使用的是&nbsp;LIFO&nbsp;方式，也就是说每次从top取出任务来执行</li><li>每个工作线程在处理自己的工作队列同时，会尝试窃取一个任务，窃取的任务位于其他线程的工作队列的base，也就是说工作线程在窃取其他工作线程的任务时，使用的是FIFO&nbsp;方式</li><li>在遇到&nbsp;join()&nbsp;时，如果需要&nbsp;join&nbsp;的任务尚未完成，则会先处理其他任务，并等待其完成</li><li>在既没有自己的任务，也没有可以窃取的任务时，进入休眠</li></ul></li><li>工作窃取：就是允许空闲线程从繁忙线程的双端队列中窃取任务<ul><li>减少线程竞争任务的可能性：工作线程从它自己的双端队列的头部获取任务。但是，当自己的任务为空时，线程会从其他繁忙线程双端队列的尾部中获取任务</li><li>工作窃取队列（work-stealing&nbsp;queues&nbsp;）：由内部类WorkQueue实现，它是Deques的特殊形式，但仅支持三种操作方式：push、pop和poll（也称为窃取）</li><li>队列的读取有着严格的约束，push和pop仅能从其所属线程调用，而poll则可以从其他线程调用</li></ul></li><li>为什么工作线程总是从头部获取任务，窃取线程从尾部获取任务<ul><li>通过始终选择最近提交的任务，可以增加资源仍分配在CPU缓存中的机会</li><li>窃取者之所以从尾部获取任务，则是为了降低线程之间的竞争可能</li><li>由于任务是可分割的，那队列中较旧的任务最有可能粒度较大，因为它们可能还没有被分割，而空闲的线程则相对更有“精力”来完成这些粒度较大的任务</li></ul></li><li>工作队列 WorkQueue<ul><li>WorkQueue&nbsp;是双向列表，用于任务的有序执行，如果&nbsp;WorkQueue&nbsp;用于自己的执行线程&nbsp;Thread，线程默认将会从尾端选取任务用来执行&nbsp;LIFO</li><li>每个&nbsp;ForkJoinWorkThread&nbsp;都有属于自己的&nbsp;WorkQueue，但不是每个&nbsp;WorkQueue&nbsp;都有对应的&nbsp;ForkJoinWorkThread</li><li>没有&nbsp;ForkJoinWorkThread&nbsp;的&nbsp;WorkQueue&nbsp;保存的是&nbsp;submission，来自外部提交，在 <code>WorkQueues[]</code>&nbsp;的下标是偶数位</li></ul></li><li>ForkJoinWorkThread 是用于执行任务的线程，用于区别使用非&nbsp;ForkJoinWorkThread&nbsp;线程提交task。启动一个该&nbsp;Thread，会自动注册一个&nbsp;WorkQueue&nbsp;到&nbsp;Pool，拥有&nbsp;Thread&nbsp;的&nbsp;WorkQueue&nbsp;只能出现在&nbsp;<code>WorkQueues[]</code>&nbsp;的奇数位</li></ul><p><img src="/static/architect/Java%E5%B9%B6%E5%8F%91-ForkJoin-1.png" alt=""></p><p><img src="/static/architect/Java%E5%B9%B6%E5%8F%91-ForkJoin-2.png" alt=""></p><p><img src="/static/architect/Java%E5%B9%B6%E5%8F%91-ForkJoin-3.png" alt=""></p>]]></content>
    
    
      
      
    <summary type="html">&lt;ul&gt;
&lt;li&gt;线程数计算方法：&lt;code&gt;线程数&amp;nbsp;=&amp;nbsp;CPU&amp;nbsp;核心数&amp;nbsp;*（1+平均等待时间/平均工作时间）&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;CPU密集型任务：线程数为 CPU&amp;nbsp;核心数的&amp;nbsp;1~2&amp;nbsp;倍&lt;/li&gt;</summary>
      
    
    
    
    <category term="IT学习笔记" scheme="https://jxch.github.io/categories/IT%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="Java并发" scheme="https://jxch.github.io/tags/Java%E5%B9%B6%E5%8F%91/"/>
    
  </entry>
  
  <entry>
    <title>Java并发-Disruptor</title>
    <link href="https://jxch.github.io/2024/06/13/architect/java-bing-fa/java-bing-fa-disruptor/"/>
    <id>https://jxch.github.io/2024/06/13/architect/java-bing-fa/java-bing-fa-disruptor/</id>
    <published>2024-06-13T03:33:49.000Z</published>
    <updated>2024-08-30T07:00:11.271Z</updated>
    
    <content type="html"><![CDATA[<ul><li>Disruptor 通过以下设计来解决队列速度慢的问题<ul><li>环形数组结构：为了避免垃圾回收，采用数组而非链表。同时，数组对处理器的缓存机制更加友好（空间局部性原理）</li><li>元素位置定位：数组长度2^n，通过位运算，加快定位的速度。下标采取递增的形式。不用担心index溢出的问题。index是long类型，即使100万QPS的处理速度，也需要30万年才能用完</li><li>无锁设计：每个生产者或者消费者线程，会先申请可以操作的元素在数组中的位置，申请到之后，直接在该位置写入或者读取数据</li><li>利用缓存行填充解决了伪共享的问题</li><li>实现了基于事件驱动的生产者消费者模型（观察者模式）</li></ul></li><li>RingBuffer 数据结构：一个可自定义大小的环形数组，还有一个序列号(sequence)，用以指向下一个可用的元素<ul><li>Disruptor要求设置数组长度为2的n次幂。在知道索引(index)下标的情况下，存与取数组上的元素时间复杂度只有O(1)，而这个index我们可以通过序列号与数组的长度取模来计算得出，index=sequence&nbsp;%&nbsp;entries.length。也可以用位运算来计算效率更高，此时array.length必须是2的幂次方，index=sequece&amp;(entries.length-1)</li><li>当需要覆盖数据时，会执行一个策略，Disruptor给提供多种策略<ul><li>BlockingWaitStrategy策略，常见且默认的等待策略。使用ReentrantLock+Condition实现阻塞，最节省cpu，但高并发场景下性能最差。适合CPU资源紧缺，吞吐量和延迟并不重要的场景</li><li>SleepingWaitStrategy策略，会在循环中不断等待数据。先进行自旋等待如果不成功，则使用Thread.yield()让出CPU,并最终使用LockSupport.parkNanos(1L)进行线程休眠，以确保不占用太多的CPU资源。因此这个策略会产生比较高的平均延时。典型的应用场景就是异步日志</li><li>YieldingWaitStrategy策略，这个策略用于低延时的场合。消费者线程会不断循环监控缓冲区变化，在循环内部使用Thread.yield()让出CPU给别的线程执行时间。如果需要一个高性能的系统，并且对延时比较有严格的要求，可以考虑这种策略</li><li>BusySpinWaitStrategy策略:&nbsp;采用死循环，消费者线程会尽最大努力监控缓冲区的变化。对延时非常苛刻的场景使用，cpu核数必须大于消费者线程数量。推荐在线程绑定到固定的CPU的场景下使用</li></ul></li></ul></li><li>一个生产者单线程写数据的流程<ol><li>申请写入m个元素</li><li>若是有m个元素可以写入，则返回最大的序列号。这里主要判断是否会覆盖未读的元素</li><li>若是返回的正确，则生产者开始写入元素</li></ol></li><li>多个生产者写数据的流程<ol><li>申请写入m个元素</li><li>若是有m个元素可以写入，则返回最大的序列号。每个生产者会被分配一段独享的空间</li><li>生产者写入元素，写入元素的同时设置available&nbsp;Buffer里面相应的位置，以标记自己哪些位置是已经写入成功的</li></ol><ul><li>问题<ul><li>如何防止多个线程重复写同一个元素：每个线程通过CAS获取不同的一段数组空间进行操作</li><li>如何防止读取的时候，读到还未写的元素：引入了一个与Ring&nbsp;Buffer大小相同的buffer：available&nbsp;Buffer。当某个位置写入成功的时候，便把availble&nbsp;Buffer相应的位置置位，标记为写入成功。读取的时候，会遍历available&nbsp;Buffer，来判断元素是否已经就绪</li></ul></li></ul></li><li>生产者多线程写入的情况下读数据<ol><li>申请读取到序号n</li><li>若writer&nbsp;cursor&nbsp;&gt;=&nbsp;n，这时仍然无法确定连续可读的最大下标。从reader&nbsp;cursor开始读取available&nbsp;Buffer，一直查到第一个不可用的元素，然后返回最大连续可读元素的位置</li><li>消费者读取元素</li></ol></li></ul><p><img src="/static/architect/Java%E5%B9%B6%E5%8F%91-Disruptor-1.png" alt=""></p><hr><ul><li>Disruptor核心概念<ul><li>RingBuffer（环形缓冲区）：基于数组的内存级别缓存，是创建sequencer(序号)与定义WaitStrategy(拒绝策略)的入口</li><li>Disruptor（总体执行入口）：对RingBuffer的封装，持有RingBuffer、消费者线程池Executor、消费之集合ConsumerRepository等引用</li><li>Sequence（序号分配器）：对RingBuffer中的元素进行序号标记，通过顺序递增的方式来管理进行交换的数据(事件/Event)，一个Sequence可以跟踪标识某个事件的处理进度，同时还能消除伪共享</li><li>Sequencer（数据传输器）：Sequencer里面包含了Sequence，是Disruptor的核心，Sequencer有两个实现类：SingleProducerSequencer(单生产者实现)、MultiProducerSequencer(多生产者实现)，Sequencer主要作用是实现生产者和消费者之间快速、正确传递数据的并发算法</li><li>SequenceBarrier（消费者屏障）：用于控制RingBuffer的Producer和Consumer之间的平衡关系，并且决定了Consumer是否还有可处理的事件的逻辑</li><li>WaitStrategy（消费者等待策略）：决定了消费者如何等待生产者将Event生产进Disruptor，WaitStrategy有多种实现策略</li><li>Event：从生产者到消费者过程中所处理的数据单元，Event由使用者自定义</li><li>EventHandler：由用户自定义实现，就是我们写消费者逻辑的地方，代表了Disruptor中的一个消费者的接口</li><li>EventProcessor：这是个事件处理器接口，实现了Runnable，处理主要事件循环，处理Event，拥有消费者的Sequence</li></ul></li></ul><p><img src="/static/architect/Java%E5%B9%B6%E5%8F%91-Disruptor-2.png" alt=""></p><hr><p>Disruptor的使用</p><pre class="line-numbers language-markup" data-language="markup"><code class="language-markup"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>com.lmax<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>disruptor<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><ol><li>创建 Event（消息载体/事件）和 EventFactory（事件工厂） <code>implements&nbsp;EventFactory</code></li><li>创建消息（事件）生产者 <code>RingBuffer#publish</code></li><li>创建消费者 <code>implements&nbsp;EventHandler</code><ul><li><code>disruptor#handleEventsWithWorkerPool</code> 多消费者下一个消息只会被一个消费者消费，要实现 <code>WorkHandler</code></li><li>顺序消费：<code>disruptor.handleEventsWith().then().then()</code></li></ul></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;ul&gt;
&lt;li&gt;Disruptor 通过以下设计来解决队列速度慢的问题
&lt;ul&gt;
&lt;li&gt;环形数组结构：为了避免垃圾回收，采用数组而非链表。同时，数组对处理器的缓存机制更加友好（空间局部性原理）&lt;/li&gt;
&lt;li&gt;元素位置定位：数组长度2^n，通过位运算，加快定位的速度。下标采</summary>
      
    
    
    
    <category term="IT学习笔记" scheme="https://jxch.github.io/categories/IT%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="Java并发" scheme="https://jxch.github.io/tags/Java%E5%B9%B6%E5%8F%91/"/>
    
  </entry>
  
  <entry>
    <title>Java并发-CAS &amp; Atomic</title>
    <link href="https://jxch.github.io/2024/06/13/architect/java-bing-fa/java-bing-fa-cas-atomic/"/>
    <id>https://jxch.github.io/2024/06/13/architect/java-bing-fa/java-bing-fa-cas-atomic/</id>
    <published>2024-06-13T03:30:49.000Z</published>
    <updated>2024-08-30T07:00:06.146Z</updated>
    
    <content type="html"><![CDATA[<ul><li>CAS</li><li>Atomic</li><li>LongAdder</li></ul><hr><ul><li>CAS（Compare&nbsp;And&nbsp;Swap，比较并交换）：针对一个变量，首先比较它的内存值与某个期望值是否相同，如果相同，就给它赋一个新值<ul><li>一个不可分割的原子操作，并且其原子性是直接在硬件层面得到保障的</li></ul></li><li>CAS缺陷<ul><li>自旋&nbsp;CAS&nbsp;长时间地不成功，则会给&nbsp;CPU&nbsp;带来非常大的开销</li><li>只能保证一个共享变量原子操作</li><li>ABA&nbsp;问题<ul><li>加时间戳的原子操作类（AtomicStampedReference&lt;V&gt;）</li><li>AtomicMarkableReference（只关心是否修改过，而不关心修改次数）</li></ul></li></ul></li></ul><hr><ul><li>java.util.concurrent.atomic<ul><li>基本类型：AtomicInteger、AtomicLong、AtomicBoolean</li><li>引用类型：AtomicReference、AtomicStampedRerence、AtomicMarkableReference</li><li>数组类型：AtomicIntegerArray、AtomicLongArray、AtomicReferenceArray</li><li>对象属性原子修改器：AtomicIntegerFieldUpdater、AtomicLongFieldUpdater、AtomicReferenceFieldUpdater<ul><li>字段必须是volatile类型的</li><li>调用者能够直接操作对象字段（修饰符public/protected/default/private），但是子类是不能操作父类的字段，尽管子类可以访问父类的字段</li><li>只能是实例变量，不能是类变量，也就是说不能加static关键字</li><li>只能是可修改变量，不能使final变量，因为final的语义就是不可修改（实际上volatile和final的语义本来就是冲突的）</li><li>不能修改其包装类型，如果要修改包装类型就需要使用AtomicReferenceFieldUpdater</li></ul></li><li>原子类型累加器（jdk1.8增加的类）：DoubleAccumulator、DoubleAdder、LongAccumulator、LongAdder、Striped64</li></ul></li></ul><hr><ul><li>LongAdder解决高并发环境下AtomicLong的自旋瓶颈问题：尽量减少热点冲突，不到最后万不得已，尽量将CAS操作延迟<ul><li>基本思路就是分散热点，将value值分散到一个数组中，不同线程会命中到数组的不同槽中，各个线程只对自己槽中的那个值进行CAS操作</li><li>如果要获取真正的long值，只要将各个槽中的变量值累加返回</li></ul></li><li>LongAdder的内部结构：一个base变量，一个Cell[]数组<ul><li>base变量：非竞态条件下，直接累加到该变量上</li><li>Cell[]数组：竞态条件下，累加到各个线程自己的槽Cell[i]中</li></ul></li><li>LongAdder#add<ul><li>CPU核数，用来决定槽数组的大小，大小为2的次幂</li><li>没有遇到并发竞争时，直接使用base累加数值<ul><li>只有从未出现过并发冲突的时候，base基数才会使用到，一旦出现了并发冲突，之后所有的操作都只针对Cell[]数组中的单元Cell</li></ul></li><li>初始化cells数组时，必须要保证cells数组只能被初始化一次（即只有一个线程能对cells初始化），他竞争失败的线程会讲数值累加到base上<ul><li>如果Cell[]数组未初始化，会调用父类的longAccumelate去初始化Cell[]，如果Cell[]已经初始化但是冲突发生在Cell单元内，则也调用父类的longAccumelate，此时可能就需要对Cell[]扩容了</li></ul></li><li>累加到各个线程自己的槽Cell[i]中</li><li><img src="/static/architect/Java%E5%B9%B6%E5%8F%91-CAS-Atomic-1.png" alt=""></li></ul></li><li>Striped64#longAccumulate<ul><li><img src="/static/architect/Java%E5%B9%B6%E5%8F%91-CAS-Atomic-2.png" alt=""></li></ul></li><li>LongAdder#sum：返回累加的和，也就是"当前时刻"的计数值（计算总和时没有对Cell数组进行加锁）<ul><li>高并发时，除非全局加锁，否则得不到程序运行中某个时刻绝对准确的值</li><li>此返回值可能不是绝对准确的，因为调用这个方法时还有其他线程可能正在进行计数累加，方法的返回时刻和调用时刻不是同一个点，在有并发的情况下，这个值只是近似准确的计数值</li></ul></li><li>LongAccumulator是LongAdder的增强版：提供了自定义的函数操作（LongBinaryOperator）<ul><li>内部原理和LongAdder几乎完全一样，都是利用了父类Striped64的longAccumulate方法</li></ul></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;ul&gt;
&lt;li&gt;CAS&lt;/li&gt;
&lt;li&gt;Atomic&lt;/li&gt;
&lt;li&gt;LongAdder&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;ul&gt;
&lt;li&gt;CAS（Compare&amp;nbsp;And&amp;nbsp;Swap，比较并交换）：针对一个变量，首先比较它的内存值与某个期望值是否相同，如果</summary>
      
    
    
    
    <category term="IT学习笔记" scheme="https://jxch.github.io/categories/IT%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="Java并发" scheme="https://jxch.github.io/tags/Java%E5%B9%B6%E5%8F%91/"/>
    
  </entry>
  
  <entry>
    <title>Java并发-BlockingQueue</title>
    <link href="https://jxch.github.io/2024/06/13/architect/java-bing-fa/java-bing-fa-blockingqueue/"/>
    <id>https://jxch.github.io/2024/06/13/architect/java-bing-fa/java-bing-fa-blockingqueue/</id>
    <published>2024-06-13T03:29:49.000Z</published>
    <updated>2024-08-30T07:00:01.032Z</updated>
    
    <content type="html"><![CDATA[<ul><li>BlockingQueue和JDK集合包中的Queue接口兼容，同时在其基础上增加了阻塞功能<ul><li>offer(E&nbsp;e)：如果队列没满，返回true，如果队列已满，返回false（不阻塞）</li><li>offer(E&nbsp;e,&nbsp;long&nbsp;timeout,&nbsp;TimeUnit&nbsp;unit)：可以设置阻塞时间，如果队列已满，则进行阻塞。超过阻塞时间，则返回false</li><li>put(E&nbsp;e)：队列没满的时候是正常的插入，如果队列已满，则阻塞，直至队列空出位置</li><li>poll()：如果有数据，出队，如果没有数据，返回null&nbsp;&nbsp;&nbsp;（不阻塞）</li><li>poll(long&nbsp;timeout,&nbsp;TimeUnit&nbsp;unit)：可以设置阻塞时间，如果没有数据，则阻塞，超过阻塞时间，则返回null</li><li>take()：队列里有数据会正常取出数据并删除；但是如果队列里无数据，则阻塞，直到队列里有数据</li></ul></li><li>ArrayBlockingQueue 基于数组的有界阻塞队列<ul><li>利用&nbsp;ReentrantLock&nbsp;实现线程安全（只能有一个线程可以进行入队或者出队操作）</li><li>利用了Lock锁的Condition通知机制进行阻塞控制（notEmpty、notFull）</li></ul></li><li>LinkedBlockingQueue  基于单链表的无界阻塞队列<ul><li>读写分离（只能从head取元素，从tail添加元素）：采用两把锁（putLock、takeLock）的锁分离技术实现入队出队互不阻塞</li></ul></li><li>SynchronousQueue 没有数据缓冲（容量为0）的 BlockingQueue ：它所做的就是直接传递<ul><li>每次取数据都要先阻塞，直到有数据被放入</li><li>每次放数据的时候也会阻塞，直到有消费者来取</li></ul></li><li>PriorityBlockingQueue 基于数组（二叉堆）的无界优先级阻塞队列（默认长度是11，虽然指定了数组的长度，但是可以无限的扩充）<ul><li>每次出队都返回优先级别最高的或者最低的元素（不能保证同优先级元素的顺序）</li><li>默认情况下元素采用自然顺序升序排序（也可以通过构造函数来指定Comparator来对元素进行排序）</li></ul></li><li>DelayQueue 基于优先队列&nbsp;PriorityQueue&nbsp;的支持延时获取元素的无界队阻塞队列<ul><li>元素必须实现&nbsp;Delayed&nbsp;接口（&nbsp;Delayed&nbsp;接口又继承了&nbsp;Comparable&nbsp;接口）</li><li>在创建元素时可以指定多久才可以从队列中获取当前元素，只有在延迟期满时才能从队列中提取元素</li><li>按照延迟时间的长短来排序，下一个即将执行的任务会排到队列的最前面</li><li>获取元素，先获取到锁对象，然后获取最早过期的元素（但是并不从队列中弹出元素）<ul><li>判断最早过期元素是否为空（如果为空则直接让当前线程无限期等待状态，并且让出当前锁对象）</li><li>如果不为空：获取最早过期元素的剩余过期时间（如果已经过期则直接返回当前元素）</li><li>如果没有过期（剩余时间还存在），则先获取Leader对象，如果Leader已经有线程在处理，则当前线程进行无限期等待，如果Leader为空，则首先将Leader设置为当前线程，并且让当前线程等待剩余时间</li><li>最后将Leader线程设置为空，并且队列有内容则唤醒一个等待的队列</li></ul></li></ul></li><li>线程池对于阻塞队列的选择<ul><li>FixedThreadPool（SingleThreadExecutor&nbsp;同理）选取的是&nbsp;LinkedBlockingQueue</li><li>CachedThreadPool&nbsp;选取的是&nbsp;SynchronousQueue</li><li>ScheduledThreadPool（SingleThreadScheduledExecutor同理）选取的是延迟队列</li></ul></li><li>选择策略：<ul><li>功能&nbsp;PriorityBlockingQueue 优先级；DelayQueue 延时</li><li>容量：SynchronousQueue 容量是0；DelayQueue 容量是Integer.MAX_VALUE</li><li>能否扩容：ArrayBlockingQueue 不能扩容；PriorityBlockingQueue 可以动态扩容</li><li>内存结构：ArrayBlockingQueue 数组的空间利用率更高</li><li>性能：LinkedBlockingQueue 读写分离；SynchronousQueue 直接传递</li></ul></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;ul&gt;
&lt;li&gt;BlockingQueue和JDK集合包中的Queue接口兼容，同时在其基础上增加了阻塞功能
&lt;ul&gt;
&lt;li&gt;offer(E&amp;nbsp;e)：如果队列没满，返回true，如果队列已满，返回false（不阻塞）&lt;/li&gt;
&lt;li&gt;offer(E&amp;nbsp;e,&amp;</summary>
      
    
    
    
    <category term="IT学习笔记" scheme="https://jxch.github.io/categories/IT%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="Java并发" scheme="https://jxch.github.io/tags/Java%E5%B9%B6%E5%8F%91/"/>
    
  </entry>
  
  <entry>
    <title>Java并发-AQS</title>
    <link href="https://jxch.github.io/2024/06/13/architect/java-bing-fa/java-bing-fa-aqs/"/>
    <id>https://jxch.github.io/2024/06/13/architect/java-bing-fa/java-bing-fa-aqs/</id>
    <published>2024-06-13T03:28:49.000Z</published>
    <updated>2024-08-30T06:59:55.443Z</updated>
    
    <content type="html"><![CDATA[<ul><li>AQS具备的特性：阻塞等待队列；共享/独占；公平/非公平；可重入；允许中断</li><li>AQS内部维护属性<code>volatile&nbsp;int&nbsp;state</code>：state 表示资源的可用状态<ul><li>State三种访问方式：<code>getState()&nbsp;setState()&nbsp;compareAndSetState()</code></li></ul></li><li>AQS定义两种资源共享方式<ul><li>Exclusive-独占，只有一个线程能执行，如ReentrantLock</li><li>Share-共享，多个线程可以同时执行，如Semaphore/CountDownLatch</li></ul></li><li>AQS定义两种队列<ul><li>同步等待队列：&nbsp;主要用于维护获取锁失败时入队的线程</li><li>条件等待队列：&nbsp;调用await()的时候会释放锁，然后线程会加入到条件队列，调用signal()唤醒的时候会把条件队列中的线程节点移动到同步队列中，等待再次获得锁</li></ul></li><li>AQS&nbsp;定义了5个队列中节点状态<ul><li>值为0，初始化状态，表示当前节点在sync队列中，等待着获取锁</li><li>CANCELLED，值为1，表示当前的线程被取消</li><li>SIGNAL，值为-1，表示当前节点的后继节点包含的线程需要运行，也就是unpark</li><li>CONDITION，值为-2，表示当前节点在等待condition，也就是在condition队列中</li><li>PROPAGATE，值为-3，表示当前场景下后续的acquireShared能够得以执行</li></ul></li><li>自定义同步器实现时主要实现以下几种方法：只需要实现共享资源state的获取与释放方式即可，至于具体线程等待队列的维护（如获取资源失败入队/唤醒出队等），AQS已经在顶层实现好了<ul><li>isHeldExclusively()：该线程是否正在独占资源。只有用到condition才需要去实现它</li><li>tryAcquire(int)：独占方式。尝试获取资源，成功则返回true，失败则返回false</li><li>tryRelease(int)：独占方式。尝试释放资源，成功则返回true，失败则返回false</li><li>tryAcquireShared(int)：共享方式。尝试获取资源。负数表示失败；0表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源</li><li>tryReleaseShared(int)：共享方式。尝试释放资源，如果释放后允许唤醒后续等待结点返回true，否则返回false</li></ul></li><li>同步等待队列：AQS当中的同步等待队列也称CLH队列，一种基于双向链表数据结构的队列，是FIFO先进先出线程等待队列，Java中的CLH队列是原CLH队列的一个变种，线程由原自旋机制改为阻塞机制。AQS&nbsp;依赖CLH同步队列来完成同步状态的管理<ul><li>当前线程如果获取同步状态失败时，AQS则会将当前线程已经等待状态等信息构造成一个节点（Node）并将其加入到CLH同步队列，同时会阻塞当前线程</li><li>当同步状态释放时，会把首节点唤醒（公平锁），使其再次尝试获取同步状态</li><li>通过signal或signalAll将条件队列中的节点转移到同步队列。（由条件队列转化为同步队列）</li></ul></li><li>条件等待队列：AQS中条件队列是使用单向列表保存的，用nextWaiter来连接<ul><li>调用await方法阻塞线程</li><li>当前线程存在于同步队列的头结点，调用await方法进行阻塞（从同步队列转化到条件队列）</li></ul></li><li>Condition接口<ul><li>调用<code>Condition#await</code>方法会释放当前持有的锁，然后阻塞当前线程，同时向Condition队列尾部添加一个节点，所以调用<code>Condition#await</code>方法的时候必须持有锁</li><li>调用<code>Condition#signal</code>方法会将Condition队列的首节点移动到阻塞队列尾部，然后唤醒因调用<code>Condition#await</code>方法而阻塞的线程(唤醒之后这个线程就可以去竞争锁了)，所以调用<code>Condition#signal</code>方法的时候必须持有锁，持有锁的线程唤醒被因调用<code>Condition#await</code>方法而阻塞的线程</li></ul></li></ul><p><img src="/static/architect/Java%E5%B9%B6%E5%8F%91-AQS.png" alt=""></p>]]></content>
    
    
      
      
    <summary type="html">&lt;ul&gt;
&lt;li&gt;AQS具备的特性：阻塞等待队列；共享/独占；公平/非公平；可重入；允许中断&lt;/li&gt;
&lt;li&gt;AQS内部维护属性&lt;code&gt;volatile&amp;nbsp;int&amp;nbsp;state&lt;/code&gt;：state 表示资源的可用状态
&lt;ul&gt;
&lt;li&gt;State三种访</summary>
      
    
    
    
    <category term="IT学习笔记" scheme="https://jxch.github.io/categories/IT%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="Java并发" scheme="https://jxch.github.io/tags/Java%E5%B9%B6%E5%8F%91/"/>
    
  </entry>
  
  <entry>
    <title>Java并发-线程休眠与唤醒</title>
    <link href="https://jxch.github.io/2024/06/13/architect/java-bing-fa/java-bing-fa-xian-cheng-xiu-mian-yu-huan-xing/"/>
    <id>https://jxch.github.io/2024/06/13/architect/java-bing-fa/java-bing-fa-xian-cheng-xiu-mian-yu-huan-xing/</id>
    <published>2024-06-13T03:27:49.000Z</published>
    <updated>2024-08-30T06:59:48.977Z</updated>
    
    <content type="html"><![CDATA[<ul><li>Thread#sleep<ul><li>必须指定休眠时间</li><li>休眠时线程状态为TIMED_WAITING</li><li>需要捕获InterruptedException异常</li><li>不会释放持有的锁</li></ul></li><li>Object#wait<ul><li>可以通过notify唤醒，notify必须在wait之后执行，否则会丢失唤醒信号</li><li>休眠时线程状态为WAITING</li><li>需要捕获InterruptedException异常</li><li>会释放持有的锁</li><li>必须在synchronized内使用</li><li>无法唤醒指定的线程</li></ul></li><li>LockSupport#park<ul><li>通过二元信号量实现的阻塞</li><li>休眠时线程状态为WAITING</li><li>无须捕获InterruptedException异常，但是也会响应中断</li><li>不会释放持有的锁</li><li>可以通过unpark唤醒，unpark方法可以比park先执行，不会丢失唤醒信号</li><li>可以指定任何线程进行唤醒</li></ul></li></ul><hr><ul><li>LockSupport就是通过控制变量_counter来对线程阻塞唤醒进行控制的，原理有点类似于信号量机制<ul><li>当调用park()方法时，会将_counter置为0，同时判断前值，小于1说明前面被unpark过，则直接退出，否则将使该线程阻塞</li><li>当调用unpark()方法时，会将_counter置为1，同时判断前值，小于1会进行线程唤醒，否则直接退出<ul><li>为什么唤醒两次后阻塞两次会阻塞线程：连续调用两次unpark和调用一次unpark效果一样（_counter最大为1）</li></ul></li></ul></li><li>pthread_cond_wait()&nbsp;&nbsp;用于阻塞当前线程，等待别的线程使用&nbsp;pthread_cond_signal()&nbsp;或pthread_cond_broadcast来唤醒它<ul><li>pthread_cond_signal()可以唤醒至少一个线程；发送一个信号给另外一个正在处于阻塞等待状态的线程，使其脱离阻塞状态，继续执行</li><li>pthread_cond_broadcast()则是唤醒等待该条件满足的所有线程</li></ul></li></ul><p><img src="/static/architect/Java%E5%B9%B6%E5%8F%91-%E7%BA%BF%E7%A8%8B%E4%BC%91%E7%9C%A0%E4%B8%8E%E5%94%A4%E9%86%92.png" alt=""></p>]]></content>
    
    
      
      
    <summary type="html">&lt;ul&gt;
&lt;li&gt;Thread#sleep
&lt;ul&gt;
&lt;li&gt;必须指定休眠时间&lt;/li&gt;
&lt;li&gt;休眠时线程状态为TIMED_WAITING&lt;/li&gt;
&lt;li&gt;需要捕获InterruptedException异常&lt;/li&gt;
&lt;li&gt;不会释放持有的锁&lt;/li&gt;
&lt;/ul&gt;
&lt;/li</summary>
      
    
    
    
    <category term="IT学习笔记" scheme="https://jxch.github.io/categories/IT%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="Java并发" scheme="https://jxch.github.io/tags/Java%E5%B9%B6%E5%8F%91/"/>
    
  </entry>
  
  <entry>
    <title>Java并发-线程</title>
    <link href="https://jxch.github.io/2024/06/13/architect/java-bing-fa/java-bing-fa-xian-cheng/"/>
    <id>https://jxch.github.io/2024/06/13/architect/java-bing-fa/java-bing-fa-xian-cheng/</id>
    <published>2024-06-13T03:26:49.000Z</published>
    <updated>2024-08-30T06:59:42.572Z</updated>
    
    <content type="html"><![CDATA[<ul><li>线程共有六种状态：NEW（初始化状态）；RUNNABLE（可运行状态+运行状态）；BLOCKED（阻塞状态）；WAITING（无时限等待）；TIMED_WAITING（有时限等待）；TERMINATED（终止状态）<ul><li><img src="/static/architect/Java%E5%B9%B6%E5%8F%91-%E7%BA%BF%E7%A8%8B.png" alt=""></li></ul></li><li>中断机制：中断机制是一种协作机制，也就是说通过中断并不能直接终止另一个线程，而需要被中断的线程自己处理<ul><li>interrupt()：&nbsp;将线程的中断标志位设置为true，不会停止线程</li><li>isInterrupted()：判断当前线程的中断标志位是否为true，不会清除中断标志位</li><li>Thread.interrupted()：判断当前线程的中断标志位是否为true，并清除中断标志位，重置为false</li><li>InterruptedException&nbsp;异常，同时清除中断信号，将中断标记位设置成&nbsp;false</li></ul></li><li>管道输入输出流：PipedOutputStream、PipedInputStream、PipedReader和PipedWriter</li></ul><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token class-name">PipedWriter</span> out <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">PipedWriter</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token class-name">PipedReader</span> in <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">PipedReader</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 将输出流和输入流进行连接，否则在使用时会抛出IOException</span>out<span class="token punctuation">.</span><span class="token function">connect</span><span class="token punctuation">(</span>in<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 在不同的线程里使用out和in进行通讯</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;ul&gt;
&lt;li&gt;线程共有六种状态：NEW（初始化状态）；RUNNABLE（可运行状态+运行状态）；BLOCKED（阻塞状态）；WAITING（无时限等待）；TIMED_WAITING（有时限等待）；TERMINATED（终止状态）
&lt;ul&gt;
&lt;li&gt;&lt;img src=&quot;/sta</summary>
      
    
    
    
    <category term="IT学习笔记" scheme="https://jxch.github.io/categories/IT%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="Java并发" scheme="https://jxch.github.io/tags/Java%E5%B9%B6%E5%8F%91/"/>
    
  </entry>
  
  <entry>
    <title>Java并发-设计模式</title>
    <link href="https://jxch.github.io/2024/06/13/architect/java-bing-fa/java-bing-fa-she-ji-mo-shi/"/>
    <id>https://jxch.github.io/2024/06/13/architect/java-bing-fa/java-bing-fa-she-ji-mo-shi/</id>
    <published>2024-06-13T03:25:49.000Z</published>
    <updated>2024-08-30T06:59:33.503Z</updated>
    
    <content type="html"><![CDATA[<ul><li>终止线程的设计模式<ul><li>Two-phase&nbsp;Termination（两阶段终止）模式：终止标志位</li></ul></li><li>避免共享的设计模式<ul><li>Immutability模式：只读</li><li>Copy-on-Write模式：写时复制</li><li>Thread-Specific&nbsp;Storage&nbsp;模式：线程本地存储 ThreadLocal</li></ul></li><li>多线程版本的 if 模式<ul><li>Guarded&nbsp;Suspension 模式（Guarded&nbsp;Wait&nbsp;模式、Spin&nbsp;Lock&nbsp;模式）：一个线程需要等待另外的线程完成后继续下一步操作</li><li>Balking 模式：一个线程发现另一个线程已经做了某一件相同的事，那么本线程就无需再做了，直接结束返回</li></ul></li><li>多线程分工模式<ul><li>Thread-Per-Message&nbsp;模式：为每个任务分配一个独立的线程</li><li>Worker&nbsp;Thread 模式：线程池</li><li>生产者-消费者模式：核心是一个任务队列<ul><li>过饱问题：生产者生产的速度大于消费者消费的速度<ul><li>消费者每天能处理的量比生产者生产的少：消费者加机器</li><li>消费者每天能处理的量比生产者生产的多：适当的加大队列</li><li>系统高峰期生产者速度太快：生产者限流</li></ul></li></ul></li></ul></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;ul&gt;
&lt;li&gt;终止线程的设计模式
&lt;ul&gt;
&lt;li&gt;Two-phase&amp;nbsp;Termination（两阶段终止）模式：终止标志位&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;避免共享的设计模式
&lt;ul&gt;
&lt;li&gt;Immutability模式：只读&lt;/li&gt;
&lt;li&gt;Cop</summary>
      
    
    
    
    <category term="IT学习笔记" scheme="https://jxch.github.io/categories/IT%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="Java并发" scheme="https://jxch.github.io/tags/Java%E5%B9%B6%E5%8F%91/"/>
    
  </entry>
  
</feed>
